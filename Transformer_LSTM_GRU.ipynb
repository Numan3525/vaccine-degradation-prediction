{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 17310.801886,
      "end_time": "2020-10-01T06:43:44.273538",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-10-01T01:55:13.471652",
      "version": "2.1.0"
    },
    "colab": {
      "name": "Transformer_RezaV2F.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xj1yiNiaRUB",
        "outputId": "5329a289-05ac-4a40-9354-c9df112d026d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSqFBatsaR4M",
        "outputId": "93edc755-ff8d-4e6d-cb49-ab9d10ce6451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install kaggle\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"mizanurr\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"654c2a7dc145088aa93c65566a027cf6\"\n",
        "!kaggle competitions download -c stanford-covid-vaccine\n",
        "!kaggle datasets download -d vaghefi/aug-vaccine\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling kaggle-1.5.8:\n",
            "  Successfully uninstalled kaggle-1.5.8\n",
            "Processing /root/.cache/pip/wheels/94/a7/09/68dc83c7c14fdbdf5d3f2b2da5b87e587bfc1e85df69b1130c/kaggle-1.5.8-cp36-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.8\n",
            "stanford-covid-vaccine.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading aug-vaccine.zip to /content\n",
            " 80% 73.0M/91.1M [00:04<00:01, 10.1MB/s]\n",
            "100% 91.1M/91.1M [00:04<00:00, 22.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3v4QxCaaT_V"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfQS2VRcaX8u"
      },
      "source": [
        "with zipfile.ZipFile('/content/stanford-covid-vaccine.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/data/')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "158HblVaacMB"
      },
      "source": [
        "with zipfile.ZipFile('/content/aug-vaccine.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/data/')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:17.991651Z",
          "iopub.status.busy": "2020-10-01T01:55:17.990733Z",
          "iopub.status.idle": "2020-10-01T01:55:28.701411Z",
          "shell.execute_reply": "2020-10-01T01:55:28.700315Z"
        },
        "papermill": {
          "duration": 10.726996,
          "end_time": "2020-10-01T01:55:28.701553",
          "exception": false,
          "start_time": "2020-10-01T01:55:17.974557",
          "status": "completed"
        },
        "tags": [],
        "id": "0d9TNkX9aIs3",
        "outputId": "a96bd6ca-6993-49af-dbe2-1ee652d3bc0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "!pip install spektral"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spektral\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/2e/3b5bb768d0568f9568bcde08f42738b17bada5f5329221222edfad0838f6/spektral-0.6.1-py3-none-any.whl (95kB)\n",
            "\r\u001b[K     |███▍                            | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from spektral) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spektral) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from spektral) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from spektral) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spektral) (1.18.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from spektral) (4.2.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from spektral) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from spektral) (2.5)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from spektral) (2.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->spektral) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->spektral) (2018.9)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->spektral) (4.4.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.15.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.3.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (50.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (3.2.0)\n",
            "Installing collected packages: spektral\n",
            "Successfully installed spektral-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:28.747768Z",
          "iopub.status.busy": "2020-10-01T01:55:28.746789Z",
          "iopub.status.idle": "2020-10-01T01:55:36.477040Z",
          "shell.execute_reply": "2020-10-01T01:55:36.476485Z"
        },
        "papermill": {
          "duration": 7.757591,
          "end_time": "2020-10-01T01:55:36.477169",
          "exception": false,
          "start_time": "2020-10-01T01:55:28.719578",
          "status": "completed"
        },
        "tags": [],
        "id": "xNAdxQ8VaIs7",
        "outputId": "2ae3da72-3376-4fa6-a245-51aaf68494eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#the basics\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import math, json\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import time\n",
        "from spektral.layers import GraphAttention, GatedGraphConv\n",
        "\n",
        "#tensorflow deep learning basics\n",
        "import tensorflow as tf\n",
        "\n",
        "print('tf version:',tf.__version__)\n",
        "\n",
        "print('\\nList of GPUs:')\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version: 2.3.0\n",
            "\n",
            "List of GPUs:\n",
            "Name: /physical_device:GPU:0   Type: GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:36.522717Z",
          "iopub.status.busy": "2020-10-01T01:55:36.521914Z",
          "iopub.status.idle": "2020-10-01T01:55:46.339097Z",
          "shell.execute_reply": "2020-10-01T01:55:46.339950Z"
        },
        "papermill": {
          "duration": 9.843065,
          "end_time": "2020-10-01T01:55:46.340104",
          "exception": false,
          "start_time": "2020-10-01T01:55:36.497039",
          "status": "completed"
        },
        "tags": [],
        "id": "4vTAr-ylaIs-",
        "outputId": "bc5fc43b-21c1-4aec-d79b-a87d64f46e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "import os\n",
        "folder = '/content/data/bpps'\n",
        "files = os.listdir(folder)\n",
        "\n",
        "lst = []\n",
        "for file in tqdm(files):\n",
        "    data = np.load(os.path.join(folder, file))\n",
        "    lst.append([file.replace('.npy',''), data])\n",
        "    \n",
        "bpps = pd.DataFrame(lst, columns=['id', 'bpps'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6034/6034 [00:02<00:00, 2959.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:46.458781Z",
          "iopub.status.busy": "2020-10-01T01:55:46.456938Z",
          "iopub.status.idle": "2020-10-01T01:55:46.459644Z",
          "shell.execute_reply": "2020-10-01T01:55:46.460184Z"
        },
        "papermill": {
          "duration": 0.064842,
          "end_time": "2020-10-01T01:55:46.460317",
          "exception": false,
          "start_time": "2020-10-01T01:55:46.395475",
          "status": "completed"
        },
        "tags": [],
        "id": "rvqsfduUaItA"
      },
      "source": [
        "def get_structure_feature(structure):\n",
        "    pm = np.zeros((len(structure), 3))\n",
        "    start_token_indices = []\n",
        "    for i, token in enumerate(structure):\n",
        "        if token == \"(\":\n",
        "            start_token_indices.append(i)\n",
        "        elif token == \")\":\n",
        "            j = start_token_indices.pop()\n",
        "            pm[i, 0] = pm[i, 0] = i - j\n",
        "            pm[i, 1] = pm[j, 1] = structure[j:i+1].count('.')\n",
        "            pm[i, 2] = pm[j, 2] = structure[j:i+1].count(')') - 1\n",
        "    return pm"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UkrstLqbZuB"
      },
      "source": [
        "train = pd.read_json('/content/data/train.json', lines=True).merge(bpps)\n",
        "test = pd.read_json('/content/data/test.json', lines=True).merge(bpps)\n",
        "sample_sub = pd.read_csv('/content/data/sample_submission.csv')\n",
        "augment = pd.read_csv('/content/drive/My Drive/Vaccine/aug_data1.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:46.588189Z",
          "iopub.status.busy": "2020-10-01T01:55:46.577873Z",
          "iopub.status.idle": "2020-10-01T01:55:52.471799Z",
          "shell.execute_reply": "2020-10-01T01:55:52.470919Z"
        },
        "papermill": {
          "duration": 5.958859,
          "end_time": "2020-10-01T01:55:52.471928",
          "exception": false,
          "start_time": "2020-10-01T01:55:46.513069",
          "status": "completed"
        },
        "tags": [],
        "id": "vbOzg9isaItC",
        "outputId": "cd288dfb-522f-4397-bc12-ea676a109456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True).merge(bpps)\n",
        "# test = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True).merge(bpps)\n",
        "# sample_sub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\n",
        "# augment = pd.read_csv('../input/aug-vaccine/aug_data1.csv')\n",
        "\n",
        "\n",
        "train_aug = train.drop(columns=['structure', 'predicted_loop_type']).merge(augment, how='left', on=['id','sequence'])\n",
        "test_aug = test.drop(columns=['structure', 'predicted_loop_type']).merge(augment, how='left', on=['id','sequence'])\n",
        "\n",
        "test = test.append(test_aug[test.columns])\n",
        "\n",
        "#target columns\n",
        "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
        "error_cols = ['reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C']\n",
        "metric_cols = [0, 1, 3]\n",
        "\n",
        "token = {'sequence': 'ACGU', 'structure': '().', 'predicted_loop_type': 'BEHIMSX'}\n",
        "token_map = {key: {x:i for i, x in enumerate(val)} for key, val in token.items()}\n",
        "\n",
        "def get_adj(structure):\n",
        "    pm = np.zeros((len(structure), len(structure)))\n",
        "    start_token_indices = []\n",
        "    for i, token in enumerate(structure):\n",
        "        if token == \"(\":\n",
        "            start_token_indices.append(i)\n",
        "        elif token == \")\":\n",
        "            j = start_token_indices.pop()\n",
        "            pm[i, j] = 1.0\n",
        "            pm[j, i] = 1.0\n",
        "        pm[i, i] = 1\n",
        "    return pm\n",
        "\n",
        "\n",
        "mu_bpps = 0.368\n",
        "sd_bpps = 0.415\n",
        "\n",
        "def preprocess_inputs(df):\n",
        "    features = []\n",
        "    for col in ['sequence', 'structure', 'predicted_loop_type']:\n",
        "        x = np.array(df[col].apply(lambda seq: [token_map[col][x] for x in seq]).values.tolist())\n",
        "        features.append(tf.keras.backend.one_hot(x,len(token_map[col])))\n",
        "    bpps = np.array(df['bpps'].tolist())\n",
        "    features.append((1-bpps.sum(-1))[:,:,None])\n",
        "    features.append(bpps.max(-1)[:,:,None])\n",
        "    features.append((bpps > 0).mean(-1)[:,:,None])\n",
        "    features.append(np.array(df['structure'].apply(get_structure_feature).values.tolist())/130)\n",
        "    return np.concatenate(features, axis=-1)\n",
        "\n",
        "print('processing train')\n",
        "train_snfilter = train.SN_filter.values\n",
        "train_inputs = preprocess_inputs(train)\n",
        "train_inputs = np.pad(train_inputs,((0, 0), (0, 130-107), (0, 0)))\n",
        "\n",
        "train_inputs_aug = preprocess_inputs(train_aug)\n",
        "train_inputs_aug = np.pad(train_inputs_aug,((0, 0), (0, 130-107), (0, 0)))\n",
        "train_ids_aug = train_aug['id'].values\n",
        "\n",
        "train_weights = np.array(train.signal_to_noise.values.tolist())\n",
        "train_weights_aug = np.array(train_aug.signal_to_noise.values.tolist())\n",
        "\n",
        "train_labels = np.array(train[target_cols].values.tolist()).transpose((0, 2, 1))\n",
        "train_labels_aug = np.array(train_aug[target_cols].values.tolist()).transpose((0, 2, 1))\n",
        "\n",
        "print('Original Train:', train_inputs.shape, train_labels.shape, train_weights.shape)\n",
        "print('Augmented Train:', train_inputs_aug.shape, train_labels_aug.shape, train_weights_aug.shape)\n",
        "\n",
        "train_adj = np.array(train['structure'].apply(get_adj).values.tolist())\n",
        "train_adj = np.pad(train_adj, ((0,0),(0,130-107),(0,130-107)), 'constant')\n",
        "train_adj_aug = np.array(train_aug['structure'].apply(get_adj).values.tolist())\n",
        "train_adj_aug = np.pad(train_adj_aug, ((0,0),(0,130-107),(0,130-107)), 'constant')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing train\n",
            "Original Train: (2400, 130, 20) (2400, 68, 5) (2400,)\n",
            "Augmented Train: (2400, 130, 20) (2400, 68, 5) (2400,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:52.597137Z",
          "iopub.status.busy": "2020-10-01T01:55:52.596220Z",
          "iopub.status.idle": "2020-10-01T01:55:57.403347Z",
          "shell.execute_reply": "2020-10-01T01:55:57.402442Z"
        },
        "papermill": {
          "duration": 4.878349,
          "end_time": "2020-10-01T01:55:57.403509",
          "exception": false,
          "start_time": "2020-10-01T01:55:52.525160",
          "status": "completed"
        },
        "tags": [],
        "id": "RvcT3O61aItE",
        "outputId": "f3981caf-c6f8-4f94-9c04-96c00289d431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#get different test sets and process each\n",
        "public_df = test.query(\"seq_length == 107\").copy()\n",
        "private_df = test.query(\"seq_length == 130\").copy()\n",
        "\n",
        "print('processing test')\n",
        "public_inputs = preprocess_inputs(public_df)\n",
        "public_inputs = np.pad(public_inputs,((0, 0), (0, 130-public_inputs.shape[1]), (0, 0)))\n",
        "\n",
        "private_inputs = preprocess_inputs(private_df)\n",
        "private_inputs = np.pad(private_inputs,((0, 0), (0, 130-private_inputs.shape[1]), (0, 0)))\n",
        "\n",
        "public_adj = np.array(public_df.loc[:, 'structure'].apply(get_adj).values.tolist())\n",
        "public_adj = np.pad(public_adj, ((0,0),(0,130-public_adj.shape[1]),(0,130-public_adj.shape[1])), 'constant')\n",
        "\n",
        "private_adj = np.array(private_df.loc[:, 'structure'].apply(get_adj).values.tolist())\n",
        "private_adj = np.pad(private_adj, ((0,0),(0,130-private_adj.shape[1]),(0,130-private_adj.shape[1])), 'constant')\n",
        "\n",
        "print('Test Sizes:', public_inputs.shape, public_adj.shape, private_inputs.shape, private_adj.shape)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing test\n",
            "Test Sizes: (1258, 130, 20) (1258, 130, 130) (6010, 130, 20) (6010, 130, 130)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:57.523170Z",
          "iopub.status.busy": "2020-10-01T01:55:57.521931Z",
          "iopub.status.idle": "2020-10-01T01:55:57.566000Z",
          "shell.execute_reply": "2020-10-01T01:55:57.564873Z"
        },
        "papermill": {
          "duration": 0.106026,
          "end_time": "2020-10-01T01:55:57.566120",
          "exception": false,
          "start_time": "2020-10-01T01:55:57.460094",
          "status": "completed"
        },
        "tags": [],
        "id": "7OkSXb3xaItH",
        "outputId": "ee294f0d-42b6-4ca2-d1da-5c6b06cc7b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "public_preds = np.load('/content/data/gtn_aug_snr_gru_public_preds.npy')\n",
        "public_std = public_preds.mean(3).mean(2).std(0)\n",
        "good_public = np.where(public_std < np.quantile(public_std, 0.13))[0]\n",
        "public_labels = public_preds.mean(0)[good_public][:,:68,:]\n",
        "print('Public Pseudo-labeling Sizes:', public_labels.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public Pseudo-labeling Sizes: (164, 68, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:57.829572Z",
          "iopub.status.busy": "2020-10-01T01:55:57.828534Z",
          "iopub.status.idle": "2020-10-01T01:55:58.078416Z",
          "shell.execute_reply": "2020-10-01T01:55:58.079529Z"
        },
        "papermill": {
          "duration": 0.457064,
          "end_time": "2020-10-01T01:55:58.079750",
          "exception": false,
          "start_time": "2020-10-01T01:55:57.622686",
          "status": "completed"
        },
        "tags": [],
        "id": "eWjp5f_MaItJ",
        "outputId": "8922d3a0-2f9d-4cf8-887d-d6002cdd655e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "private_preds = np.load('/content/data/gtn_aug_snr_gru_private_preds.npy')\n",
        "private_std = private_preds.mean(3).mean(2).std(0)\n",
        "good_private = np.where(private_std < np.quantile(private_std, 0.13))[0]\n",
        "private_labels = private_preds.mean(0)[good_private][:,:68,:]\n",
        "print('Private Pseudo-labeling Sizes:', private_labels.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Private Pseudo-labeling Sizes: (782, 68, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYc155j2c2Nb"
      },
      "source": [
        "\"\"\" TF-Keras SWA: callback utility for performing stochastic weight averaging (SWA).\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "class SWA(Callback):\n",
        "    \"\"\" Stochastic Weight Averging.\n",
        "    # Paper\n",
        "        title: Averaging Weights Leads to Wider Optima and Better Generalization\n",
        "        link: https://arxiv.org/abs/1803.05407\n",
        "    # Arguments\n",
        "        start_epoch:   integer, epoch when swa should start.\n",
        "        lr_schedule:   string, type of learning rate schedule.\n",
        "        swa_lr:        float, learning rate for swa sampling.\n",
        "        swa_lr2:       float, upper bound of cyclic learning rate.\n",
        "        swa_freq:      integer, length of learning rate cycle.\n",
        "        verbose:       integer, verbosity mode, 0 or 1.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 start_epoch,\n",
        "                 no_samples,\n",
        "                 lr_schedule='manual',\n",
        "                 swa_lr='auto',\n",
        "                 swa_lr2='auto',\n",
        "                 swa_freq=1,\n",
        "                 verbose=0):\n",
        "                 \n",
        "        super(SWA, self).__init__()\n",
        "        self.start_epoch = start_epoch - 1\n",
        "        self.lr_schedule = lr_schedule\n",
        "        self.swa_lr = swa_lr\n",
        "        self.swa_lr2 = swa_lr2\n",
        "        self.swa_freq = swa_freq\n",
        "        self.verbose = verbose\n",
        "        self.no_samples = no_samples\n",
        "        # self.params['samples'] = no_samples \n",
        "\n",
        "        if start_epoch < 2:\n",
        "            raise ValueError('\"swa_start\" attribute cannot be lower than 2.')\n",
        "\n",
        "        schedules = ['manual', 'constant', 'cyclic']\n",
        "\n",
        "        if self.lr_schedule not in schedules:\n",
        "            raise ValueError('\"{}\" is not a valid learning rate schedule' \\\n",
        "                             .format(self.lr_schedule))\n",
        "\n",
        "        if self.lr_schedule == 'cyclic' and self.swa_freq < 2:\n",
        "            raise ValueError('\"swa_freq\" must be higher than 1 for cyclic schedule.')\n",
        "\n",
        "        if self.swa_lr == 'auto' and self.swa_lr2 != 'auto':\n",
        "            raise ValueError('\"swa_lr2\" cannot be manually set if \"swa_lr\" is automatic.') \n",
        "            \n",
        "        if self.lr_schedule == 'cyclic' and self.swa_lr != 'auto' \\\n",
        "           and self.swa_lr2 != 'auto' and self.swa_lr > self.swa_lr2:\n",
        "            raise ValueError('\"swa_lr\" must be lower than \"swa_lr2\".')\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "\n",
        "        self.epochs = self.params.get('epochs')\n",
        "\n",
        "        if self.start_epoch >= self.epochs - 1:\n",
        "            raise ValueError('\"swa_start\" attribute must be lower than \"epochs\".')\n",
        "\n",
        "        self.init_lr = K.eval(self.model.optimizer.lr)\n",
        "\n",
        "        # automatic swa_lr\n",
        "        if self.swa_lr == 'auto':\n",
        "            self.swa_lr = 0.1*self.init_lr\n",
        "        \n",
        "        if self.init_lr < self.swa_lr:\n",
        "            raise ValueError('\"swa_lr\" must be lower than rate set in optimizer.')\n",
        "\n",
        "        # automatic swa_lr2 between initial lr and swa_lr   \n",
        "        if self.lr_schedule == 'cyclic' and self.swa_lr2 == 'auto':\n",
        "            self.swa_lr2 = self.swa_lr + (self.init_lr - self.swa_lr)*0.25\n",
        "\n",
        "        self._check_batch_norm()\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "\n",
        "        self.current_epoch = epoch\n",
        "        self._scheduler(epoch)\n",
        "\n",
        "        # constant schedule is updated epoch-wise\n",
        "        if self.lr_schedule == 'constant' or self.is_batch_norm_epoch:\n",
        "            self._update_lr(epoch)\n",
        "\n",
        "        if self.is_swa_start_epoch:\n",
        "            self.swa_weights = self.model.get_weights()\n",
        "\n",
        "            if self.verbose > 0:\n",
        "                print('\\nEpoch %05d: starting stochastic weight averaging'\n",
        "                      % (epoch + 1))\n",
        "\n",
        "        if self.is_batch_norm_epoch:\n",
        "            self._set_swa_weights(epoch)\n",
        "\n",
        "            if self.verbose > 0:\n",
        "                print('\\nEpoch %05d: reinitializing batch normalization layers'\n",
        "                      % (epoch + 1))\n",
        "\n",
        "            self._reset_batch_norm()\n",
        "\n",
        "            if self.verbose > 0:\n",
        "                print('\\nEpoch %05d: running forward pass to adjust batch normalization'\n",
        "                      % (epoch + 1))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "\n",
        "        # update lr each batch for cyclic lr schedule\n",
        "        if self.lr_schedule == 'cyclic':\n",
        "            self._update_lr(self.current_epoch, batch)\n",
        "\n",
        "        if self.is_batch_norm_epoch:\n",
        "            batch_size = 64\n",
        "            momentum = batch_size / (batch*batch_size + batch_size)\n",
        "\n",
        "            for layer in self.batch_norm_layers:\n",
        "                layer.momentum = momentum\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.eval(self.model.optimizer.lr)\n",
        "        for k, v in logs.items():\n",
        "            if k == 'lr':\n",
        "                self.model.history.history.setdefault(k, []).append(v)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        if self.is_swa_start_epoch:\n",
        "            self.swa_start_epoch = epoch\n",
        "\n",
        "        if self.is_swa_epoch and not self.is_batch_norm_epoch:\n",
        "            self.swa_weights = self._average_weights(epoch)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "\n",
        "        if not self.has_batch_norm:\n",
        "            self._set_swa_weights(self.epochs)\n",
        "        else:\n",
        "            self._restore_batch_norm()\n",
        "\n",
        "    def _scheduler(self, epoch):\n",
        "\n",
        "        swa_epoch = (epoch - self.start_epoch)\n",
        "\n",
        "        self.is_swa_epoch = epoch >= self.start_epoch and swa_epoch % self.swa_freq == 0\n",
        "        self.is_swa_start_epoch = epoch == self.start_epoch\n",
        "        self.is_batch_norm_epoch = epoch == self.epochs - 1 and self.has_batch_norm\n",
        "\n",
        "    def _average_weights(self, epoch):\n",
        "\n",
        "        return [(swa_w * (epoch - self.start_epoch) + w)\n",
        "                / ((epoch - self.start_epoch) + 1)\n",
        "                for swa_w, w in zip(self.swa_weights, self.model.get_weights())]\n",
        "\n",
        "    def _update_lr(self, epoch, batch=None):\n",
        "\n",
        "        if self.is_batch_norm_epoch:\n",
        "            lr = 0\n",
        "            K.set_value(self.model.optimizer.lr, lr)\n",
        "        elif self.lr_schedule == 'constant':\n",
        "            lr = self._constant_schedule(epoch)\n",
        "            K.set_value(self.model.optimizer.lr, lr)\n",
        "        elif self.lr_schedule == 'cyclic':\n",
        "            lr = self._cyclic_schedule(epoch, batch)\n",
        "            K.set_value(self.model.optimizer.lr, lr)\n",
        "\n",
        "    def _constant_schedule(self, epoch):\n",
        "\n",
        "        t = epoch / self.start_epoch\n",
        "        lr_ratio = self.swa_lr / self.init_lr\n",
        "        if t <= 0.5:\n",
        "            factor = 1.0\n",
        "        elif t <= 0.9:\n",
        "            factor = 1.0 - (1.0 - lr_ratio) * (t - 0.5) / 0.4\n",
        "        else:\n",
        "            factor = lr_ratio\n",
        "        return self.init_lr * factor\n",
        "\n",
        "    def _cyclic_schedule(self, epoch, batch):\n",
        "        \"\"\" Designed after Section 3.1 of Averaging Weights Leads to\n",
        "        Wider Optima and Better Generalization(https://arxiv.org/abs/1803.05407)\n",
        "        \"\"\"\n",
        "        # steps are mini-batches per epoch, equal to training_samples / batch_size\n",
        "        steps = self.params.get('steps')\n",
        "        \n",
        "        #occasionally steps parameter will not be set. We then calculate it ourselves\n",
        "        if steps == None:\n",
        "            self.params['samples'] = self.no_samples\n",
        "            steps = self.params['samples'] // self.params['batch_size']\n",
        "        \n",
        "        swa_epoch = (epoch - self.start_epoch) % self.swa_freq\n",
        "        cycle_length = self.swa_freq * steps\n",
        "\n",
        "        # batch 0 indexed, so need to add 1\n",
        "        i = (swa_epoch * steps) + (batch + 1)\n",
        "        if epoch >= self.start_epoch:\n",
        "            t = (((i-1) % cycle_length) + 1)/cycle_length\n",
        "            return (1-t)*self.swa_lr2 + t*self.swa_lr\n",
        "        else:\n",
        "            return self._constant_schedule(epoch)\n",
        "\n",
        "    def _set_swa_weights(self, epoch):\n",
        "\n",
        "        self.model.set_weights(self.swa_weights)\n",
        "\n",
        "        if self.verbose > 0:\n",
        "            print('\\nEpoch %05d: final model weights set to stochastic weight average'\n",
        "                  % (epoch + 1))\n",
        "\n",
        "    def _check_batch_norm(self):\n",
        "\n",
        "        self.batch_norm_momentums = []\n",
        "        self.batch_norm_layers = []\n",
        "        self.has_batch_norm = False\n",
        "        self.running_bn_epoch = False\n",
        "\n",
        "        for layer in self.model.layers:\n",
        "            if issubclass(layer.__class__, BatchNormalization):\n",
        "                self.has_batch_norm = True\n",
        "                self.batch_norm_momentums.append(layer.momentum)\n",
        "                self.batch_norm_layers.append(layer)\n",
        "\n",
        "        if self.verbose > 0 and self.has_batch_norm:\n",
        "            print('Model uses batch normalization. SWA will require last epoch '\n",
        "                  'to be a forward pass and will run with no learning rate')\n",
        "\n",
        "    def _reset_batch_norm(self):\n",
        "\n",
        "        for layer in self.batch_norm_layers:\n",
        "\n",
        "            # to get properly initialized moving mean and moving variance weights\n",
        "            # we initialize a new batch norm layer from the config of the existing\n",
        "            # layer, build that layer, retrieve its reinitialized moving mean and\n",
        "            # moving var weights and then delete the layer\n",
        "            bn_config = layer.get_config()\n",
        "            new_batch_norm = BatchNormalization(**bn_config)\n",
        "            new_batch_norm.build(layer.input_shape)\n",
        "            new_moving_mean, new_moving_var = new_batch_norm.get_weights()[-2:]\n",
        "            # get rid of the new_batch_norm layer\n",
        "            del new_batch_norm\n",
        "            # get the trained gamma and beta from the current batch norm layer\n",
        "            trained_weights = layer.get_weights()\n",
        "            new_weights = []\n",
        "            # get gamma if exists\n",
        "            if bn_config['scale']:\n",
        "                new_weights.append(trained_weights.pop(0))\n",
        "            # get beta if exists\n",
        "            if bn_config['center']:\n",
        "                new_weights.append(trained_weights.pop(0))\n",
        "            new_weights += [new_moving_mean, new_moving_var]\n",
        "            # set weights to trained gamma and beta, reinitialized mean and variance\n",
        "            layer.set_weights(new_weights)\n",
        "\n",
        "    def _restore_batch_norm(self):\n",
        "\n",
        "        for layer, momentum in zip(self.batch_norm_layers, self.batch_norm_momentums):\n",
        "            layer.momentum = momentum"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWM_Tgn3lt3Y"
      },
      "source": [
        "import tensorflow.keras.layers as L\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RfQLC8Mc8Pv"
      },
      "source": [
        "class MultiHeadSelfAttention(L.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = L.Dense(embed_dim)\n",
        "        self.key_dense = L.Dense(embed_dim)\n",
        "        self.value_dense = L.Dense(embed_dim)\n",
        "        self.combine_heads = L.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhTIPNsyc-8l"
      },
      "source": [
        "class EncoderBlock(L.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.3):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [L.Dense(ff_dim, activation=\"relu\"), L.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = L.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = L.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = L.Dropout(rate)\n",
        "        self.dropout2 = L.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFAZALI7c_z6"
      },
      "source": [
        "class DecoderBlock(L.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.3):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.mha2 = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [L.Dense(ff_dim, activation=\"relu\"), L.Dense(embed_dim),]\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, enc_output, training):\n",
        "        attn1 = self.mha1(inputs)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn1)\n",
        "\n",
        "        if enc_output is not None:\n",
        "            attn2 = self.mha2(enc_output)  # (batch_size, target_seq_len, d_model)\n",
        "            attn2 = self.dropout2(attn2, training=training)\n",
        "            out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "        else:\n",
        "            attn2 = self.mha2(inputs)  # (batch_size, target_seq_len, d_model)\n",
        "            attn2 = self.dropout2(attn2, training=training)\n",
        "            out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4sTDTvgdCPf"
      },
      "source": [
        "class TokenAndPositionEmbedding(L.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = L.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = L.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2CArXrQdFNT"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:58.274929Z",
          "iopub.status.busy": "2020-10-01T01:55:58.257981Z",
          "iopub.status.idle": "2020-10-01T01:55:58.307957Z",
          "shell.execute_reply": "2020-10-01T01:55:58.309296Z"
        },
        "papermill": {
          "duration": 0.146152,
          "end_time": "2020-10-01T01:55:58.309511",
          "exception": false,
          "start_time": "2020-10-01T01:55:58.163359",
          "status": "completed"
        },
        "tags": [],
        "id": "r8A1zztTaItL"
      },
      "source": [
        "nnodes = train_inputs.shape[-2]          # Number of nodes in the graphs\n",
        "nfeatures = train_inputs.shape[-1]          # Original feature dimensionality\n",
        "\n",
        "def cbr(x, out_layer, kernel, stride, dilation):\n",
        "        x = L.Conv1D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
        "        # x = L.BatchNormalization()(x)\n",
        "        x = L.Activation(\"relu\")(x)\n",
        "        return x\n",
        "\n",
        "def wave_block(x, filters, kernel_size, n):\n",
        "        dilation_rates = [2**i for i in range(n)]\n",
        "        x = tf.keras.layers.Conv1D(filters = filters,\n",
        "                   kernel_size = 1,\n",
        "                   padding = 'same')(x)\n",
        "        res_x = x\n",
        "        for dilation_rate in dilation_rates:\n",
        "            tanh_out = tf.keras.layers.Conv1D(filters = filters,\n",
        "                              kernel_size = kernel_size,\n",
        "                              padding = 'same', \n",
        "                              activation = 'tanh', \n",
        "                              dilation_rate = dilation_rate)(x)\n",
        "            sigm_out = tf.keras.layers.Conv1D(filters = filters,\n",
        "                              kernel_size = kernel_size,\n",
        "                              padding = 'same',\n",
        "                              activation = 'sigmoid', \n",
        "                              dilation_rate = dilation_rate)(x)\n",
        "            x = tf.keras.layers.Multiply()([tanh_out, sigm_out])\n",
        "            x = tf.keras.layers.Conv1D(filters = filters,\n",
        "                       kernel_size = 1,\n",
        "                       padding = 'same')(x)\n",
        "            res_x = tf.keras.layers.Add()([res_x, x])\n",
        "        return res_x\n",
        "\n",
        "def gru_layer(hidden_dim, dropout):\n",
        "    return tf.keras.layers.Bidirectional(\n",
        "                                tf.keras.layers.GRU(hidden_dim,\n",
        "                                dropout=dropout,\n",
        "                                return_sequences=True,\n",
        "                                kernel_initializer = 'orthogonal'))\n",
        "\n",
        "def lstm_layer(hidden_dim, dropout):\n",
        "    return tf.keras.layers.Bidirectional(\n",
        "                                tf.keras.layers.LSTM(hidden_dim,\n",
        "                                dropout=dropout,\n",
        "                                return_sequences=True,\n",
        "                                kernel_initializer = 'orthogonal'))\n",
        "\n",
        "def mcrmse_loss(y_true, y_pred):\n",
        "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
        "\n",
        "def mcrmse(y_true, y_pred):\n",
        "    diff = tf.reshape(y_true[:,:,:5] - y_pred, [-1, 5])\n",
        "    colwise_mse = tf.reduce_mean(tf.square(diff), axis=0)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse))\n",
        "\n",
        "\n",
        "def competition_metric(y_true, y_pred):\n",
        "    total = 0\n",
        "    for i in range(5):\n",
        "        rmse = np.mean((y_pred[:,:,i] - y_true[:,:,i])**2)**0.5\n",
        "        print('{:12s}: {:.4f}'.format(target_cols[i], rmse))\n",
        "        if target_cols[i] in ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']:\n",
        "            total += rmse/3\n",
        "    print('total:', total)\n",
        "\n",
        "def build_model(model_num=0,seq_len=130, pred_len=68, dropout=0.4,\n",
        "                embed_dim=512, hidden_dim=256):\n",
        "    \n",
        "    X_in = tf.keras.layers.Input(shape=(seq_len, nfeatures))\n",
        "    A_in = tf.keras.layers.Input(shape=(seq_len, seq_len))\n",
        "    embed = tf.keras.layers.Dense(embed_dim, activation='linear')(X_in)    \n",
        "        \n",
        "    gc1 = GraphAttention(embed_dim, activation='relu', dropout_rate=0.1)([X_in, A_in])\n",
        "    gc1 = tf.keras.layers.Dropout(.2)(gc1)\n",
        "    gc1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(gc1 + embed)\n",
        "    \n",
        "    gc2 = GraphAttention(embed_dim, activation='relu', dropout_rate=0.1)([gc1, A_in])\n",
        "    gc2 = tf.keras.layers.Dropout(.2)(gc2)\n",
        "    gc2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(gc2 + gc1)\n",
        "    \n",
        "    reshaped = tf.keras.layers.LayerNormalization(epsilon=1e-6)(gc2 + embed)\n",
        "    \n",
        "\n",
        "    encoder_block1 = EncoderBlock(reshaped.shape[2], 4, 32)\n",
        "    encoder_block2 = EncoderBlock(reshaped.shape[2], 4, 64)\n",
        "    encoder_block3 = EncoderBlock(reshaped.shape[2], 4, 128)\n",
        "    \n",
        "    hidden = encoder_block1(reshaped)\n",
        "    hidden = encoder_block2(hidden)\n",
        "    hidden = encoder_block3(hidden)\n",
        "    \n",
        "    if model_num == 0:\n",
        "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "  \n",
        "              \n",
        "    if model_num == 1:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        \n",
        "    if model_num == 2:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "\n",
        "    if model_num == 3:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "\n",
        "    if model_num == 4:\n",
        "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden) \n",
        "        \n",
        "    if model_num == 5:\n",
        "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        \n",
        "    \n",
        "    #only making predictions on the first part of each sequence\n",
        "    truncated = hidden[:, :pred_len]\n",
        "    \n",
        "    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[X_in, A_in], outputs=out)\n",
        "\n",
        "    #some optimizers\n",
        "    adam = tf.optimizers.Adam()\n",
        "    \n",
        "    model.compile(optimizer = adam, loss=mcrmse_loss)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:58.485135Z",
          "iopub.status.busy": "2020-10-01T01:55:58.484268Z",
          "iopub.status.idle": "2020-10-01T01:55:58.488357Z",
          "shell.execute_reply": "2020-10-01T01:55:58.487814Z"
        },
        "papermill": {
          "duration": 0.097,
          "end_time": "2020-10-01T01:55:58.488480",
          "exception": false,
          "start_time": "2020-10-01T01:55:58.391480",
          "status": "completed"
        },
        "tags": [],
        "id": "eT57g8JmaItN"
      },
      "source": [
        "#basic training configuration\n",
        "FOLDS = 10\n",
        "EPOCHS = 500\n",
        "BATCH_SIZE = 64*len(gpus)\n",
        "VERBOSE = 1\n",
        "\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(verbose=VERBOSE, factor=0.9, patience = 5 )\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=VERBOSE, mode='auto')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:58.629846Z",
          "iopub.status.busy": "2020-10-01T01:55:58.619409Z",
          "iopub.status.idle": "2020-10-01T06:39:54.540864Z",
          "shell.execute_reply": "2020-10-01T06:39:54.542107Z"
        },
        "papermill": {
          "duration": 17035.99745,
          "end_time": "2020-10-01T06:39:54.542340",
          "exception": false,
          "start_time": "2020-10-01T01:55:58.544890",
          "status": "completed"
        },
        "tags": [],
        "id": "2moDM897aItP",
        "outputId": "adde6735-3594-4788-e12c-11a565288994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = KFold(FOLDS, shuffle = True, random_state = 34)\n",
        "\n",
        "#strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "model_name = 'gtn_aug_snr'\n",
        "\n",
        "train_ids = train['id'].values\n",
        "\n",
        "models = [0,1,2,3]\n",
        "\n",
        "gru_private_preds = [None]*len(models)\n",
        "gru_public_preds = [None]*len(models)\n",
        "oof = [None]*len(models)\n",
        "\n",
        "for model_num in models:\n",
        "    \n",
        "    gru_private_preds[model_num] = np.zeros((private_df.shape[0], 130, 5))\n",
        "    gru_public_preds[model_num] = np.zeros((public_df.shape[0], 107, 5))\n",
        "    oof[model_num] = np.zeros((train_labels.shape[0], 68, 5))\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(list(kfold.split(train_inputs))[:]):\n",
        "        print('Fold:', fold, ' model_num:', model_num)\n",
        "        cp = tf.keras.callbacks.ModelCheckpoint(f'{model_name}_{fold}_{model_num}.h5', monitor='val_loss', verbose=VERBOSE, save_best_only=True,\n",
        "            save_weights_only=True, mode='auto', save_freq='epoch')\n",
        "        \n",
        "        #train_index = train_index[train_snfilter[train_index] == 1]\n",
        "        train_X = train_inputs[train_index]\n",
        "        train_y = train_labels[train_index]\n",
        "        train_A = train_adj[train_index]\n",
        "        train_W = train_weights[train_index]\n",
        "        \n",
        "        if 1:\n",
        "            aug_indx = np.isin(train_ids_aug, train_ids[train_index])    \n",
        "            train_X_aug = train_inputs_aug[aug_indx]\n",
        "            train_y_aug = train_labels_aug[aug_indx]\n",
        "            train_A_aug = train_adj_aug[aug_indx]\n",
        "            train_W_aug = train_weights_aug[aug_indx]\n",
        "\n",
        "            train_X = np.concatenate((train_X, train_X_aug))\n",
        "            train_y = np.concatenate((train_y, train_y_aug))\n",
        "            train_A = np.concatenate((train_A, train_A_aug))\n",
        "            train_W = np.concatenate((train_W, train_W_aug))\n",
        "        \n",
        "        if 0:\n",
        "            train_X_aug = public_inputs[good_public]\n",
        "            train_A_aug = public_adj[good_public]\n",
        "            train_W_aug = train_weights[train_index].mean()*np.ones(train_X_aug.shape[0])\n",
        "            train_y_aug = public_labels\n",
        "\n",
        "            train_X = np.concatenate((train_X, train_X_aug))\n",
        "            train_y = np.concatenate((train_y, train_y_aug))\n",
        "            train_A = np.concatenate((train_A, train_A_aug))\n",
        "            train_W = np.concatenate((train_W, train_W_aug))    \n",
        "            \n",
        "            train_X_aug = private_inputs[good_private]\n",
        "            train_A_aug = private_adj[good_private]\n",
        "            train_W_aug = train_weights[train_index].mean()*np.ones(train_X_aug.shape[0])\n",
        "            train_y_aug = private_labels\n",
        "\n",
        "            train_X = np.concatenate((train_X, train_X_aug))\n",
        "            train_y = np.concatenate((train_y, train_y_aug))\n",
        "            train_A = np.concatenate((train_A, train_A_aug))\n",
        "            train_W = np.concatenate((train_W, train_W_aug)) \n",
        "        \n",
        "        print(train_X.shape)\n",
        "        \n",
        "        val_index = val_index[train_snfilter[val_index] == 1]\n",
        "        valid_X = train_inputs[val_index]\n",
        "        valid_y = train_labels[val_index]\n",
        "        valid_A = train_adj[val_index]\n",
        "        \n",
        "        model = build_model(model_num)\n",
        "        history = model.fit([train_X,train_A], train_y, sample_weight = train_W, validation_data=([valid_X,valid_A],valid_y), \n",
        "                            batch_size=BATCH_SIZE, epochs=EPOCHS,callbacks=[lr,cp,es],verbose = VERBOSE)      \n",
        "        \n",
        "        model.load_weights(f'{model_name}_{fold}_{model_num}.h5')\n",
        "        oof[model_num][val_index] = model.predict([valid_X,valid_A])\n",
        "        \n",
        "        competition_metric(valid_y, oof[model_num][val_index])\n",
        "    \n",
        "        \n",
        "        if 1:\n",
        "            #load best model and predict\n",
        "            gru_short = build_model(model_num, pred_len=107)\n",
        "            gru_short.load_weights(f'{model_name}_{fold}_{model_num}.h5')\n",
        "            gru_public_pred = gru_short.predict([public_inputs,public_adj]) / FOLDS\n",
        "            \n",
        "            gru_long = build_model(model_num, pred_len=130)\n",
        "            gru_long.load_weights(f'{model_name}_{fold}_{model_num}.h5')\n",
        "            gru_private_pred = gru_long.predict([private_inputs, private_adj]) / FOLDS\n",
        "            \n",
        "            gru_public_preds[model_num] += gru_public_pred\n",
        "            gru_private_preds[model_num] += gru_private_pred\n",
        "      \n",
        "    print('===================OOF RMSE=================')\n",
        "    competition_metric(train_labels[train_snfilter == 1], oof[model_num][train_snfilter == 1])\n",
        "    print('============================================')\n",
        "\n",
        "\n",
        "print('===================COMBINED OOF RMSE=================')\n",
        "competition_metric(train_labels[train_snfilter == 1], np.mean(oof, axis=0)[train_snfilter == 1])\n",
        "print('=====================================================')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.9452 - val_loss: 0.2293\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9268\n",
            "Epoch 00012: val_loss did not improve from 0.22694\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.9268 - val_loss: 0.2301\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9102\n",
            "Epoch 00013: val_loss did not improve from 0.22694\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.9102 - val_loss: 0.2302\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8924\n",
            "Epoch 00014: val_loss improved from 0.22694 to 0.21958, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.8924 - val_loss: 0.2196\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8735\n",
            "Epoch 00015: val_loss did not improve from 0.21958\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.8735 - val_loss: 0.2208\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8604\n",
            "Epoch 00016: val_loss improved from 0.21958 to 0.21890, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.8604 - val_loss: 0.2189\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8414\n",
            "Epoch 00017: val_loss improved from 0.21890 to 0.21847, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.8414 - val_loss: 0.2185\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8275\n",
            "Epoch 00018: val_loss improved from 0.21847 to 0.21599, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.8275 - val_loss: 0.2160\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8149\n",
            "Epoch 00019: val_loss did not improve from 0.21599\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.8149 - val_loss: 0.2160\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8018\n",
            "Epoch 00020: val_loss did not improve from 0.21599\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.8018 - val_loss: 0.2163\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7911\n",
            "Epoch 00021: val_loss improved from 0.21599 to 0.21518, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.7911 - val_loss: 0.2152\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7828\n",
            "Epoch 00022: val_loss improved from 0.21518 to 0.21155, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.7828 - val_loss: 0.2115\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7676\n",
            "Epoch 00023: val_loss improved from 0.21155 to 0.21092, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.7676 - val_loss: 0.2109\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7597\n",
            "Epoch 00024: val_loss improved from 0.21092 to 0.21011, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.7597 - val_loss: 0.2101\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7503\n",
            "Epoch 00025: val_loss did not improve from 0.21011\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7503 - val_loss: 0.2110\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7404\n",
            "Epoch 00026: val_loss improved from 0.21011 to 0.20947, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.7404 - val_loss: 0.2095\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7327\n",
            "Epoch 00027: val_loss did not improve from 0.20947\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7327 - val_loss: 0.2095\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7259\n",
            "Epoch 00028: val_loss did not improve from 0.20947\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7259 - val_loss: 0.2119\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7160\n",
            "Epoch 00029: val_loss did not improve from 0.20947\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7160 - val_loss: 0.2105\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7079\n",
            "Epoch 00030: val_loss improved from 0.20947 to 0.20885, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.7079 - val_loss: 0.2089\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7017\n",
            "Epoch 00031: val_loss did not improve from 0.20885\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7017 - val_loss: 0.2104\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6957\n",
            "Epoch 00032: val_loss improved from 0.20885 to 0.20682, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.6957 - val_loss: 0.2068\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6898\n",
            "Epoch 00033: val_loss did not improve from 0.20682\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6898 - val_loss: 0.2098\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6815\n",
            "Epoch 00034: val_loss did not improve from 0.20682\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.6815 - val_loss: 0.2101\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6760\n",
            "Epoch 00035: val_loss did not improve from 0.20682\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6760 - val_loss: 0.2069\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6696\n",
            "Epoch 00036: val_loss did not improve from 0.20682\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6696 - val_loss: 0.2082\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6635\n",
            "Epoch 00037: val_loss improved from 0.20682 to 0.20581, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.6635 - val_loss: 0.2058\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6611\n",
            "Epoch 00038: val_loss did not improve from 0.20581\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6611 - val_loss: 0.2093\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6544\n",
            "Epoch 00039: val_loss did not improve from 0.20581\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6544 - val_loss: 0.2066\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6489\n",
            "Epoch 00040: val_loss did not improve from 0.20581\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6489 - val_loss: 0.2075\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6440\n",
            "Epoch 00041: val_loss improved from 0.20581 to 0.20501, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.6440 - val_loss: 0.2050\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6374\n",
            "Epoch 00042: val_loss did not improve from 0.20501\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6374 - val_loss: 0.2069\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6359\n",
            "Epoch 00043: val_loss did not improve from 0.20501\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6359 - val_loss: 0.2082\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6300\n",
            "Epoch 00044: val_loss did not improve from 0.20501\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6300 - val_loss: 0.2067\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6259\n",
            "Epoch 00045: val_loss did not improve from 0.20501\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6259 - val_loss: 0.2062\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6224\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.20501\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6224 - val_loss: 0.2060\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6158\n",
            "Epoch 00047: val_loss did not improve from 0.20501\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6158 - val_loss: 0.2066\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6118\n",
            "Epoch 00048: val_loss did not improve from 0.20501\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6118 - val_loss: 0.2075\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6083\n",
            "Epoch 00049: val_loss did not improve from 0.20501\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6083 - val_loss: 0.2067\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6039\n",
            "Epoch 00050: val_loss improved from 0.20501 to 0.20461, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.6039 - val_loss: 0.2046\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6007\n",
            "Epoch 00051: val_loss improved from 0.20461 to 0.20434, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.6007 - val_loss: 0.2043\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5983\n",
            "Epoch 00052: val_loss did not improve from 0.20434\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5983 - val_loss: 0.2050\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5942\n",
            "Epoch 00053: val_loss improved from 0.20434 to 0.20306, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.5942 - val_loss: 0.2031\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5911\n",
            "Epoch 00054: val_loss did not improve from 0.20306\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5911 - val_loss: 0.2035\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5896\n",
            "Epoch 00055: val_loss did not improve from 0.20306\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5896 - val_loss: 0.2045\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5863\n",
            "Epoch 00056: val_loss improved from 0.20306 to 0.20264, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.5863 - val_loss: 0.2026\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5839\n",
            "Epoch 00057: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.5839 - val_loss: 0.2031\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5796\n",
            "Epoch 00058: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5796 - val_loss: 0.2047\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5782\n",
            "Epoch 00059: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5782 - val_loss: 0.2061\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5762\n",
            "Epoch 00060: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5762 - val_loss: 0.2039\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5732\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5732 - val_loss: 0.2032\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5668\n",
            "Epoch 00062: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5668 - val_loss: 0.2032\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5650\n",
            "Epoch 00063: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5650 - val_loss: 0.2046\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5623\n",
            "Epoch 00064: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5623 - val_loss: 0.2027\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5598\n",
            "Epoch 00065: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5598 - val_loss: 0.2035\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5572\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5572 - val_loss: 0.2032\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5538\n",
            "Epoch 00067: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5538 - val_loss: 0.2034\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5510\n",
            "Epoch 00068: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5510 - val_loss: 0.2029\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5481\n",
            "Epoch 00069: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.5481 - val_loss: 0.2033\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5457\n",
            "Epoch 00070: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5457 - val_loss: 0.2047\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5459\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.20264\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5459 - val_loss: 0.2040\n",
            "Epoch 00071: early stopping\n",
            "reactivity  : 0.2148\n",
            "deg_Mg_pH10 : 0.2540\n",
            "deg_pH10    : 0.2354\n",
            "deg_Mg_50C  : 0.2055\n",
            "deg_50C     : 0.2059\n",
            "total: 0.2247588567625597\n",
            "Fold: 9  model_num: 0\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.9329\n",
            "Epoch 00001: val_loss improved from inf to 0.31881, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 13s 185ms/step - loss: 1.9329 - val_loss: 0.3188\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4147\n",
            "Epoch 00002: val_loss improved from 0.31881 to 0.30274, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 1.4147 - val_loss: 0.3027\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3172\n",
            "Epoch 00003: val_loss improved from 0.30274 to 0.27941, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 1.3172 - val_loss: 0.2794\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2303\n",
            "Epoch 00004: val_loss improved from 0.27941 to 0.25781, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 1.2303 - val_loss: 0.2578\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1628\n",
            "Epoch 00005: val_loss improved from 0.25781 to 0.25065, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 1.1628 - val_loss: 0.2506\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1090\n",
            "Epoch 00006: val_loss improved from 0.25065 to 0.23891, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 1.1090 - val_loss: 0.2389\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0615\n",
            "Epoch 00007: val_loss improved from 0.23891 to 0.23612, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 1.0615 - val_loss: 0.2361\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0258\n",
            "Epoch 00008: val_loss improved from 0.23612 to 0.22795, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 1.0258 - val_loss: 0.2279\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9965\n",
            "Epoch 00009: val_loss improved from 0.22795 to 0.22658, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.9965 - val_loss: 0.2266\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9715\n",
            "Epoch 00010: val_loss did not improve from 0.22658\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.9715 - val_loss: 0.2285\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9491\n",
            "Epoch 00011: val_loss improved from 0.22658 to 0.22184, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.9491 - val_loss: 0.2218\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9297\n",
            "Epoch 00012: val_loss improved from 0.22184 to 0.22075, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.9297 - val_loss: 0.2207\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9070\n",
            "Epoch 00013: val_loss improved from 0.22075 to 0.21672, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.9070 - val_loss: 0.2167\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8919\n",
            "Epoch 00014: val_loss did not improve from 0.21672\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.8919 - val_loss: 0.2168\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8743\n",
            "Epoch 00015: val_loss improved from 0.21672 to 0.21305, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.8743 - val_loss: 0.2130\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8560\n",
            "Epoch 00016: val_loss improved from 0.21305 to 0.21283, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.8560 - val_loss: 0.2128\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8415\n",
            "Epoch 00017: val_loss did not improve from 0.21283\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.8415 - val_loss: 0.2141\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8301\n",
            "Epoch 00018: val_loss did not improve from 0.21283\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.8301 - val_loss: 0.2158\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8170\n",
            "Epoch 00019: val_loss improved from 0.21283 to 0.21086, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.8170 - val_loss: 0.2109\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8041\n",
            "Epoch 00020: val_loss improved from 0.21086 to 0.20790, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.8041 - val_loss: 0.2079\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7933\n",
            "Epoch 00021: val_loss improved from 0.20790 to 0.20605, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.7933 - val_loss: 0.2061\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7817\n",
            "Epoch 00022: val_loss did not improve from 0.20605\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7817 - val_loss: 0.2103\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7690\n",
            "Epoch 00023: val_loss did not improve from 0.20605\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7690 - val_loss: 0.2067\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7607\n",
            "Epoch 00024: val_loss did not improve from 0.20605\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7607 - val_loss: 0.2084\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7515\n",
            "Epoch 00025: val_loss did not improve from 0.20605\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7515 - val_loss: 0.2066\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7439\n",
            "Epoch 00026: val_loss improved from 0.20605 to 0.20327, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.7439 - val_loss: 0.2033\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7372\n",
            "Epoch 00027: val_loss did not improve from 0.20327\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7372 - val_loss: 0.2050\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7266\n",
            "Epoch 00028: val_loss improved from 0.20327 to 0.20231, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.7266 - val_loss: 0.2023\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7186\n",
            "Epoch 00029: val_loss did not improve from 0.20231\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7186 - val_loss: 0.2046\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7113\n",
            "Epoch 00030: val_loss did not improve from 0.20231\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.7113 - val_loss: 0.2055\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7036\n",
            "Epoch 00031: val_loss improved from 0.20231 to 0.20091, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.7036 - val_loss: 0.2009\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6972\n",
            "Epoch 00032: val_loss did not improve from 0.20091\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6972 - val_loss: 0.2032\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6897\n",
            "Epoch 00033: val_loss did not improve from 0.20091\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6897 - val_loss: 0.2021\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6851\n",
            "Epoch 00034: val_loss did not improve from 0.20091\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6851 - val_loss: 0.2020\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6783\n",
            "Epoch 00035: val_loss did not improve from 0.20091\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6783 - val_loss: 0.2017\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6747\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.20091\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6747 - val_loss: 0.2023\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6643\n",
            "Epoch 00037: val_loss did not improve from 0.20091\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.6643 - val_loss: 0.2014\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6587\n",
            "Epoch 00038: val_loss improved from 0.20091 to 0.20045, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.6587 - val_loss: 0.2005\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6550\n",
            "Epoch 00039: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6550 - val_loss: 0.2005\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6483\n",
            "Epoch 00040: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6483 - val_loss: 0.2012\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6445\n",
            "Epoch 00041: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.6445 - val_loss: 0.2021\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6414\n",
            "Epoch 00042: val_loss improved from 0.20045 to 0.19896, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.6414 - val_loss: 0.1990\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6370\n",
            "Epoch 00043: val_loss did not improve from 0.19896\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.6370 - val_loss: 0.1995\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6324\n",
            "Epoch 00044: val_loss did not improve from 0.19896\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6324 - val_loss: 0.1992\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6286\n",
            "Epoch 00045: val_loss did not improve from 0.19896\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.6286 - val_loss: 0.2008\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6237\n",
            "Epoch 00046: val_loss did not improve from 0.19896\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6237 - val_loss: 0.2006\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6205\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.19896\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.6205 - val_loss: 0.2007\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6138\n",
            "Epoch 00048: val_loss did not improve from 0.19896\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6138 - val_loss: 0.2002\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6092\n",
            "Epoch 00049: val_loss did not improve from 0.19896\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.6092 - val_loss: 0.2011\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6067\n",
            "Epoch 00050: val_loss did not improve from 0.19896\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.6067 - val_loss: 0.1995\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6027\n",
            "Epoch 00051: val_loss improved from 0.19896 to 0.19895, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.6027 - val_loss: 0.1990\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5989\n",
            "Epoch 00052: val_loss improved from 0.19895 to 0.19851, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 157ms/step - loss: 0.5989 - val_loss: 0.1985\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5971\n",
            "Epoch 00053: val_loss did not improve from 0.19851\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5971 - val_loss: 0.1994\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5933\n",
            "Epoch 00054: val_loss did not improve from 0.19851\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5933 - val_loss: 0.1995\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5916\n",
            "Epoch 00055: val_loss did not improve from 0.19851\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5916 - val_loss: 0.1992\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5882\n",
            "Epoch 00056: val_loss did not improve from 0.19851\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5882 - val_loss: 0.1989\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5856\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.19851\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5856 - val_loss: 0.2005\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5805\n",
            "Epoch 00058: val_loss did not improve from 0.19851\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5805 - val_loss: 0.1994\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5769\n",
            "Epoch 00059: val_loss did not improve from 0.19851\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5769 - val_loss: 0.1987\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5743\n",
            "Epoch 00060: val_loss did not improve from 0.19851\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5743 - val_loss: 0.1988\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5709\n",
            "Epoch 00061: val_loss did not improve from 0.19851\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5709 - val_loss: 0.2011\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5688\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.19851\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5688 - val_loss: 0.2000\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5663\n",
            "Epoch 00063: val_loss improved from 0.19851 to 0.19851, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5663 - val_loss: 0.1985\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5628\n",
            "Epoch 00064: val_loss improved from 0.19851 to 0.19816, saving model to gtn_aug_snr_9_0.h5\n",
            "68/68 [==============================] - 11s 156ms/step - loss: 0.5628 - val_loss: 0.1982\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5605\n",
            "Epoch 00065: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5605 - val_loss: 0.1992\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5581\n",
            "Epoch 00066: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5581 - val_loss: 0.1993\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5553\n",
            "Epoch 00067: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5553 - val_loss: 0.2003\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5540\n",
            "Epoch 00068: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5540 - val_loss: 0.1986\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5531\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5531 - val_loss: 0.1984\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5483\n",
            "Epoch 00070: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5483 - val_loss: 0.1986\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5459\n",
            "Epoch 00071: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5459 - val_loss: 0.1991\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5441\n",
            "Epoch 00072: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5441 - val_loss: 0.1991\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5420\n",
            "Epoch 00073: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5420 - val_loss: 0.1995\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5407\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5407 - val_loss: 0.1995\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5369\n",
            "Epoch 00075: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5369 - val_loss: 0.1985\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5347\n",
            "Epoch 00076: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5347 - val_loss: 0.1997\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5326\n",
            "Epoch 00077: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5326 - val_loss: 0.1985\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5308\n",
            "Epoch 00078: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5308 - val_loss: 0.1990\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5298\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.19816\n",
            "68/68 [==============================] - 11s 155ms/step - loss: 0.5298 - val_loss: 0.2005\n",
            "Epoch 00079: early stopping\n",
            "reactivity  : 0.2029\n",
            "deg_Mg_pH10 : 0.2421\n",
            "deg_pH10    : 0.2149\n",
            "deg_Mg_50C  : 0.1973\n",
            "deg_50C     : 0.1969\n",
            "total: 0.21408034423889943\n",
            "===================OOF RMSE=================\n",
            "reactivity  : 0.1963\n",
            "deg_Mg_pH10 : 0.2455\n",
            "deg_pH10    : 0.2262\n",
            "deg_Mg_50C  : 0.2001\n",
            "deg_50C     : 0.1965\n",
            "total: 0.2139797335770084\n",
            "============================================\n",
            "Fold: 0  model_num: 1\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.0447\n",
            "Epoch 00001: val_loss improved from inf to 0.32182, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 10s 151ms/step - loss: 2.0447 - val_loss: 0.3218\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4907\n",
            "Epoch 00002: val_loss improved from 0.32182 to 0.28382, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.4907 - val_loss: 0.2838\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3633\n",
            "Epoch 00003: val_loss improved from 0.28382 to 0.26724, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.3633 - val_loss: 0.2672\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3016\n",
            "Epoch 00004: val_loss improved from 0.26724 to 0.25874, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.3016 - val_loss: 0.2587\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2452\n",
            "Epoch 00005: val_loss improved from 0.25874 to 0.24655, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.2452 - val_loss: 0.2466\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1943\n",
            "Epoch 00006: val_loss improved from 0.24655 to 0.23415, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.1943 - val_loss: 0.2342\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1478\n",
            "Epoch 00007: val_loss improved from 0.23415 to 0.23226, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.1478 - val_loss: 0.2323\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1088\n",
            "Epoch 00008: val_loss improved from 0.23226 to 0.22590, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.1088 - val_loss: 0.2259\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0744\n",
            "Epoch 00009: val_loss improved from 0.22590 to 0.22285, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.0744 - val_loss: 0.2228\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0416\n",
            "Epoch 00010: val_loss improved from 0.22285 to 0.21746, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.0416 - val_loss: 0.2175\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0172\n",
            "Epoch 00011: val_loss improved from 0.21746 to 0.21421, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0172 - val_loss: 0.2142\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9964\n",
            "Epoch 00012: val_loss improved from 0.21421 to 0.21157, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9964 - val_loss: 0.2116\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9777\n",
            "Epoch 00013: val_loss improved from 0.21157 to 0.20862, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9777 - val_loss: 0.2086\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9560\n",
            "Epoch 00014: val_loss improved from 0.20862 to 0.20788, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9560 - val_loss: 0.2079\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9361\n",
            "Epoch 00015: val_loss improved from 0.20788 to 0.20279, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9361 - val_loss: 0.2028\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9207\n",
            "Epoch 00016: val_loss improved from 0.20279 to 0.20267, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9207 - val_loss: 0.2027\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9103\n",
            "Epoch 00017: val_loss improved from 0.20267 to 0.19948, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9103 - val_loss: 0.1995\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8922\n",
            "Epoch 00018: val_loss did not improve from 0.19948\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.8922 - val_loss: 0.2008\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8802\n",
            "Epoch 00019: val_loss did not improve from 0.19948\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8802 - val_loss: 0.1999\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8709\n",
            "Epoch 00020: val_loss did not improve from 0.19948\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.8709 - val_loss: 0.2016\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8541\n",
            "Epoch 00021: val_loss improved from 0.19948 to 0.19547, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8541 - val_loss: 0.1955\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8404\n",
            "Epoch 00022: val_loss did not improve from 0.19547\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8404 - val_loss: 0.1976\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8286\n",
            "Epoch 00023: val_loss did not improve from 0.19547\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8286 - val_loss: 0.1965\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8151\n",
            "Epoch 00024: val_loss improved from 0.19547 to 0.19440, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8151 - val_loss: 0.1944\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8045\n",
            "Epoch 00025: val_loss did not improve from 0.19440\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.8045 - val_loss: 0.1958\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7929\n",
            "Epoch 00026: val_loss did not improve from 0.19440\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7929 - val_loss: 0.1957\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7851\n",
            "Epoch 00027: val_loss improved from 0.19440 to 0.19437, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7851 - val_loss: 0.1944\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7789\n",
            "Epoch 00028: val_loss improved from 0.19437 to 0.19248, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7789 - val_loss: 0.1925\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7647\n",
            "Epoch 00029: val_loss did not improve from 0.19248\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7647 - val_loss: 0.1927\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7570\n",
            "Epoch 00030: val_loss did not improve from 0.19248\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7570 - val_loss: 0.1926\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7503\n",
            "Epoch 00031: val_loss improved from 0.19248 to 0.19089, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7503 - val_loss: 0.1909\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7423\n",
            "Epoch 00032: val_loss did not improve from 0.19089\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7423 - val_loss: 0.1943\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7344\n",
            "Epoch 00033: val_loss did not improve from 0.19089\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7344 - val_loss: 0.1936\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7233\n",
            "Epoch 00034: val_loss did not improve from 0.19089\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7233 - val_loss: 0.1921\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7133\n",
            "Epoch 00035: val_loss improved from 0.19089 to 0.19071, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7133 - val_loss: 0.1907\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7090\n",
            "Epoch 00036: val_loss improved from 0.19071 to 0.18972, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7090 - val_loss: 0.1897\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7009\n",
            "Epoch 00037: val_loss did not improve from 0.18972\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7009 - val_loss: 0.1906\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6948\n",
            "Epoch 00038: val_loss did not improve from 0.18972\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6948 - val_loss: 0.1912\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6886\n",
            "Epoch 00039: val_loss did not improve from 0.18972\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6886 - val_loss: 0.1902\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6828\n",
            "Epoch 00040: val_loss did not improve from 0.18972\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6828 - val_loss: 0.1911\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6762\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.18972\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.6762 - val_loss: 0.1903\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6641\n",
            "Epoch 00042: val_loss improved from 0.18972 to 0.18913, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6641 - val_loss: 0.1891\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6594\n",
            "Epoch 00043: val_loss did not improve from 0.18913\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6594 - val_loss: 0.1912\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6529\n",
            "Epoch 00044: val_loss improved from 0.18913 to 0.18830, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6529 - val_loss: 0.1883\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6486\n",
            "Epoch 00045: val_loss did not improve from 0.18830\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.6486 - val_loss: 0.1897\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6443\n",
            "Epoch 00046: val_loss improved from 0.18830 to 0.18758, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6443 - val_loss: 0.1876\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6383\n",
            "Epoch 00047: val_loss improved from 0.18758 to 0.18717, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6383 - val_loss: 0.1872\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6335\n",
            "Epoch 00048: val_loss did not improve from 0.18717\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6335 - val_loss: 0.1878\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6310\n",
            "Epoch 00049: val_loss did not improve from 0.18717\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6310 - val_loss: 0.1880\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6252\n",
            "Epoch 00050: val_loss did not improve from 0.18717\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6252 - val_loss: 0.1887\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6224\n",
            "Epoch 00051: val_loss did not improve from 0.18717\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6224 - val_loss: 0.1883\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6174\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.18717\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6174 - val_loss: 0.1872\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6095\n",
            "Epoch 00053: val_loss improved from 0.18717 to 0.18598, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6095 - val_loss: 0.1860\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6075\n",
            "Epoch 00054: val_loss did not improve from 0.18598\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6075 - val_loss: 0.1869\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6022\n",
            "Epoch 00055: val_loss did not improve from 0.18598\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6022 - val_loss: 0.1878\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6005\n",
            "Epoch 00056: val_loss improved from 0.18598 to 0.18575, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6005 - val_loss: 0.1858\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5944\n",
            "Epoch 00057: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5944 - val_loss: 0.1869\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5915\n",
            "Epoch 00058: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5915 - val_loss: 0.1876\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5885\n",
            "Epoch 00059: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5885 - val_loss: 0.1888\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5848\n",
            "Epoch 00060: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5848 - val_loss: 0.1880\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5842\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5842 - val_loss: 0.1871\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5773\n",
            "Epoch 00062: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5773 - val_loss: 0.1864\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5740\n",
            "Epoch 00063: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5740 - val_loss: 0.1875\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5699\n",
            "Epoch 00064: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5699 - val_loss: 0.1869\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5681\n",
            "Epoch 00065: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5681 - val_loss: 0.1860\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5660\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5660 - val_loss: 0.1870\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5603\n",
            "Epoch 00067: val_loss did not improve from 0.18575\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5603 - val_loss: 0.1863\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5581\n",
            "Epoch 00068: val_loss improved from 0.18575 to 0.18555, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5581 - val_loss: 0.1855\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5551\n",
            "Epoch 00069: val_loss did not improve from 0.18555\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5551 - val_loss: 0.1858\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5530\n",
            "Epoch 00070: val_loss did not improve from 0.18555\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5530 - val_loss: 0.1868\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5501\n",
            "Epoch 00071: val_loss did not improve from 0.18555\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5501 - val_loss: 0.1862\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5473\n",
            "Epoch 00072: val_loss did not improve from 0.18555\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5473 - val_loss: 0.1863\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5460\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.18555\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5460 - val_loss: 0.1864\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5420\n",
            "Epoch 00074: val_loss did not improve from 0.18555\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5420 - val_loss: 0.1859\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5396\n",
            "Epoch 00075: val_loss did not improve from 0.18555\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5396 - val_loss: 0.1861\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5373\n",
            "Epoch 00076: val_loss improved from 0.18555 to 0.18545, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5373 - val_loss: 0.1854\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5362\n",
            "Epoch 00077: val_loss did not improve from 0.18545\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5362 - val_loss: 0.1861\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5346\n",
            "Epoch 00078: val_loss did not improve from 0.18545\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5346 - val_loss: 0.1864\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5328\n",
            "Epoch 00079: val_loss did not improve from 0.18545\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5328 - val_loss: 0.1858\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5306\n",
            "Epoch 00080: val_loss did not improve from 0.18545\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5306 - val_loss: 0.1859\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5278\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.18545\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5278 - val_loss: 0.1867\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5252\n",
            "Epoch 00082: val_loss did not improve from 0.18545\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5252 - val_loss: 0.1858\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5213\n",
            "Epoch 00083: val_loss improved from 0.18545 to 0.18488, saving model to gtn_aug_snr_0_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.5213 - val_loss: 0.1849\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5200\n",
            "Epoch 00084: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5200 - val_loss: 0.1860\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5190\n",
            "Epoch 00085: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5190 - val_loss: 0.1852\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5171\n",
            "Epoch 00086: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5171 - val_loss: 0.1858\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5153\n",
            "Epoch 00087: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5153 - val_loss: 0.1858\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5154\n",
            "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5154 - val_loss: 0.1865\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5112\n",
            "Epoch 00089: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5112 - val_loss: 0.1857\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5106\n",
            "Epoch 00090: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5106 - val_loss: 0.1855\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5086\n",
            "Epoch 00091: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5086 - val_loss: 0.1859\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5063\n",
            "Epoch 00092: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5063 - val_loss: 0.1863\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5055\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5055 - val_loss: 0.1851\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5024\n",
            "Epoch 00094: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5024 - val_loss: 0.1855\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4995\n",
            "Epoch 00095: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4995 - val_loss: 0.1859\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4999\n",
            "Epoch 00096: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4999 - val_loss: 0.1864\n",
            "Epoch 97/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4975\n",
            "Epoch 00097: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4975 - val_loss: 0.1857\n",
            "Epoch 98/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4973\n",
            "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.18488\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4973 - val_loss: 0.1856\n",
            "Epoch 00098: early stopping\n",
            "reactivity  : 0.1880\n",
            "deg_Mg_pH10 : 0.2185\n",
            "deg_pH10    : 0.2098\n",
            "deg_Mg_50C  : 0.1796\n",
            "deg_50C     : 0.1947\n",
            "total: 0.19537196049277686\n",
            "Fold: 1  model_num: 1\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.9587\n",
            "Epoch 00001: val_loss improved from inf to 0.31603, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 10s 154ms/step - loss: 1.9587 - val_loss: 0.3160\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4605\n",
            "Epoch 00002: val_loss improved from 0.31603 to 0.28444, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.4605 - val_loss: 0.2844\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3522\n",
            "Epoch 00003: val_loss improved from 0.28444 to 0.27908, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.3522 - val_loss: 0.2791\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2955\n",
            "Epoch 00004: val_loss improved from 0.27908 to 0.26714, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.2955 - val_loss: 0.2671\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2525\n",
            "Epoch 00005: val_loss improved from 0.26714 to 0.25624, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.2525 - val_loss: 0.2562\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1978\n",
            "Epoch 00006: val_loss improved from 0.25624 to 0.24860, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.1978 - val_loss: 0.2486\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1524\n",
            "Epoch 00007: val_loss improved from 0.24860 to 0.23770, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1524 - val_loss: 0.2377\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1005\n",
            "Epoch 00008: val_loss improved from 0.23770 to 0.23362, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1005 - val_loss: 0.2336\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0599\n",
            "Epoch 00009: val_loss improved from 0.23362 to 0.22508, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0599 - val_loss: 0.2251\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0332\n",
            "Epoch 00010: val_loss did not improve from 0.22508\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.0332 - val_loss: 0.2270\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0075\n",
            "Epoch 00011: val_loss improved from 0.22508 to 0.22134, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0075 - val_loss: 0.2213\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9863\n",
            "Epoch 00012: val_loss improved from 0.22134 to 0.21772, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9863 - val_loss: 0.2177\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9685\n",
            "Epoch 00013: val_loss improved from 0.21772 to 0.21499, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9685 - val_loss: 0.2150\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9469\n",
            "Epoch 00014: val_loss improved from 0.21499 to 0.21464, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9469 - val_loss: 0.2146\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9331\n",
            "Epoch 00015: val_loss improved from 0.21464 to 0.21214, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9331 - val_loss: 0.2121\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9138\n",
            "Epoch 00016: val_loss did not improve from 0.21214\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9138 - val_loss: 0.2132\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8999\n",
            "Epoch 00017: val_loss improved from 0.21214 to 0.21050, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8999 - val_loss: 0.2105\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8853\n",
            "Epoch 00018: val_loss improved from 0.21050 to 0.20972, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8853 - val_loss: 0.2097\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8717\n",
            "Epoch 00019: val_loss improved from 0.20972 to 0.20772, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8717 - val_loss: 0.2077\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8596\n",
            "Epoch 00020: val_loss did not improve from 0.20772\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8596 - val_loss: 0.2081\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8453\n",
            "Epoch 00021: val_loss improved from 0.20772 to 0.20513, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8453 - val_loss: 0.2051\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8309\n",
            "Epoch 00022: val_loss improved from 0.20513 to 0.20411, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8309 - val_loss: 0.2041\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8216\n",
            "Epoch 00023: val_loss did not improve from 0.20411\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8216 - val_loss: 0.2105\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8140\n",
            "Epoch 00024: val_loss improved from 0.20411 to 0.20392, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8140 - val_loss: 0.2039\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7966\n",
            "Epoch 00025: val_loss did not improve from 0.20392\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7966 - val_loss: 0.2042\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7884\n",
            "Epoch 00026: val_loss improved from 0.20392 to 0.20366, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7884 - val_loss: 0.2037\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7799\n",
            "Epoch 00027: val_loss improved from 0.20366 to 0.20183, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.7799 - val_loss: 0.2018\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7690\n",
            "Epoch 00028: val_loss did not improve from 0.20183\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7690 - val_loss: 0.2029\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7605\n",
            "Epoch 00029: val_loss did not improve from 0.20183\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7605 - val_loss: 0.2033\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7508\n",
            "Epoch 00030: val_loss did not improve from 0.20183\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7508 - val_loss: 0.2021\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7442\n",
            "Epoch 00031: val_loss improved from 0.20183 to 0.20118, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7442 - val_loss: 0.2012\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7347\n",
            "Epoch 00032: val_loss improved from 0.20118 to 0.20010, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7347 - val_loss: 0.2001\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7250\n",
            "Epoch 00033: val_loss did not improve from 0.20010\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7250 - val_loss: 0.2015\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7195\n",
            "Epoch 00034: val_loss improved from 0.20010 to 0.19841, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7195 - val_loss: 0.1984\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7109\n",
            "Epoch 00035: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7109 - val_loss: 0.1997\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7023\n",
            "Epoch 00036: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7023 - val_loss: 0.1998\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6990\n",
            "Epoch 00037: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6990 - val_loss: 0.2002\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6896\n",
            "Epoch 00038: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6896 - val_loss: 0.1987\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6835\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6835 - val_loss: 0.2002\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6727\n",
            "Epoch 00040: val_loss improved from 0.19841 to 0.19782, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6727 - val_loss: 0.1978\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6665\n",
            "Epoch 00041: val_loss improved from 0.19782 to 0.19709, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6665 - val_loss: 0.1971\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6611\n",
            "Epoch 00042: val_loss did not improve from 0.19709\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6611 - val_loss: 0.1975\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6549\n",
            "Epoch 00043: val_loss did not improve from 0.19709\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6549 - val_loss: 0.1976\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6497\n",
            "Epoch 00044: val_loss improved from 0.19709 to 0.19693, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6497 - val_loss: 0.1969\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6447\n",
            "Epoch 00045: val_loss did not improve from 0.19693\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6447 - val_loss: 0.1988\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6395\n",
            "Epoch 00046: val_loss improved from 0.19693 to 0.19651, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6395 - val_loss: 0.1965\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6359\n",
            "Epoch 00047: val_loss improved from 0.19651 to 0.19649, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.6359 - val_loss: 0.1965\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6307\n",
            "Epoch 00048: val_loss improved from 0.19649 to 0.19630, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6307 - val_loss: 0.1963\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6283\n",
            "Epoch 00049: val_loss did not improve from 0.19630\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6283 - val_loss: 0.1981\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6222\n",
            "Epoch 00050: val_loss did not improve from 0.19630\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6222 - val_loss: 0.1969\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6197\n",
            "Epoch 00051: val_loss did not improve from 0.19630\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6197 - val_loss: 0.1980\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6131\n",
            "Epoch 00052: val_loss improved from 0.19630 to 0.19590, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6131 - val_loss: 0.1959\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6105\n",
            "Epoch 00053: val_loss did not improve from 0.19590\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6105 - val_loss: 0.1967\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6066\n",
            "Epoch 00054: val_loss improved from 0.19590 to 0.19578, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6066 - val_loss: 0.1958\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6028\n",
            "Epoch 00055: val_loss did not improve from 0.19578\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6028 - val_loss: 0.1971\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5996\n",
            "Epoch 00056: val_loss did not improve from 0.19578\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5996 - val_loss: 0.1965\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5951\n",
            "Epoch 00057: val_loss did not improve from 0.19578\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5951 - val_loss: 0.1968\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5913\n",
            "Epoch 00058: val_loss did not improve from 0.19578\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5913 - val_loss: 0.1964\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5877\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.19578\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5877 - val_loss: 0.1961\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5835\n",
            "Epoch 00060: val_loss improved from 0.19578 to 0.19522, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5835 - val_loss: 0.1952\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5769\n",
            "Epoch 00061: val_loss did not improve from 0.19522\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5769 - val_loss: 0.1954\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5739\n",
            "Epoch 00062: val_loss did not improve from 0.19522\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5739 - val_loss: 0.1956\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5709\n",
            "Epoch 00063: val_loss did not improve from 0.19522\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5709 - val_loss: 0.1954\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5690\n",
            "Epoch 00064: val_loss did not improve from 0.19522\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5690 - val_loss: 0.1953\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5653\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.19522 to 0.19513, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5653 - val_loss: 0.1951\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5611\n",
            "Epoch 00066: val_loss improved from 0.19513 to 0.19508, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5611 - val_loss: 0.1951\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5566\n",
            "Epoch 00067: val_loss improved from 0.19508 to 0.19506, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5566 - val_loss: 0.1951\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5549\n",
            "Epoch 00068: val_loss did not improve from 0.19506\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5549 - val_loss: 0.1951\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5515\n",
            "Epoch 00069: val_loss did not improve from 0.19506\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5515 - val_loss: 0.1961\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5496\n",
            "Epoch 00070: val_loss improved from 0.19506 to 0.19422, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5496 - val_loss: 0.1942\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5460\n",
            "Epoch 00071: val_loss did not improve from 0.19422\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5460 - val_loss: 0.1946\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5455\n",
            "Epoch 00072: val_loss did not improve from 0.19422\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5455 - val_loss: 0.1947\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5431\n",
            "Epoch 00073: val_loss did not improve from 0.19422\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5431 - val_loss: 0.1950\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5412\n",
            "Epoch 00074: val_loss improved from 0.19422 to 0.19413, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5412 - val_loss: 0.1941\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5390\n",
            "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.19413\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5390 - val_loss: 0.1944\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5344\n",
            "Epoch 00076: val_loss did not improve from 0.19413\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5344 - val_loss: 0.1944\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5317\n",
            "Epoch 00077: val_loss did not improve from 0.19413\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5317 - val_loss: 0.1951\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5280\n",
            "Epoch 00078: val_loss did not improve from 0.19413\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5280 - val_loss: 0.1946\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5260\n",
            "Epoch 00079: val_loss did not improve from 0.19413\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5260 - val_loss: 0.1953\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5248\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.19413\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5248 - val_loss: 0.1943\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5203\n",
            "Epoch 00081: val_loss improved from 0.19413 to 0.19396, saving model to gtn_aug_snr_1_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5203 - val_loss: 0.1940\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5182\n",
            "Epoch 00082: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5182 - val_loss: 0.1948\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5174\n",
            "Epoch 00083: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5174 - val_loss: 0.1944\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5148\n",
            "Epoch 00084: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5148 - val_loss: 0.1957\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5141\n",
            "Epoch 00085: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5141 - val_loss: 0.1950\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5123\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5123 - val_loss: 0.1966\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5087\n",
            "Epoch 00087: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5087 - val_loss: 0.1950\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5058\n",
            "Epoch 00088: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5058 - val_loss: 0.1950\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5038\n",
            "Epoch 00089: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5038 - val_loss: 0.1940\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5022\n",
            "Epoch 00090: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5022 - val_loss: 0.1954\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5013\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5013 - val_loss: 0.1949\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4984\n",
            "Epoch 00092: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4984 - val_loss: 0.1942\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4969\n",
            "Epoch 00093: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4969 - val_loss: 0.1951\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4949\n",
            "Epoch 00094: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4949 - val_loss: 0.1946\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4940\n",
            "Epoch 00095: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.4940 - val_loss: 0.1952\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4934\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.19396\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4934 - val_loss: 0.1956\n",
            "Epoch 00096: early stopping\n",
            "reactivity  : 0.1927\n",
            "deg_Mg_pH10 : 0.2333\n",
            "deg_pH10    : 0.2279\n",
            "deg_Mg_50C  : 0.1964\n",
            "deg_50C     : 0.1920\n",
            "total: 0.20747363602947805\n",
            "Fold: 2  model_num: 1\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.0079\n",
            "Epoch 00001: val_loss improved from inf to 0.31780, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 10s 152ms/step - loss: 2.0079 - val_loss: 0.3178\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4661\n",
            "Epoch 00002: val_loss improved from 0.31780 to 0.28190, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.4661 - val_loss: 0.2819\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3487\n",
            "Epoch 00003: val_loss improved from 0.28190 to 0.27758, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.3487 - val_loss: 0.2776\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2908\n",
            "Epoch 00004: val_loss improved from 0.27758 to 0.25591, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.2908 - val_loss: 0.2559\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2346\n",
            "Epoch 00005: val_loss improved from 0.25591 to 0.24944, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.2346 - val_loss: 0.2494\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1855\n",
            "Epoch 00006: val_loss improved from 0.24944 to 0.23884, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1855 - val_loss: 0.2388\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1371\n",
            "Epoch 00007: val_loss improved from 0.23884 to 0.23615, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 1.1371 - val_loss: 0.2361\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0982\n",
            "Epoch 00008: val_loss improved from 0.23615 to 0.22705, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0982 - val_loss: 0.2271\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0669\n",
            "Epoch 00009: val_loss improved from 0.22705 to 0.22624, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0669 - val_loss: 0.2262\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0419\n",
            "Epoch 00010: val_loss improved from 0.22624 to 0.21843, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.0419 - val_loss: 0.2184\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0113\n",
            "Epoch 00011: val_loss improved from 0.21843 to 0.21576, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0113 - val_loss: 0.2158\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9825\n",
            "Epoch 00012: val_loss improved from 0.21576 to 0.21506, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9825 - val_loss: 0.2151\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9677\n",
            "Epoch 00013: val_loss improved from 0.21506 to 0.20962, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9677 - val_loss: 0.2096\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9504\n",
            "Epoch 00014: val_loss did not improve from 0.20962\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9504 - val_loss: 0.2146\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9307\n",
            "Epoch 00015: val_loss improved from 0.20962 to 0.20681, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9307 - val_loss: 0.2068\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9191\n",
            "Epoch 00016: val_loss did not improve from 0.20681\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9191 - val_loss: 0.2069\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8993\n",
            "Epoch 00017: val_loss improved from 0.20681 to 0.20408, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8993 - val_loss: 0.2041\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8884\n",
            "Epoch 00018: val_loss improved from 0.20408 to 0.20361, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8884 - val_loss: 0.2036\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8754\n",
            "Epoch 00019: val_loss did not improve from 0.20361\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8754 - val_loss: 0.2118\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8642\n",
            "Epoch 00020: val_loss improved from 0.20361 to 0.20204, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8642 - val_loss: 0.2020\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8482\n",
            "Epoch 00021: val_loss improved from 0.20204 to 0.19941, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8482 - val_loss: 0.1994\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8371\n",
            "Epoch 00022: val_loss did not improve from 0.19941\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8371 - val_loss: 0.2005\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8247\n",
            "Epoch 00023: val_loss did not improve from 0.19941\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8247 - val_loss: 0.2003\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8117\n",
            "Epoch 00024: val_loss improved from 0.19941 to 0.19570, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8117 - val_loss: 0.1957\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8015\n",
            "Epoch 00025: val_loss did not improve from 0.19570\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8015 - val_loss: 0.1967\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7897\n",
            "Epoch 00026: val_loss did not improve from 0.19570\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7897 - val_loss: 0.1968\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7806\n",
            "Epoch 00027: val_loss did not improve from 0.19570\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7806 - val_loss: 0.1962\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7725\n",
            "Epoch 00028: val_loss improved from 0.19570 to 0.19367, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7725 - val_loss: 0.1937\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7618\n",
            "Epoch 00029: val_loss improved from 0.19367 to 0.19316, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7618 - val_loss: 0.1932\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7536\n",
            "Epoch 00030: val_loss improved from 0.19316 to 0.19186, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7536 - val_loss: 0.1919\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7439\n",
            "Epoch 00031: val_loss did not improve from 0.19186\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7439 - val_loss: 0.1922\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7371\n",
            "Epoch 00032: val_loss did not improve from 0.19186\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7371 - val_loss: 0.1954\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7288\n",
            "Epoch 00033: val_loss did not improve from 0.19186\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7288 - val_loss: 0.1928\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7225\n",
            "Epoch 00034: val_loss improved from 0.19186 to 0.19089, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7225 - val_loss: 0.1909\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7124\n",
            "Epoch 00035: val_loss did not improve from 0.19089\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7124 - val_loss: 0.1916\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7068\n",
            "Epoch 00036: val_loss improved from 0.19089 to 0.19069, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7068 - val_loss: 0.1907\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6989\n",
            "Epoch 00037: val_loss did not improve from 0.19069\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6989 - val_loss: 0.1925\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6915\n",
            "Epoch 00038: val_loss did not improve from 0.19069\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6915 - val_loss: 0.1911\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6846\n",
            "Epoch 00039: val_loss did not improve from 0.19069\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6846 - val_loss: 0.1925\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6761\n",
            "Epoch 00040: val_loss improved from 0.19069 to 0.18815, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6761 - val_loss: 0.1882\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6737\n",
            "Epoch 00041: val_loss did not improve from 0.18815\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6737 - val_loss: 0.1895\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6650\n",
            "Epoch 00042: val_loss did not improve from 0.18815\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6650 - val_loss: 0.1890\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6594\n",
            "Epoch 00043: val_loss did not improve from 0.18815\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6594 - val_loss: 0.1882\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6538\n",
            "Epoch 00044: val_loss improved from 0.18815 to 0.18795, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6538 - val_loss: 0.1880\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6502\n",
            "Epoch 00045: val_loss did not improve from 0.18795\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6502 - val_loss: 0.1889\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6423\n",
            "Epoch 00046: val_loss did not improve from 0.18795\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6423 - val_loss: 0.1894\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6380\n",
            "Epoch 00047: val_loss did not improve from 0.18795\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6380 - val_loss: 0.1912\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6328\n",
            "Epoch 00048: val_loss improved from 0.18795 to 0.18756, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6328 - val_loss: 0.1876\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6291\n",
            "Epoch 00049: val_loss did not improve from 0.18756\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6291 - val_loss: 0.1885\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6233\n",
            "Epoch 00050: val_loss did not improve from 0.18756\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6233 - val_loss: 0.1888\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6168\n",
            "Epoch 00051: val_loss did not improve from 0.18756\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6168 - val_loss: 0.1886\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6146\n",
            "Epoch 00052: val_loss did not improve from 0.18756\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6146 - val_loss: 0.1886\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6094\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.18756\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6094 - val_loss: 0.1885\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6035\n",
            "Epoch 00054: val_loss improved from 0.18756 to 0.18615, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6035 - val_loss: 0.1862\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5971\n",
            "Epoch 00055: val_loss did not improve from 0.18615\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5971 - val_loss: 0.1867\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5937\n",
            "Epoch 00056: val_loss did not improve from 0.18615\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5937 - val_loss: 0.1866\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5894\n",
            "Epoch 00057: val_loss did not improve from 0.18615\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5894 - val_loss: 0.1870\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5862\n",
            "Epoch 00058: val_loss did not improve from 0.18615\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5862 - val_loss: 0.1882\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5834\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.18615\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5834 - val_loss: 0.1873\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5771\n",
            "Epoch 00060: val_loss improved from 0.18615 to 0.18597, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5771 - val_loss: 0.1860\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5737\n",
            "Epoch 00061: val_loss improved from 0.18597 to 0.18573, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5737 - val_loss: 0.1857\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5719\n",
            "Epoch 00062: val_loss did not improve from 0.18573\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5719 - val_loss: 0.1863\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5680\n",
            "Epoch 00063: val_loss improved from 0.18573 to 0.18529, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5680 - val_loss: 0.1853\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5640\n",
            "Epoch 00064: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5640 - val_loss: 0.1872\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5618\n",
            "Epoch 00065: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5618 - val_loss: 0.1869\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5592\n",
            "Epoch 00066: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5592 - val_loss: 0.1857\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5576\n",
            "Epoch 00067: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5576 - val_loss: 0.1868\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5564\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5564 - val_loss: 0.1859\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5497\n",
            "Epoch 00069: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5497 - val_loss: 0.1867\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5452\n",
            "Epoch 00070: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5452 - val_loss: 0.1862\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5424\n",
            "Epoch 00071: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5424 - val_loss: 0.1870\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5409\n",
            "Epoch 00072: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5409 - val_loss: 0.1869\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5388\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5388 - val_loss: 0.1866\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5339\n",
            "Epoch 00074: val_loss did not improve from 0.18529\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5339 - val_loss: 0.1856\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5312\n",
            "Epoch 00075: val_loss improved from 0.18529 to 0.18513, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5312 - val_loss: 0.1851\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5303\n",
            "Epoch 00076: val_loss did not improve from 0.18513\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5303 - val_loss: 0.1860\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5274\n",
            "Epoch 00077: val_loss did not improve from 0.18513\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5274 - val_loss: 0.1858\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5259\n",
            "Epoch 00078: val_loss did not improve from 0.18513\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5259 - val_loss: 0.1870\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5243\n",
            "Epoch 00079: val_loss did not improve from 0.18513\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5243 - val_loss: 0.1870\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5226\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.18513\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5226 - val_loss: 0.1867\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5180\n",
            "Epoch 00081: val_loss improved from 0.18513 to 0.18481, saving model to gtn_aug_snr_2_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5180 - val_loss: 0.1848\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5157\n",
            "Epoch 00082: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5157 - val_loss: 0.1867\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5141\n",
            "Epoch 00083: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5141 - val_loss: 0.1853\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5125\n",
            "Epoch 00084: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5125 - val_loss: 0.1851\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5105\n",
            "Epoch 00085: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5105 - val_loss: 0.1857\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5107\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5107 - val_loss: 0.1857\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5078\n",
            "Epoch 00087: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5078 - val_loss: 0.1862\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5044\n",
            "Epoch 00088: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5044 - val_loss: 0.1858\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5033\n",
            "Epoch 00089: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5033 - val_loss: 0.1856\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5017\n",
            "Epoch 00090: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5017 - val_loss: 0.1860\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4999\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4999 - val_loss: 0.1862\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4961\n",
            "Epoch 00092: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4961 - val_loss: 0.1863\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4954\n",
            "Epoch 00093: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4954 - val_loss: 0.1852\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4941\n",
            "Epoch 00094: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4941 - val_loss: 0.1857\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4920\n",
            "Epoch 00095: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4920 - val_loss: 0.1861\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4916\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.18481\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4916 - val_loss: 0.1868\n",
            "Epoch 00096: early stopping\n",
            "reactivity  : 0.1800\n",
            "deg_Mg_pH10 : 0.2249\n",
            "deg_pH10    : 0.2104\n",
            "deg_Mg_50C  : 0.1929\n",
            "deg_50C     : 0.1890\n",
            "total: 0.19927705750438351\n",
            "Fold: 3  model_num: 1\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.9492\n",
            "Epoch 00001: val_loss improved from inf to 0.31038, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 10s 152ms/step - loss: 1.9492 - val_loss: 0.3104\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4500\n",
            "Epoch 00002: val_loss improved from 0.31038 to 0.28109, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.4500 - val_loss: 0.2811\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3351\n",
            "Epoch 00003: val_loss improved from 0.28109 to 0.26272, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.3351 - val_loss: 0.2627\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2816\n",
            "Epoch 00004: val_loss improved from 0.26272 to 0.25366, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.2816 - val_loss: 0.2537\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2275\n",
            "Epoch 00005: val_loss improved from 0.25366 to 0.24205, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.2275 - val_loss: 0.2420\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1722\n",
            "Epoch 00006: val_loss improved from 0.24205 to 0.23890, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1722 - val_loss: 0.2389\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1322\n",
            "Epoch 00007: val_loss improved from 0.23890 to 0.22957, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1322 - val_loss: 0.2296\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0908\n",
            "Epoch 00008: val_loss improved from 0.22957 to 0.22067, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0908 - val_loss: 0.2207\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0527\n",
            "Epoch 00009: val_loss improved from 0.22067 to 0.21956, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0527 - val_loss: 0.2196\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0261\n",
            "Epoch 00010: val_loss improved from 0.21956 to 0.21703, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0261 - val_loss: 0.2170\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9958\n",
            "Epoch 00011: val_loss improved from 0.21703 to 0.21249, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9958 - val_loss: 0.2125\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9784\n",
            "Epoch 00012: val_loss improved from 0.21249 to 0.21148, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9784 - val_loss: 0.2115\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9545\n",
            "Epoch 00013: val_loss improved from 0.21148 to 0.21034, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9545 - val_loss: 0.2103\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9390\n",
            "Epoch 00014: val_loss improved from 0.21034 to 0.20573, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9390 - val_loss: 0.2057\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9208\n",
            "Epoch 00015: val_loss did not improve from 0.20573\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9208 - val_loss: 0.2061\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9060\n",
            "Epoch 00016: val_loss improved from 0.20573 to 0.20406, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9060 - val_loss: 0.2041\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8920\n",
            "Epoch 00017: val_loss improved from 0.20406 to 0.20183, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8920 - val_loss: 0.2018\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8777\n",
            "Epoch 00018: val_loss did not improve from 0.20183\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8777 - val_loss: 0.2019\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8606\n",
            "Epoch 00019: val_loss improved from 0.20183 to 0.20057, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.8606 - val_loss: 0.2006\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8499\n",
            "Epoch 00020: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8499 - val_loss: 0.2013\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8381\n",
            "Epoch 00021: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8381 - val_loss: 0.2006\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8258\n",
            "Epoch 00022: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8258 - val_loss: 0.2051\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8139\n",
            "Epoch 00023: val_loss improved from 0.20057 to 0.20039, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8139 - val_loss: 0.2004\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8050\n",
            "Epoch 00024: val_loss improved from 0.20039 to 0.20029, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8050 - val_loss: 0.2003\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7913\n",
            "Epoch 00025: val_loss improved from 0.20029 to 0.19699, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7913 - val_loss: 0.1970\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7804\n",
            "Epoch 00026: val_loss improved from 0.19699 to 0.19679, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7804 - val_loss: 0.1968\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7719\n",
            "Epoch 00027: val_loss improved from 0.19679 to 0.19543, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7719 - val_loss: 0.1954\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7647\n",
            "Epoch 00028: val_loss did not improve from 0.19543\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7647 - val_loss: 0.1961\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7522\n",
            "Epoch 00029: val_loss did not improve from 0.19543\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7522 - val_loss: 0.1966\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7424\n",
            "Epoch 00030: val_loss did not improve from 0.19543\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7424 - val_loss: 0.1960\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7336\n",
            "Epoch 00031: val_loss did not improve from 0.19543\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7336 - val_loss: 0.1982\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7271\n",
            "Epoch 00032: val_loss improved from 0.19543 to 0.19500, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7271 - val_loss: 0.1950\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7189\n",
            "Epoch 00033: val_loss did not improve from 0.19500\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7189 - val_loss: 0.1959\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7110\n",
            "Epoch 00034: val_loss improved from 0.19500 to 0.19453, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.7110 - val_loss: 0.1945\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7042\n",
            "Epoch 00035: val_loss improved from 0.19453 to 0.19384, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.7042 - val_loss: 0.1938\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6976\n",
            "Epoch 00036: val_loss improved from 0.19384 to 0.19376, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.6976 - val_loss: 0.1938\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6892\n",
            "Epoch 00037: val_loss improved from 0.19376 to 0.19274, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6892 - val_loss: 0.1927\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6831\n",
            "Epoch 00038: val_loss did not improve from 0.19274\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6831 - val_loss: 0.1956\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6744\n",
            "Epoch 00039: val_loss did not improve from 0.19274\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6744 - val_loss: 0.1963\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6702\n",
            "Epoch 00040: val_loss did not improve from 0.19274\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6702 - val_loss: 0.1945\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6662\n",
            "Epoch 00041: val_loss did not improve from 0.19274\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6662 - val_loss: 0.1933\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6574\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.19274\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6574 - val_loss: 0.1956\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6496\n",
            "Epoch 00043: val_loss did not improve from 0.19274\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6496 - val_loss: 0.1934\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6435\n",
            "Epoch 00044: val_loss improved from 0.19274 to 0.19256, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6435 - val_loss: 0.1926\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6376\n",
            "Epoch 00045: val_loss improved from 0.19256 to 0.19232, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6376 - val_loss: 0.1923\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6324\n",
            "Epoch 00046: val_loss improved from 0.19232 to 0.19074, saving model to gtn_aug_snr_3_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6324 - val_loss: 0.1907\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6280\n",
            "Epoch 00047: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6280 - val_loss: 0.1920\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6233\n",
            "Epoch 00048: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6233 - val_loss: 0.1917\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6201\n",
            "Epoch 00049: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6201 - val_loss: 0.1924\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6145\n",
            "Epoch 00050: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6145 - val_loss: 0.1918\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6098\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6098 - val_loss: 0.1917\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6040\n",
            "Epoch 00052: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6040 - val_loss: 0.1930\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5999\n",
            "Epoch 00053: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5999 - val_loss: 0.1921\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5964\n",
            "Epoch 00054: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5964 - val_loss: 0.1916\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5923\n",
            "Epoch 00055: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5923 - val_loss: 0.1915\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5899\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5899 - val_loss: 0.1937\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5839\n",
            "Epoch 00057: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5839 - val_loss: 0.1913\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5795\n",
            "Epoch 00058: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5795 - val_loss: 0.1911\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5771\n",
            "Epoch 00059: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5771 - val_loss: 0.1917\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5724\n",
            "Epoch 00060: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5724 - val_loss: 0.1908\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5715\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.19074\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5715 - val_loss: 0.1910\n",
            "Epoch 00061: early stopping\n",
            "reactivity  : 0.1827\n",
            "deg_Mg_pH10 : 0.2413\n",
            "deg_pH10    : 0.2144\n",
            "deg_Mg_50C  : 0.1949\n",
            "deg_50C     : 0.1852\n",
            "total: 0.2063018762377805\n",
            "Fold: 4  model_num: 1\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.9853\n",
            "Epoch 00001: val_loss improved from inf to 0.33557, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 12s 179ms/step - loss: 1.9853 - val_loss: 0.3356\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4480\n",
            "Epoch 00002: val_loss improved from 0.33557 to 0.29566, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.4480 - val_loss: 0.2957\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3297\n",
            "Epoch 00003: val_loss improved from 0.29566 to 0.28348, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.3297 - val_loss: 0.2835\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2752\n",
            "Epoch 00004: val_loss improved from 0.28348 to 0.28170, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.2752 - val_loss: 0.2817\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2256\n",
            "Epoch 00005: val_loss improved from 0.28170 to 0.26981, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 1.2256 - val_loss: 0.2698\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1654\n",
            "Epoch 00006: val_loss improved from 0.26981 to 0.25926, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1654 - val_loss: 0.2593\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1169\n",
            "Epoch 00007: val_loss improved from 0.25926 to 0.25055, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1169 - val_loss: 0.2505\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0705\n",
            "Epoch 00008: val_loss improved from 0.25055 to 0.24745, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0705 - val_loss: 0.2475\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0350\n",
            "Epoch 00009: val_loss improved from 0.24745 to 0.23832, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 1.0350 - val_loss: 0.2383\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0083\n",
            "Epoch 00010: val_loss improved from 0.23832 to 0.23593, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0083 - val_loss: 0.2359\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9857\n",
            "Epoch 00011: val_loss improved from 0.23593 to 0.23219, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9857 - val_loss: 0.2322\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9643\n",
            "Epoch 00012: val_loss improved from 0.23219 to 0.23180, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9643 - val_loss: 0.2318\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9483\n",
            "Epoch 00013: val_loss did not improve from 0.23180\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9483 - val_loss: 0.2319\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9317\n",
            "Epoch 00014: val_loss improved from 0.23180 to 0.22755, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9317 - val_loss: 0.2275\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9134\n",
            "Epoch 00015: val_loss improved from 0.22755 to 0.22575, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9134 - val_loss: 0.2257\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9050\n",
            "Epoch 00016: val_loss improved from 0.22575 to 0.22524, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9050 - val_loss: 0.2252\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8859\n",
            "Epoch 00017: val_loss improved from 0.22524 to 0.22127, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.8859 - val_loss: 0.2213\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8709\n",
            "Epoch 00018: val_loss did not improve from 0.22127\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8709 - val_loss: 0.2216\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8607\n",
            "Epoch 00019: val_loss did not improve from 0.22127\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8607 - val_loss: 0.2233\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8477\n",
            "Epoch 00020: val_loss did not improve from 0.22127\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8477 - val_loss: 0.2233\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8351\n",
            "Epoch 00021: val_loss did not improve from 0.22127\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8351 - val_loss: 0.2225\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8248\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.22127\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8248 - val_loss: 0.2215\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8094\n",
            "Epoch 00023: val_loss improved from 0.22127 to 0.21842, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8094 - val_loss: 0.2184\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7968\n",
            "Epoch 00024: val_loss improved from 0.21842 to 0.21612, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7968 - val_loss: 0.2161\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7892\n",
            "Epoch 00025: val_loss did not improve from 0.21612\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7892 - val_loss: 0.2172\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7803\n",
            "Epoch 00026: val_loss improved from 0.21612 to 0.21538, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7803 - val_loss: 0.2154\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7715\n",
            "Epoch 00027: val_loss did not improve from 0.21538\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7715 - val_loss: 0.2164\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7634\n",
            "Epoch 00028: val_loss improved from 0.21538 to 0.21489, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7634 - val_loss: 0.2149\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7533\n",
            "Epoch 00029: val_loss improved from 0.21489 to 0.21395, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7533 - val_loss: 0.2140\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7455\n",
            "Epoch 00030: val_loss did not improve from 0.21395\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7455 - val_loss: 0.2142\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7350\n",
            "Epoch 00031: val_loss did not improve from 0.21395\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7350 - val_loss: 0.2142\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7305\n",
            "Epoch 00032: val_loss did not improve from 0.21395\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7305 - val_loss: 0.2147\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7212\n",
            "Epoch 00033: val_loss improved from 0.21395 to 0.21323, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7212 - val_loss: 0.2132\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7130\n",
            "Epoch 00034: val_loss improved from 0.21323 to 0.21237, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7130 - val_loss: 0.2124\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7080\n",
            "Epoch 00035: val_loss improved from 0.21237 to 0.21130, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7080 - val_loss: 0.2113\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7028\n",
            "Epoch 00036: val_loss did not improve from 0.21130\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7028 - val_loss: 0.2130\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6931\n",
            "Epoch 00037: val_loss did not improve from 0.21130\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6931 - val_loss: 0.2118\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6876\n",
            "Epoch 00038: val_loss did not improve from 0.21130\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6876 - val_loss: 0.2125\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6813\n",
            "Epoch 00039: val_loss did not improve from 0.21130\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6813 - val_loss: 0.2117\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6742\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.21130\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6742 - val_loss: 0.2124\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6660\n",
            "Epoch 00041: val_loss improved from 0.21130 to 0.21051, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6660 - val_loss: 0.2105\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6602\n",
            "Epoch 00042: val_loss improved from 0.21051 to 0.21017, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6602 - val_loss: 0.2102\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6555\n",
            "Epoch 00043: val_loss did not improve from 0.21017\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6555 - val_loss: 0.2128\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6504\n",
            "Epoch 00044: val_loss did not improve from 0.21017\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6504 - val_loss: 0.2124\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6451\n",
            "Epoch 00045: val_loss did not improve from 0.21017\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6451 - val_loss: 0.2113\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6421\n",
            "Epoch 00046: val_loss did not improve from 0.21017\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6421 - val_loss: 0.2112\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6359\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.21017 to 0.21008, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6359 - val_loss: 0.2101\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6289\n",
            "Epoch 00048: val_loss improved from 0.21008 to 0.21004, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6289 - val_loss: 0.2100\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6239\n",
            "Epoch 00049: val_loss did not improve from 0.21004\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6239 - val_loss: 0.2110\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6209\n",
            "Epoch 00050: val_loss did not improve from 0.21004\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6209 - val_loss: 0.2113\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6179\n",
            "Epoch 00051: val_loss did not improve from 0.21004\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6179 - val_loss: 0.2105\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6140\n",
            "Epoch 00052: val_loss improved from 0.21004 to 0.20985, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6140 - val_loss: 0.2099\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6111\n",
            "Epoch 00053: val_loss did not improve from 0.20985\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6111 - val_loss: 0.2100\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6045\n",
            "Epoch 00054: val_loss did not improve from 0.20985\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6045 - val_loss: 0.2111\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6014\n",
            "Epoch 00055: val_loss did not improve from 0.20985\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6014 - val_loss: 0.2102\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5995\n",
            "Epoch 00056: val_loss did not improve from 0.20985\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5995 - val_loss: 0.2109\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5959\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.20985\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5959 - val_loss: 0.2110\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5896\n",
            "Epoch 00058: val_loss did not improve from 0.20985\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5896 - val_loss: 0.2099\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5853\n",
            "Epoch 00059: val_loss did not improve from 0.20985\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5853 - val_loss: 0.2110\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5826\n",
            "Epoch 00060: val_loss did not improve from 0.20985\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5826 - val_loss: 0.2106\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5793\n",
            "Epoch 00061: val_loss improved from 0.20985 to 0.20937, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.5793 - val_loss: 0.2094\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5755\n",
            "Epoch 00062: val_loss did not improve from 0.20937\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5755 - val_loss: 0.2097\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5742\n",
            "Epoch 00063: val_loss did not improve from 0.20937\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5742 - val_loss: 0.2111\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5713\n",
            "Epoch 00064: val_loss did not improve from 0.20937\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5713 - val_loss: 0.2108\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5689\n",
            "Epoch 00065: val_loss did not improve from 0.20937\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5689 - val_loss: 0.2101\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5673\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.20937\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5673 - val_loss: 0.2101\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5623\n",
            "Epoch 00067: val_loss did not improve from 0.20937\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5623 - val_loss: 0.2104\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5594\n",
            "Epoch 00068: val_loss did not improve from 0.20937\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5594 - val_loss: 0.2104\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5565\n",
            "Epoch 00069: val_loss improved from 0.20937 to 0.20933, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.5565 - val_loss: 0.2093\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5543\n",
            "Epoch 00070: val_loss improved from 0.20933 to 0.20923, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5543 - val_loss: 0.2092\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5507\n",
            "Epoch 00071: val_loss did not improve from 0.20923\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5507 - val_loss: 0.2114\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5497\n",
            "Epoch 00072: val_loss did not improve from 0.20923\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5497 - val_loss: 0.2097\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5472\n",
            "Epoch 00073: val_loss did not improve from 0.20923\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5472 - val_loss: 0.2096\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5463\n",
            "Epoch 00074: val_loss did not improve from 0.20923\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5463 - val_loss: 0.2107\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5431\n",
            "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.20923\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5431 - val_loss: 0.2100\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5393\n",
            "Epoch 00076: val_loss improved from 0.20923 to 0.20915, saving model to gtn_aug_snr_4_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5393 - val_loss: 0.2092\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5368\n",
            "Epoch 00077: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5368 - val_loss: 0.2102\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5341\n",
            "Epoch 00078: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5341 - val_loss: 0.2104\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5327\n",
            "Epoch 00079: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5327 - val_loss: 0.2092\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5299\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5299 - val_loss: 0.2103\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5274\n",
            "Epoch 00081: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5274 - val_loss: 0.2101\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5258\n",
            "Epoch 00082: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5258 - val_loss: 0.2108\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5229\n",
            "Epoch 00083: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5229 - val_loss: 0.2102\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5218\n",
            "Epoch 00084: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5218 - val_loss: 0.2102\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5208\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5208 - val_loss: 0.2106\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5179\n",
            "Epoch 00086: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5179 - val_loss: 0.2110\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5155\n",
            "Epoch 00087: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5155 - val_loss: 0.2107\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5129\n",
            "Epoch 00088: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5129 - val_loss: 0.2104\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5129\n",
            "Epoch 00089: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5129 - val_loss: 0.2098\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5108\n",
            "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5108 - val_loss: 0.2101\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5081\n",
            "Epoch 00091: val_loss did not improve from 0.20915\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5081 - val_loss: 0.2098\n",
            "Epoch 00091: early stopping\n",
            "reactivity  : 0.2078\n",
            "deg_Mg_pH10 : 0.2716\n",
            "deg_pH10    : 0.2527\n",
            "deg_Mg_50C  : 0.2188\n",
            "deg_50C     : 0.2056\n",
            "total: 0.2327285362093761\n",
            "Fold: 5  model_num: 1\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.8960\n",
            "Epoch 00001: val_loss improved from inf to 0.32097, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 10s 153ms/step - loss: 1.8960 - val_loss: 0.3210\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4440\n",
            "Epoch 00002: val_loss improved from 0.32097 to 0.30197, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 1.4440 - val_loss: 0.3020\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3341\n",
            "Epoch 00003: val_loss improved from 0.30197 to 0.28192, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.3341 - val_loss: 0.2819\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2792\n",
            "Epoch 00004: val_loss improved from 0.28192 to 0.26792, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.2792 - val_loss: 0.2679\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2228\n",
            "Epoch 00005: val_loss improved from 0.26792 to 0.25477, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.2228 - val_loss: 0.2548\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1670\n",
            "Epoch 00006: val_loss improved from 0.25477 to 0.24523, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 1.1670 - val_loss: 0.2452\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1153\n",
            "Epoch 00007: val_loss improved from 0.24523 to 0.23823, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1153 - val_loss: 0.2382\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0767\n",
            "Epoch 00008: val_loss improved from 0.23823 to 0.23612, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0767 - val_loss: 0.2361\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0444\n",
            "Epoch 00009: val_loss improved from 0.23612 to 0.22990, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0444 - val_loss: 0.2299\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0136\n",
            "Epoch 00010: val_loss improved from 0.22990 to 0.22622, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 1.0136 - val_loss: 0.2262\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9892\n",
            "Epoch 00011: val_loss did not improve from 0.22622\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9892 - val_loss: 0.2269\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9740\n",
            "Epoch 00012: val_loss improved from 0.22622 to 0.22245, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9740 - val_loss: 0.2225\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9462\n",
            "Epoch 00013: val_loss did not improve from 0.22245\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9462 - val_loss: 0.2245\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9302\n",
            "Epoch 00014: val_loss improved from 0.22245 to 0.21697, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9302 - val_loss: 0.2170\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9146\n",
            "Epoch 00015: val_loss improved from 0.21697 to 0.21544, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9146 - val_loss: 0.2154\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8994\n",
            "Epoch 00016: val_loss improved from 0.21544 to 0.21445, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8994 - val_loss: 0.2145\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8843\n",
            "Epoch 00017: val_loss did not improve from 0.21445\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8843 - val_loss: 0.2170\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8669\n",
            "Epoch 00018: val_loss improved from 0.21445 to 0.21140, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8669 - val_loss: 0.2114\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8540\n",
            "Epoch 00019: val_loss did not improve from 0.21140\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8540 - val_loss: 0.2123\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8417\n",
            "Epoch 00020: val_loss improved from 0.21140 to 0.20988, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8417 - val_loss: 0.2099\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8314\n",
            "Epoch 00021: val_loss improved from 0.20988 to 0.20969, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8314 - val_loss: 0.2097\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8164\n",
            "Epoch 00022: val_loss improved from 0.20969 to 0.20732, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.8164 - val_loss: 0.2073\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8035\n",
            "Epoch 00023: val_loss improved from 0.20732 to 0.20713, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8035 - val_loss: 0.2071\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7919\n",
            "Epoch 00024: val_loss did not improve from 0.20713\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7919 - val_loss: 0.2081\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7805\n",
            "Epoch 00025: val_loss did not improve from 0.20713\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7805 - val_loss: 0.2080\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7742\n",
            "Epoch 00026: val_loss improved from 0.20713 to 0.20565, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7742 - val_loss: 0.2057\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7610\n",
            "Epoch 00027: val_loss did not improve from 0.20565\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7610 - val_loss: 0.2082\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7530\n",
            "Epoch 00028: val_loss improved from 0.20565 to 0.20398, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7530 - val_loss: 0.2040\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7451\n",
            "Epoch 00029: val_loss did not improve from 0.20398\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7451 - val_loss: 0.2051\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7363\n",
            "Epoch 00030: val_loss did not improve from 0.20398\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7363 - val_loss: 0.2045\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7251\n",
            "Epoch 00031: val_loss improved from 0.20398 to 0.20376, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7251 - val_loss: 0.2038\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7152\n",
            "Epoch 00032: val_loss improved from 0.20376 to 0.20308, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7152 - val_loss: 0.2031\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7079\n",
            "Epoch 00033: val_loss improved from 0.20308 to 0.20302, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7079 - val_loss: 0.2030\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7001\n",
            "Epoch 00034: val_loss improved from 0.20302 to 0.20266, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.7001 - val_loss: 0.2027\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6952\n",
            "Epoch 00035: val_loss did not improve from 0.20266\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6952 - val_loss: 0.2029\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6887\n",
            "Epoch 00036: val_loss improved from 0.20266 to 0.20239, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6887 - val_loss: 0.2024\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6832\n",
            "Epoch 00037: val_loss improved from 0.20239 to 0.20201, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6832 - val_loss: 0.2020\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6747\n",
            "Epoch 00038: val_loss did not improve from 0.20201\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6747 - val_loss: 0.2026\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6688\n",
            "Epoch 00039: val_loss did not improve from 0.20201\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6688 - val_loss: 0.2029\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6621\n",
            "Epoch 00040: val_loss improved from 0.20201 to 0.20108, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6621 - val_loss: 0.2011\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6564\n",
            "Epoch 00041: val_loss did not improve from 0.20108\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6564 - val_loss: 0.2021\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6507\n",
            "Epoch 00042: val_loss did not improve from 0.20108\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6507 - val_loss: 0.2020\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6451\n",
            "Epoch 00043: val_loss did not improve from 0.20108\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6451 - val_loss: 0.2018\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6394\n",
            "Epoch 00044: val_loss did not improve from 0.20108\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6394 - val_loss: 0.2012\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6358\n",
            "Epoch 00045: val_loss improved from 0.20108 to 0.19952, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.6358 - val_loss: 0.1995\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6332\n",
            "Epoch 00046: val_loss did not improve from 0.19952\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6332 - val_loss: 0.2001\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6257\n",
            "Epoch 00047: val_loss improved from 0.19952 to 0.19841, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6257 - val_loss: 0.1984\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6211\n",
            "Epoch 00048: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6211 - val_loss: 0.2020\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6166\n",
            "Epoch 00049: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6166 - val_loss: 0.1988\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6122\n",
            "Epoch 00050: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6122 - val_loss: 0.1992\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6050\n",
            "Epoch 00051: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6050 - val_loss: 0.1994\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6004\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6004 - val_loss: 0.1996\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5948\n",
            "Epoch 00053: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5948 - val_loss: 0.2001\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5916\n",
            "Epoch 00054: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5916 - val_loss: 0.1989\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5876\n",
            "Epoch 00055: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5876 - val_loss: 0.1987\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5811\n",
            "Epoch 00056: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5811 - val_loss: 0.1990\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5803\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5803 - val_loss: 0.1992\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5740\n",
            "Epoch 00058: val_loss did not improve from 0.19841\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5740 - val_loss: 0.1990\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5710\n",
            "Epoch 00059: val_loss improved from 0.19841 to 0.19787, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5710 - val_loss: 0.1979\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5658\n",
            "Epoch 00060: val_loss did not improve from 0.19787\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5658 - val_loss: 0.1992\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5632\n",
            "Epoch 00061: val_loss did not improve from 0.19787\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5632 - val_loss: 0.1994\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5602\n",
            "Epoch 00062: val_loss did not improve from 0.19787\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5602 - val_loss: 0.1985\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5576\n",
            "Epoch 00063: val_loss did not improve from 0.19787\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5576 - val_loss: 0.1982\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5552\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.19787\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5552 - val_loss: 0.1986\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5505\n",
            "Epoch 00065: val_loss improved from 0.19787 to 0.19785, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5505 - val_loss: 0.1978\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5480\n",
            "Epoch 00066: val_loss did not improve from 0.19785\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5480 - val_loss: 0.1984\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5455\n",
            "Epoch 00067: val_loss improved from 0.19785 to 0.19687, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5455 - val_loss: 0.1969\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5429\n",
            "Epoch 00068: val_loss did not improve from 0.19687\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5429 - val_loss: 0.1970\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5402\n",
            "Epoch 00069: val_loss improved from 0.19687 to 0.19672, saving model to gtn_aug_snr_5_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5402 - val_loss: 0.1967\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5376\n",
            "Epoch 00070: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5376 - val_loss: 0.1989\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5354\n",
            "Epoch 00071: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5354 - val_loss: 0.1987\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5346\n",
            "Epoch 00072: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5346 - val_loss: 0.1980\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5317\n",
            "Epoch 00073: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5317 - val_loss: 0.1985\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5299\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5299 - val_loss: 0.1974\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5258\n",
            "Epoch 00075: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5258 - val_loss: 0.1975\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5233\n",
            "Epoch 00076: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5233 - val_loss: 0.1978\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5219\n",
            "Epoch 00077: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5219 - val_loss: 0.1981\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5187\n",
            "Epoch 00078: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.5187 - val_loss: 0.1977\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5166\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5166 - val_loss: 0.1974\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5129\n",
            "Epoch 00080: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5129 - val_loss: 0.1971\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5107\n",
            "Epoch 00081: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5107 - val_loss: 0.1981\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5094\n",
            "Epoch 00082: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5094 - val_loss: 0.1986\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5081\n",
            "Epoch 00083: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5081 - val_loss: 0.1976\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5050\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.19672\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5050 - val_loss: 0.1977\n",
            "Epoch 00084: early stopping\n",
            "reactivity  : 0.1951\n",
            "deg_Mg_pH10 : 0.2433\n",
            "deg_pH10    : 0.2270\n",
            "deg_Mg_50C  : 0.2024\n",
            "deg_50C     : 0.1990\n",
            "total: 0.2136115146450338\n",
            "Fold: 6  model_num: 1\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.8986\n",
            "Epoch 00001: val_loss improved from inf to 0.31193, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 10s 154ms/step - loss: 1.8986 - val_loss: 0.3119\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4220\n",
            "Epoch 00002: val_loss improved from 0.31193 to 0.27594, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.4220 - val_loss: 0.2759\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3184\n",
            "Epoch 00003: val_loss improved from 0.27594 to 0.26309, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.3184 - val_loss: 0.2631\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2648\n",
            "Epoch 00004: val_loss improved from 0.26309 to 0.25475, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.2648 - val_loss: 0.2547\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2000\n",
            "Epoch 00005: val_loss improved from 0.25475 to 0.24255, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 1.2000 - val_loss: 0.2425\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1508\n",
            "Epoch 00006: val_loss improved from 0.24255 to 0.23448, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1508 - val_loss: 0.2345\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1008\n",
            "Epoch 00007: val_loss improved from 0.23448 to 0.23015, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1008 - val_loss: 0.2302\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0645\n",
            "Epoch 00008: val_loss improved from 0.23015 to 0.22339, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0645 - val_loss: 0.2234\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0305\n",
            "Epoch 00009: val_loss improved from 0.22339 to 0.22256, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0305 - val_loss: 0.2226\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0070\n",
            "Epoch 00010: val_loss improved from 0.22256 to 0.22071, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0070 - val_loss: 0.2207\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9821\n",
            "Epoch 00011: val_loss improved from 0.22071 to 0.21453, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.9821 - val_loss: 0.2145\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9589\n",
            "Epoch 00012: val_loss improved from 0.21453 to 0.21236, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9589 - val_loss: 0.2124\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9412\n",
            "Epoch 00013: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9412 - val_loss: 0.2125\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9247\n",
            "Epoch 00014: val_loss improved from 0.21236 to 0.20779, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9247 - val_loss: 0.2078\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9099\n",
            "Epoch 00015: val_loss did not improve from 0.20779\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9099 - val_loss: 0.2125\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8954\n",
            "Epoch 00016: val_loss improved from 0.20779 to 0.20602, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8954 - val_loss: 0.2060\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8798\n",
            "Epoch 00017: val_loss improved from 0.20602 to 0.20545, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.8798 - val_loss: 0.2054\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8637\n",
            "Epoch 00018: val_loss improved from 0.20545 to 0.20358, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8637 - val_loss: 0.2036\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8506\n",
            "Epoch 00019: val_loss did not improve from 0.20358\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8506 - val_loss: 0.2050\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8407\n",
            "Epoch 00020: val_loss improved from 0.20358 to 0.20265, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8407 - val_loss: 0.2027\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8258\n",
            "Epoch 00021: val_loss did not improve from 0.20265\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8258 - val_loss: 0.2032\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8180\n",
            "Epoch 00022: val_loss did not improve from 0.20265\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8180 - val_loss: 0.2033\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8042\n",
            "Epoch 00023: val_loss improved from 0.20265 to 0.20083, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8042 - val_loss: 0.2008\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7914\n",
            "Epoch 00024: val_loss did not improve from 0.20083\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7914 - val_loss: 0.2021\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7807\n",
            "Epoch 00025: val_loss improved from 0.20083 to 0.19900, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.7807 - val_loss: 0.1990\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7713\n",
            "Epoch 00026: val_loss did not improve from 0.19900\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7713 - val_loss: 0.1993\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7617\n",
            "Epoch 00027: val_loss did not improve from 0.19900\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7617 - val_loss: 0.2014\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7522\n",
            "Epoch 00028: val_loss improved from 0.19900 to 0.19869, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7522 - val_loss: 0.1987\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7431\n",
            "Epoch 00029: val_loss did not improve from 0.19869\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7431 - val_loss: 0.1993\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7349\n",
            "Epoch 00030: val_loss did not improve from 0.19869\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7349 - val_loss: 0.1995\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7250\n",
            "Epoch 00031: val_loss did not improve from 0.19869\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7250 - val_loss: 0.2021\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7179\n",
            "Epoch 00032: val_loss improved from 0.19869 to 0.19759, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7179 - val_loss: 0.1976\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7110\n",
            "Epoch 00033: val_loss did not improve from 0.19759\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7110 - val_loss: 0.1987\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7043\n",
            "Epoch 00034: val_loss did not improve from 0.19759\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7043 - val_loss: 0.1995\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6948\n",
            "Epoch 00035: val_loss improved from 0.19759 to 0.19701, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6948 - val_loss: 0.1970\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6875\n",
            "Epoch 00036: val_loss did not improve from 0.19701\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6875 - val_loss: 0.1976\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6830\n",
            "Epoch 00037: val_loss did not improve from 0.19701\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6830 - val_loss: 0.1988\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6795\n",
            "Epoch 00038: val_loss did not improve from 0.19701\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6795 - val_loss: 0.2000\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6696\n",
            "Epoch 00039: val_loss improved from 0.19701 to 0.19674, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6696 - val_loss: 0.1967\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6634\n",
            "Epoch 00040: val_loss improved from 0.19674 to 0.19647, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6634 - val_loss: 0.1965\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6576\n",
            "Epoch 00041: val_loss did not improve from 0.19647\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6576 - val_loss: 0.1982\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6507\n",
            "Epoch 00042: val_loss improved from 0.19647 to 0.19605, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6507 - val_loss: 0.1961\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6452\n",
            "Epoch 00043: val_loss improved from 0.19605 to 0.19543, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6452 - val_loss: 0.1954\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6393\n",
            "Epoch 00044: val_loss did not improve from 0.19543\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6393 - val_loss: 0.1963\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6363\n",
            "Epoch 00045: val_loss improved from 0.19543 to 0.19530, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.6363 - val_loss: 0.1953\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6319\n",
            "Epoch 00046: val_loss did not improve from 0.19530\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6319 - val_loss: 0.1958\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6256\n",
            "Epoch 00047: val_loss did not improve from 0.19530\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6256 - val_loss: 0.1970\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6217\n",
            "Epoch 00048: val_loss improved from 0.19530 to 0.19361, saving model to gtn_aug_snr_6_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6217 - val_loss: 0.1936\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6177\n",
            "Epoch 00049: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6177 - val_loss: 0.1955\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6116\n",
            "Epoch 00050: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6116 - val_loss: 0.1965\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6093\n",
            "Epoch 00051: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6093 - val_loss: 0.1965\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6031\n",
            "Epoch 00052: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6031 - val_loss: 0.1953\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5997\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5997 - val_loss: 0.1956\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5934\n",
            "Epoch 00054: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5934 - val_loss: 0.1942\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5864\n",
            "Epoch 00055: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5864 - val_loss: 0.1941\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5839\n",
            "Epoch 00056: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5839 - val_loss: 0.1958\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5821\n",
            "Epoch 00057: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5821 - val_loss: 0.1943\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5761\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5761 - val_loss: 0.1955\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5721\n",
            "Epoch 00059: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5721 - val_loss: 0.1955\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5676\n",
            "Epoch 00060: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5676 - val_loss: 0.1950\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5647\n",
            "Epoch 00061: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5647 - val_loss: 0.1953\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5626\n",
            "Epoch 00062: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5626 - val_loss: 0.1944\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5584\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.19361\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5584 - val_loss: 0.1966\n",
            "Epoch 00063: early stopping\n",
            "reactivity  : 0.1929\n",
            "deg_Mg_pH10 : 0.2358\n",
            "deg_pH10    : 0.2231\n",
            "deg_Mg_50C  : 0.1964\n",
            "deg_50C     : 0.1955\n",
            "total: 0.20835369201866266\n",
            "Fold: 7  model_num: 1\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.8907\n",
            "Epoch 00001: val_loss improved from inf to 0.32715, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 10s 153ms/step - loss: 1.8907 - val_loss: 0.3272\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4428\n",
            "Epoch 00002: val_loss improved from 0.32715 to 0.29118, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.4428 - val_loss: 0.2912\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3396\n",
            "Epoch 00003: val_loss improved from 0.29118 to 0.27779, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.3396 - val_loss: 0.2778\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2749\n",
            "Epoch 00004: val_loss improved from 0.27779 to 0.26893, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.2749 - val_loss: 0.2689\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2149\n",
            "Epoch 00005: val_loss improved from 0.26893 to 0.25570, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 1.2149 - val_loss: 0.2557\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1597\n",
            "Epoch 00006: val_loss improved from 0.25570 to 0.24656, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1597 - val_loss: 0.2466\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1162\n",
            "Epoch 00007: val_loss improved from 0.24656 to 0.23992, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1162 - val_loss: 0.2399\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0763\n",
            "Epoch 00008: val_loss improved from 0.23992 to 0.23350, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0763 - val_loss: 0.2335\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0365\n",
            "Epoch 00009: val_loss improved from 0.23350 to 0.23047, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0365 - val_loss: 0.2305\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0121\n",
            "Epoch 00010: val_loss improved from 0.23047 to 0.22665, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0121 - val_loss: 0.2267\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9855\n",
            "Epoch 00011: val_loss improved from 0.22665 to 0.22333, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9855 - val_loss: 0.2233\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9633\n",
            "Epoch 00012: val_loss improved from 0.22333 to 0.22045, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9633 - val_loss: 0.2204\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9472\n",
            "Epoch 00013: val_loss did not improve from 0.22045\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9472 - val_loss: 0.2258\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9307\n",
            "Epoch 00014: val_loss did not improve from 0.22045\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9307 - val_loss: 0.2215\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9116\n",
            "Epoch 00015: val_loss improved from 0.22045 to 0.21867, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9116 - val_loss: 0.2187\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8979\n",
            "Epoch 00016: val_loss improved from 0.21867 to 0.21551, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8979 - val_loss: 0.2155\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8812\n",
            "Epoch 00017: val_loss did not improve from 0.21551\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8812 - val_loss: 0.2168\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8662\n",
            "Epoch 00018: val_loss improved from 0.21551 to 0.21288, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8662 - val_loss: 0.2129\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8497\n",
            "Epoch 00019: val_loss did not improve from 0.21288\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8497 - val_loss: 0.2129\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8381\n",
            "Epoch 00020: val_loss improved from 0.21288 to 0.21198, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8381 - val_loss: 0.2120\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8274\n",
            "Epoch 00021: val_loss improved from 0.21198 to 0.21154, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8274 - val_loss: 0.2115\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8153\n",
            "Epoch 00022: val_loss improved from 0.21154 to 0.21051, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8153 - val_loss: 0.2105\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8018\n",
            "Epoch 00023: val_loss improved from 0.21051 to 0.21042, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8018 - val_loss: 0.2104\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7915\n",
            "Epoch 00024: val_loss did not improve from 0.21042\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7915 - val_loss: 0.2114\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7808\n",
            "Epoch 00025: val_loss improved from 0.21042 to 0.20794, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.7808 - val_loss: 0.2079\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7706\n",
            "Epoch 00026: val_loss did not improve from 0.20794\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7706 - val_loss: 0.2090\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7595\n",
            "Epoch 00027: val_loss did not improve from 0.20794\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7595 - val_loss: 0.2080\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7499\n",
            "Epoch 00028: val_loss did not improve from 0.20794\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7499 - val_loss: 0.2083\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7420\n",
            "Epoch 00029: val_loss improved from 0.20794 to 0.20772, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.7420 - val_loss: 0.2077\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7326\n",
            "Epoch 00030: val_loss improved from 0.20772 to 0.20579, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7326 - val_loss: 0.2058\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7238\n",
            "Epoch 00031: val_loss did not improve from 0.20579\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7238 - val_loss: 0.2068\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7172\n",
            "Epoch 00032: val_loss did not improve from 0.20579\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7172 - val_loss: 0.2068\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7093\n",
            "Epoch 00033: val_loss did not improve from 0.20579\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7093 - val_loss: 0.2069\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7032\n",
            "Epoch 00034: val_loss did not improve from 0.20579\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7032 - val_loss: 0.2084\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6957\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.20579\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6957 - val_loss: 0.2072\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6859\n",
            "Epoch 00036: val_loss did not improve from 0.20579\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6859 - val_loss: 0.2060\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6763\n",
            "Epoch 00037: val_loss did not improve from 0.20579\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6763 - val_loss: 0.2069\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6708\n",
            "Epoch 00038: val_loss improved from 0.20579 to 0.20455, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6708 - val_loss: 0.2045\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6660\n",
            "Epoch 00039: val_loss did not improve from 0.20455\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6660 - val_loss: 0.2056\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6603\n",
            "Epoch 00040: val_loss did not improve from 0.20455\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6603 - val_loss: 0.2046\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6551\n",
            "Epoch 00041: val_loss improved from 0.20455 to 0.20414, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6551 - val_loss: 0.2041\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6486\n",
            "Epoch 00042: val_loss did not improve from 0.20414\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6486 - val_loss: 0.2061\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6429\n",
            "Epoch 00043: val_loss did not improve from 0.20414\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6429 - val_loss: 0.2052\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6382\n",
            "Epoch 00044: val_loss did not improve from 0.20414\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6382 - val_loss: 0.2053\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6340\n",
            "Epoch 00045: val_loss did not improve from 0.20414\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6340 - val_loss: 0.2054\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6292\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.20414\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6292 - val_loss: 0.2045\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6223\n",
            "Epoch 00047: val_loss improved from 0.20414 to 0.20291, saving model to gtn_aug_snr_7_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6223 - val_loss: 0.2029\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6174\n",
            "Epoch 00048: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6174 - val_loss: 0.2044\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6146\n",
            "Epoch 00049: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6146 - val_loss: 0.2054\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6093\n",
            "Epoch 00050: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6093 - val_loss: 0.2043\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6058\n",
            "Epoch 00051: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6058 - val_loss: 0.2042\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6015\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6015 - val_loss: 0.2036\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5943\n",
            "Epoch 00053: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5943 - val_loss: 0.2045\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5913\n",
            "Epoch 00054: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5913 - val_loss: 0.2036\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5877\n",
            "Epoch 00055: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5877 - val_loss: 0.2037\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5842\n",
            "Epoch 00056: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5842 - val_loss: 0.2030\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5806\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5806 - val_loss: 0.2030\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5761\n",
            "Epoch 00058: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5761 - val_loss: 0.2040\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5726\n",
            "Epoch 00059: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5726 - val_loss: 0.2034\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5708\n",
            "Epoch 00060: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5708 - val_loss: 0.2042\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5687\n",
            "Epoch 00061: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5687 - val_loss: 0.2033\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5645\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.20291\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5645 - val_loss: 0.2051\n",
            "Epoch 00062: early stopping\n",
            "reactivity  : 0.2028\n",
            "deg_Mg_pH10 : 0.2757\n",
            "deg_pH10    : 0.2365\n",
            "deg_Mg_50C  : 0.2092\n",
            "deg_50C     : 0.1959\n",
            "total: 0.2292464901395368\n",
            "Fold: 8  model_num: 1\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.9247\n",
            "Epoch 00001: val_loss improved from inf to 0.33289, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 10s 154ms/step - loss: 1.9247 - val_loss: 0.3329\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4410\n",
            "Epoch 00002: val_loss improved from 0.33289 to 0.29086, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.4410 - val_loss: 0.2909\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3313\n",
            "Epoch 00003: val_loss improved from 0.29086 to 0.28296, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.3313 - val_loss: 0.2830\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2727\n",
            "Epoch 00004: val_loss improved from 0.28296 to 0.27258, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.2727 - val_loss: 0.2726\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2079\n",
            "Epoch 00005: val_loss improved from 0.27258 to 0.25724, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.2079 - val_loss: 0.2572\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1531\n",
            "Epoch 00006: val_loss improved from 0.25724 to 0.24513, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1531 - val_loss: 0.2451\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1043\n",
            "Epoch 00007: val_loss improved from 0.24513 to 0.24396, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1043 - val_loss: 0.2440\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0649\n",
            "Epoch 00008: val_loss improved from 0.24396 to 0.23607, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0649 - val_loss: 0.2361\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0297\n",
            "Epoch 00009: val_loss improved from 0.23607 to 0.23226, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0297 - val_loss: 0.2323\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0046\n",
            "Epoch 00010: val_loss improved from 0.23226 to 0.22906, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0046 - val_loss: 0.2291\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9860\n",
            "Epoch 00011: val_loss improved from 0.22906 to 0.22696, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9860 - val_loss: 0.2270\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9621\n",
            "Epoch 00012: val_loss did not improve from 0.22696\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9621 - val_loss: 0.2280\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9422\n",
            "Epoch 00013: val_loss did not improve from 0.22696\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9422 - val_loss: 0.2277\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9249\n",
            "Epoch 00014: val_loss improved from 0.22696 to 0.22250, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9249 - val_loss: 0.2225\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9050\n",
            "Epoch 00015: val_loss did not improve from 0.22250\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9050 - val_loss: 0.2238\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8924\n",
            "Epoch 00016: val_loss improved from 0.22250 to 0.21805, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8924 - val_loss: 0.2181\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8792\n",
            "Epoch 00017: val_loss did not improve from 0.21805\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8792 - val_loss: 0.2197\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8645\n",
            "Epoch 00018: val_loss did not improve from 0.21805\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8645 - val_loss: 0.2221\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8525\n",
            "Epoch 00019: val_loss improved from 0.21805 to 0.21631, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8525 - val_loss: 0.2163\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8406\n",
            "Epoch 00020: val_loss improved from 0.21631 to 0.21561, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8406 - val_loss: 0.2156\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8243\n",
            "Epoch 00021: val_loss improved from 0.21561 to 0.21355, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8243 - val_loss: 0.2135\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8139\n",
            "Epoch 00022: val_loss did not improve from 0.21355\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.8139 - val_loss: 0.2174\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8018\n",
            "Epoch 00023: val_loss improved from 0.21355 to 0.21343, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8018 - val_loss: 0.2134\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7930\n",
            "Epoch 00024: val_loss did not improve from 0.21343\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.7930 - val_loss: 0.2158\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7829\n",
            "Epoch 00025: val_loss did not improve from 0.21343\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7829 - val_loss: 0.2157\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7722\n",
            "Epoch 00026: val_loss improved from 0.21343 to 0.21240, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7722 - val_loss: 0.2124\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7624\n",
            "Epoch 00027: val_loss did not improve from 0.21240\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7624 - val_loss: 0.2133\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7531\n",
            "Epoch 00028: val_loss improved from 0.21240 to 0.21174, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7531 - val_loss: 0.2117\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7462\n",
            "Epoch 00029: val_loss improved from 0.21174 to 0.21078, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7462 - val_loss: 0.2108\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7355\n",
            "Epoch 00030: val_loss did not improve from 0.21078\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7355 - val_loss: 0.2113\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7305\n",
            "Epoch 00031: val_loss improved from 0.21078 to 0.20999, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7305 - val_loss: 0.2100\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7193\n",
            "Epoch 00032: val_loss did not improve from 0.20999\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7193 - val_loss: 0.2102\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7131\n",
            "Epoch 00033: val_loss did not improve from 0.20999\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7131 - val_loss: 0.2105\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7057\n",
            "Epoch 00034: val_loss improved from 0.20999 to 0.20846, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7057 - val_loss: 0.2085\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6976\n",
            "Epoch 00035: val_loss did not improve from 0.20846\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6976 - val_loss: 0.2099\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6916\n",
            "Epoch 00036: val_loss did not improve from 0.20846\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6916 - val_loss: 0.2089\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6829\n",
            "Epoch 00037: val_loss improved from 0.20846 to 0.20799, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.6829 - val_loss: 0.2080\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6780\n",
            "Epoch 00038: val_loss improved from 0.20799 to 0.20789, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6780 - val_loss: 0.2079\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6721\n",
            "Epoch 00039: val_loss did not improve from 0.20789\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6721 - val_loss: 0.2090\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6674\n",
            "Epoch 00040: val_loss improved from 0.20789 to 0.20582, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6674 - val_loss: 0.2058\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6622\n",
            "Epoch 00041: val_loss did not improve from 0.20582\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6622 - val_loss: 0.2070\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6557\n",
            "Epoch 00042: val_loss did not improve from 0.20582\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6557 - val_loss: 0.2078\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6501\n",
            "Epoch 00043: val_loss did not improve from 0.20582\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6501 - val_loss: 0.2079\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6459\n",
            "Epoch 00044: val_loss improved from 0.20582 to 0.20562, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6459 - val_loss: 0.2056\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6397\n",
            "Epoch 00045: val_loss did not improve from 0.20562\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6397 - val_loss: 0.2079\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6352\n",
            "Epoch 00046: val_loss did not improve from 0.20562\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6352 - val_loss: 0.2060\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6290\n",
            "Epoch 00047: val_loss improved from 0.20562 to 0.20549, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6290 - val_loss: 0.2055\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6239\n",
            "Epoch 00048: val_loss did not improve from 0.20549\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6239 - val_loss: 0.2059\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6192\n",
            "Epoch 00049: val_loss improved from 0.20549 to 0.20484, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.6192 - val_loss: 0.2048\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6138\n",
            "Epoch 00050: val_loss did not improve from 0.20484\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6138 - val_loss: 0.2053\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6102\n",
            "Epoch 00051: val_loss did not improve from 0.20484\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6102 - val_loss: 0.2055\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6058\n",
            "Epoch 00052: val_loss did not improve from 0.20484\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6058 - val_loss: 0.2052\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6024\n",
            "Epoch 00053: val_loss improved from 0.20484 to 0.20435, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.6024 - val_loss: 0.2044\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5989\n",
            "Epoch 00054: val_loss did not improve from 0.20435\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5989 - val_loss: 0.2046\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5963\n",
            "Epoch 00055: val_loss did not improve from 0.20435\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5963 - val_loss: 0.2044\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5896\n",
            "Epoch 00056: val_loss did not improve from 0.20435\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5896 - val_loss: 0.2057\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5877\n",
            "Epoch 00057: val_loss improved from 0.20435 to 0.20419, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.5877 - val_loss: 0.2042\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5811\n",
            "Epoch 00058: val_loss did not improve from 0.20419\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5811 - val_loss: 0.2050\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5780\n",
            "Epoch 00059: val_loss improved from 0.20419 to 0.20371, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5780 - val_loss: 0.2037\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5750\n",
            "Epoch 00060: val_loss did not improve from 0.20371\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5750 - val_loss: 0.2047\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5746\n",
            "Epoch 00061: val_loss did not improve from 0.20371\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5746 - val_loss: 0.2057\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5705\n",
            "Epoch 00062: val_loss did not improve from 0.20371\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5705 - val_loss: 0.2050\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5660\n",
            "Epoch 00063: val_loss did not improve from 0.20371\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5660 - val_loss: 0.2045\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5620\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.20371\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5620 - val_loss: 0.2042\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5577\n",
            "Epoch 00065: val_loss did not improve from 0.20371\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5577 - val_loss: 0.2040\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5531\n",
            "Epoch 00066: val_loss did not improve from 0.20371\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5531 - val_loss: 0.2041\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5505\n",
            "Epoch 00067: val_loss did not improve from 0.20371\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5505 - val_loss: 0.2039\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5471\n",
            "Epoch 00068: val_loss improved from 0.20371 to 0.20369, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5471 - val_loss: 0.2037\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5442\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.20369\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5442 - val_loss: 0.2040\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5400\n",
            "Epoch 00070: val_loss did not improve from 0.20369\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5400 - val_loss: 0.2042\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5360\n",
            "Epoch 00071: val_loss did not improve from 0.20369\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5360 - val_loss: 0.2043\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5338\n",
            "Epoch 00072: val_loss did not improve from 0.20369\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5338 - val_loss: 0.2044\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5331\n",
            "Epoch 00073: val_loss did not improve from 0.20369\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5331 - val_loss: 0.2044\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5286\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.20369\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5286 - val_loss: 0.2040\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5239\n",
            "Epoch 00075: val_loss improved from 0.20369 to 0.20318, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5239 - val_loss: 0.2032\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5227\n",
            "Epoch 00076: val_loss did not improve from 0.20318\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5227 - val_loss: 0.2036\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5212\n",
            "Epoch 00077: val_loss did not improve from 0.20318\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5212 - val_loss: 0.2041\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5184\n",
            "Epoch 00078: val_loss did not improve from 0.20318\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5184 - val_loss: 0.2033\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5172\n",
            "Epoch 00079: val_loss did not improve from 0.20318\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5172 - val_loss: 0.2041\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5144\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.20318 to 0.20316, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5144 - val_loss: 0.2032\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5107\n",
            "Epoch 00081: val_loss did not improve from 0.20316\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5107 - val_loss: 0.2037\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5082\n",
            "Epoch 00082: val_loss did not improve from 0.20316\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5082 - val_loss: 0.2036\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5066\n",
            "Epoch 00083: val_loss did not improve from 0.20316\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5066 - val_loss: 0.2033\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5045\n",
            "Epoch 00084: val_loss did not improve from 0.20316\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5045 - val_loss: 0.2034\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5030\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.20316\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5030 - val_loss: 0.2048\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4999\n",
            "Epoch 00086: val_loss did not improve from 0.20316\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.4999 - val_loss: 0.2036\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4980\n",
            "Epoch 00087: val_loss did not improve from 0.20316\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.4980 - val_loss: 0.2035\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4962\n",
            "Epoch 00088: val_loss improved from 0.20316 to 0.20249, saving model to gtn_aug_snr_8_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.4962 - val_loss: 0.2025\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4948\n",
            "Epoch 00089: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.4948 - val_loss: 0.2044\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4940\n",
            "Epoch 00090: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.4940 - val_loss: 0.2030\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4915\n",
            "Epoch 00091: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.4915 - val_loss: 0.2038\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4907\n",
            "Epoch 00092: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4907 - val_loss: 0.2041\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4890\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4890 - val_loss: 0.2034\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4872\n",
            "Epoch 00094: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.4872 - val_loss: 0.2034\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4844\n",
            "Epoch 00095: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.4844 - val_loss: 0.2031\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4830\n",
            "Epoch 00096: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.4830 - val_loss: 0.2034\n",
            "Epoch 97/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4824\n",
            "Epoch 00097: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.4824 - val_loss: 0.2043\n",
            "Epoch 98/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4816\n",
            "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.4816 - val_loss: 0.2031\n",
            "Epoch 99/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4783\n",
            "Epoch 00099: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.4783 - val_loss: 0.2033\n",
            "Epoch 100/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4762\n",
            "Epoch 00100: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4762 - val_loss: 0.2032\n",
            "Epoch 101/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4757\n",
            "Epoch 00101: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4757 - val_loss: 0.2033\n",
            "Epoch 102/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4748\n",
            "Epoch 00102: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.4748 - val_loss: 0.2027\n",
            "Epoch 103/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4743\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.20249\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.4743 - val_loss: 0.2033\n",
            "Epoch 00103: early stopping\n",
            "reactivity  : 0.2155\n",
            "deg_Mg_pH10 : 0.2529\n",
            "deg_pH10    : 0.2355\n",
            "deg_Mg_50C  : 0.2072\n",
            "deg_50C     : 0.2078\n",
            "total: 0.22519383852493502\n",
            "Fold: 9  model_num: 1\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.9148\n",
            "Epoch 00001: val_loss improved from inf to 0.33172, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 10s 151ms/step - loss: 1.9148 - val_loss: 0.3317\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4550\n",
            "Epoch 00002: val_loss improved from 0.33172 to 0.29301, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.4550 - val_loss: 0.2930\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3421\n",
            "Epoch 00003: val_loss improved from 0.29301 to 0.28048, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.3421 - val_loss: 0.2805\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2815\n",
            "Epoch 00004: val_loss improved from 0.28048 to 0.27160, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.2815 - val_loss: 0.2716\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2155\n",
            "Epoch 00005: val_loss improved from 0.27160 to 0.25856, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.2155 - val_loss: 0.2586\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1631\n",
            "Epoch 00006: val_loss improved from 0.25856 to 0.24720, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.1631 - val_loss: 0.2472\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1136\n",
            "Epoch 00007: val_loss improved from 0.24720 to 0.23868, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.1136 - val_loss: 0.2387\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0690\n",
            "Epoch 00008: val_loss improved from 0.23868 to 0.23565, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.0690 - val_loss: 0.2356\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0350\n",
            "Epoch 00009: val_loss improved from 0.23565 to 0.23286, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 1.0350 - val_loss: 0.2329\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0067\n",
            "Epoch 00010: val_loss improved from 0.23286 to 0.22794, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 1.0067 - val_loss: 0.2279\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9862\n",
            "Epoch 00011: val_loss improved from 0.22794 to 0.22509, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9862 - val_loss: 0.2251\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9650\n",
            "Epoch 00012: val_loss did not improve from 0.22509\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.9650 - val_loss: 0.2261\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9444\n",
            "Epoch 00013: val_loss improved from 0.22509 to 0.21916, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9444 - val_loss: 0.2192\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9245\n",
            "Epoch 00014: val_loss improved from 0.21916 to 0.21884, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.9245 - val_loss: 0.2188\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9060\n",
            "Epoch 00015: val_loss improved from 0.21884 to 0.21685, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.9060 - val_loss: 0.2168\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8953\n",
            "Epoch 00016: val_loss improved from 0.21685 to 0.21532, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8953 - val_loss: 0.2153\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8778\n",
            "Epoch 00017: val_loss did not improve from 0.21532\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8778 - val_loss: 0.2169\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8639\n",
            "Epoch 00018: val_loss improved from 0.21532 to 0.21437, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.8639 - val_loss: 0.2144\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8527\n",
            "Epoch 00019: val_loss improved from 0.21437 to 0.21198, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8527 - val_loss: 0.2120\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8396\n",
            "Epoch 00020: val_loss improved from 0.21198 to 0.21140, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8396 - val_loss: 0.2114\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8238\n",
            "Epoch 00021: val_loss improved from 0.21140 to 0.21045, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8238 - val_loss: 0.2104\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8149\n",
            "Epoch 00022: val_loss did not improve from 0.21045\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8149 - val_loss: 0.2110\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8026\n",
            "Epoch 00023: val_loss improved from 0.21045 to 0.20859, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.8026 - val_loss: 0.2086\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7911\n",
            "Epoch 00024: val_loss did not improve from 0.20859\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.7911 - val_loss: 0.2111\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7825\n",
            "Epoch 00025: val_loss did not improve from 0.20859\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.7825 - val_loss: 0.2091\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7709\n",
            "Epoch 00026: val_loss did not improve from 0.20859\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7709 - val_loss: 0.2104\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7622\n",
            "Epoch 00027: val_loss improved from 0.20859 to 0.20636, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7622 - val_loss: 0.2064\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7529\n",
            "Epoch 00028: val_loss did not improve from 0.20636\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.7529 - val_loss: 0.2104\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7464\n",
            "Epoch 00029: val_loss did not improve from 0.20636\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.7464 - val_loss: 0.2067\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7359\n",
            "Epoch 00030: val_loss improved from 0.20636 to 0.20446, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.7359 - val_loss: 0.2045\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7262\n",
            "Epoch 00031: val_loss did not improve from 0.20446\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.7262 - val_loss: 0.2063\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7197\n",
            "Epoch 00032: val_loss did not improve from 0.20446\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.7197 - val_loss: 0.2063\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7111\n",
            "Epoch 00033: val_loss did not improve from 0.20446\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.7111 - val_loss: 0.2057\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7033\n",
            "Epoch 00034: val_loss did not improve from 0.20446\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.7033 - val_loss: 0.2058\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6983\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.20446\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.6983 - val_loss: 0.2060\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6880\n",
            "Epoch 00036: val_loss improved from 0.20446 to 0.20325, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6880 - val_loss: 0.2032\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6820\n",
            "Epoch 00037: val_loss improved from 0.20325 to 0.20269, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6820 - val_loss: 0.2027\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6732\n",
            "Epoch 00038: val_loss did not improve from 0.20269\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6732 - val_loss: 0.2042\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6696\n",
            "Epoch 00039: val_loss improved from 0.20269 to 0.20239, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6696 - val_loss: 0.2024\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6624\n",
            "Epoch 00040: val_loss did not improve from 0.20239\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.6624 - val_loss: 0.2024\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6569\n",
            "Epoch 00041: val_loss improved from 0.20239 to 0.20195, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6569 - val_loss: 0.2019\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6526\n",
            "Epoch 00042: val_loss did not improve from 0.20195\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6526 - val_loss: 0.2038\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6472\n",
            "Epoch 00043: val_loss did not improve from 0.20195\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.6472 - val_loss: 0.2038\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6445\n",
            "Epoch 00044: val_loss did not improve from 0.20195\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.6445 - val_loss: 0.2024\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6382\n",
            "Epoch 00045: val_loss improved from 0.20195 to 0.20165, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6382 - val_loss: 0.2016\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6356\n",
            "Epoch 00046: val_loss did not improve from 0.20165\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6356 - val_loss: 0.2019\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6297\n",
            "Epoch 00047: val_loss improved from 0.20165 to 0.20137, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6297 - val_loss: 0.2014\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6245\n",
            "Epoch 00048: val_loss did not improve from 0.20137\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.6245 - val_loss: 0.2023\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6217\n",
            "Epoch 00049: val_loss did not improve from 0.20137\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.6217 - val_loss: 0.2014\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6174\n",
            "Epoch 00050: val_loss improved from 0.20137 to 0.20092, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.6174 - val_loss: 0.2009\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6103\n",
            "Epoch 00051: val_loss did not improve from 0.20092\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.6103 - val_loss: 0.2014\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6061\n",
            "Epoch 00052: val_loss did not improve from 0.20092\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6061 - val_loss: 0.2010\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6037\n",
            "Epoch 00053: val_loss did not improve from 0.20092\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6037 - val_loss: 0.2021\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6000\n",
            "Epoch 00054: val_loss did not improve from 0.20092\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.6000 - val_loss: 0.2015\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5966\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.20092\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5966 - val_loss: 0.2032\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5870\n",
            "Epoch 00056: val_loss improved from 0.20092 to 0.19982, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5870 - val_loss: 0.1998\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5833\n",
            "Epoch 00057: val_loss did not improve from 0.19982\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5833 - val_loss: 0.2021\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5811\n",
            "Epoch 00058: val_loss improved from 0.19982 to 0.19963, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5811 - val_loss: 0.1996\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5772\n",
            "Epoch 00059: val_loss did not improve from 0.19963\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5772 - val_loss: 0.2003\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5763\n",
            "Epoch 00060: val_loss did not improve from 0.19963\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5763 - val_loss: 0.2011\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5732\n",
            "Epoch 00061: val_loss did not improve from 0.19963\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5732 - val_loss: 0.2007\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5695\n",
            "Epoch 00062: val_loss did not improve from 0.19963\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5695 - val_loss: 0.2014\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5667\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.19963\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5667 - val_loss: 0.2005\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5634\n",
            "Epoch 00064: val_loss did not improve from 0.19963\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5634 - val_loss: 0.2009\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5585\n",
            "Epoch 00065: val_loss did not improve from 0.19963\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5585 - val_loss: 0.2009\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5559\n",
            "Epoch 00066: val_loss did not improve from 0.19963\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5559 - val_loss: 0.2003\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5525\n",
            "Epoch 00067: val_loss did not improve from 0.19963\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5525 - val_loss: 0.2002\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5496\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.19963 to 0.19954, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5496 - val_loss: 0.1995\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5458\n",
            "Epoch 00069: val_loss did not improve from 0.19954\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5458 - val_loss: 0.1997\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5441\n",
            "Epoch 00070: val_loss improved from 0.19954 to 0.19921, saving model to gtn_aug_snr_9_1.h5\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.5441 - val_loss: 0.1992\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5406\n",
            "Epoch 00071: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5406 - val_loss: 0.1998\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5392\n",
            "Epoch 00072: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5392 - val_loss: 0.2000\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5357\n",
            "Epoch 00073: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5357 - val_loss: 0.1995\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5345\n",
            "Epoch 00074: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5345 - val_loss: 0.2006\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5344\n",
            "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5344 - val_loss: 0.2009\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5279\n",
            "Epoch 00076: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5279 - val_loss: 0.2001\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5253\n",
            "Epoch 00077: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5253 - val_loss: 0.2003\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5244\n",
            "Epoch 00078: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5244 - val_loss: 0.2008\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5224\n",
            "Epoch 00079: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5224 - val_loss: 0.1999\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5207\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5207 - val_loss: 0.2008\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5166\n",
            "Epoch 00081: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5166 - val_loss: 0.2012\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5143\n",
            "Epoch 00082: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5143 - val_loss: 0.2000\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5131\n",
            "Epoch 00083: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5131 - val_loss: 0.2003\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5115\n",
            "Epoch 00084: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.5115 - val_loss: 0.2005\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5112\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.19921\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.5112 - val_loss: 0.1997\n",
            "Epoch 00085: early stopping\n",
            "reactivity  : 0.2017\n",
            "deg_Mg_pH10 : 0.2467\n",
            "deg_pH10    : 0.2168\n",
            "deg_Mg_50C  : 0.1969\n",
            "deg_50C     : 0.1971\n",
            "total: 0.21510275051051114\n",
            "===================OOF RMSE=================\n",
            "reactivity  : 0.1962\n",
            "deg_Mg_pH10 : 0.2451\n",
            "deg_pH10    : 0.2259\n",
            "deg_Mg_50C  : 0.1998\n",
            "deg_50C     : 0.1963\n",
            "total: 0.21370004847168061\n",
            "============================================\n",
            "Fold: 0  model_num: 2\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.9666\n",
            "Epoch 00001: val_loss improved from inf to 0.30834, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 10s 143ms/step - loss: 1.9666 - val_loss: 0.3083\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4471\n",
            "Epoch 00002: val_loss improved from 0.30834 to 0.27930, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.4471 - val_loss: 0.2793\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3533\n",
            "Epoch 00003: val_loss improved from 0.27930 to 0.26527, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 1.3533 - val_loss: 0.2653\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2877\n",
            "Epoch 00004: val_loss improved from 0.26527 to 0.25155, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.2877 - val_loss: 0.2515\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2349\n",
            "Epoch 00005: val_loss improved from 0.25155 to 0.24252, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.2349 - val_loss: 0.2425\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1747\n",
            "Epoch 00006: val_loss improved from 0.24252 to 0.23210, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.1747 - val_loss: 0.2321\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1271\n",
            "Epoch 00007: val_loss improved from 0.23210 to 0.22604, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 1.1271 - val_loss: 0.2260\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0937\n",
            "Epoch 00008: val_loss improved from 0.22604 to 0.22004, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.0937 - val_loss: 0.2200\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0556\n",
            "Epoch 00009: val_loss improved from 0.22004 to 0.21492, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.0556 - val_loss: 0.2149\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0322\n",
            "Epoch 00010: val_loss did not improve from 0.21492\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 1.0322 - val_loss: 0.2152\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0036\n",
            "Epoch 00011: val_loss improved from 0.21492 to 0.20994, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 1.0036 - val_loss: 0.2099\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9799\n",
            "Epoch 00012: val_loss improved from 0.20994 to 0.20712, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.9799 - val_loss: 0.2071\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9635\n",
            "Epoch 00013: val_loss did not improve from 0.20712\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.9635 - val_loss: 0.2089\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9426\n",
            "Epoch 00014: val_loss improved from 0.20712 to 0.20501, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.9426 - val_loss: 0.2050\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9226\n",
            "Epoch 00015: val_loss improved from 0.20501 to 0.20470, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.9226 - val_loss: 0.2047\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9055\n",
            "Epoch 00016: val_loss improved from 0.20470 to 0.20157, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.9055 - val_loss: 0.2016\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8909\n",
            "Epoch 00017: val_loss improved from 0.20157 to 0.20124, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.8909 - val_loss: 0.2012\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8800\n",
            "Epoch 00018: val_loss did not improve from 0.20124\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.8800 - val_loss: 0.2044\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8599\n",
            "Epoch 00019: val_loss did not improve from 0.20124\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.8599 - val_loss: 0.2048\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8486\n",
            "Epoch 00020: val_loss improved from 0.20124 to 0.19988, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.8486 - val_loss: 0.1999\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8350\n",
            "Epoch 00021: val_loss improved from 0.19988 to 0.19945, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.8350 - val_loss: 0.1995\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8232\n",
            "Epoch 00022: val_loss improved from 0.19945 to 0.19906, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.8232 - val_loss: 0.1991\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8104\n",
            "Epoch 00023: val_loss improved from 0.19906 to 0.19739, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.8104 - val_loss: 0.1974\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8000\n",
            "Epoch 00024: val_loss improved from 0.19739 to 0.19712, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.8000 - val_loss: 0.1971\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7886\n",
            "Epoch 00025: val_loss improved from 0.19712 to 0.19669, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.7886 - val_loss: 0.1967\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7793\n",
            "Epoch 00026: val_loss did not improve from 0.19669\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7793 - val_loss: 0.1990\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7681\n",
            "Epoch 00027: val_loss improved from 0.19669 to 0.19582, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.7681 - val_loss: 0.1958\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7568\n",
            "Epoch 00028: val_loss did not improve from 0.19582\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7568 - val_loss: 0.1979\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7511\n",
            "Epoch 00029: val_loss improved from 0.19582 to 0.19341, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.7511 - val_loss: 0.1934\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7403\n",
            "Epoch 00030: val_loss did not improve from 0.19341\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7403 - val_loss: 0.1964\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7344\n",
            "Epoch 00031: val_loss did not improve from 0.19341\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.7344 - val_loss: 0.1944\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7261\n",
            "Epoch 00032: val_loss improved from 0.19341 to 0.19338, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.7261 - val_loss: 0.1934\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7187\n",
            "Epoch 00033: val_loss improved from 0.19338 to 0.19332, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.7187 - val_loss: 0.1933\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7118\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.19332\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7118 - val_loss: 0.1939\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7022\n",
            "Epoch 00035: val_loss improved from 0.19332 to 0.19174, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.7022 - val_loss: 0.1917\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6939\n",
            "Epoch 00036: val_loss improved from 0.19174 to 0.19131, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6939 - val_loss: 0.1913\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6868\n",
            "Epoch 00037: val_loss improved from 0.19131 to 0.19006, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6868 - val_loss: 0.1901\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6830\n",
            "Epoch 00038: val_loss did not improve from 0.19006\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6830 - val_loss: 0.1918\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6764\n",
            "Epoch 00039: val_loss improved from 0.19006 to 0.18934, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.6764 - val_loss: 0.1893\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6704\n",
            "Epoch 00040: val_loss did not improve from 0.18934\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6704 - val_loss: 0.1906\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6660\n",
            "Epoch 00041: val_loss did not improve from 0.18934\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6660 - val_loss: 0.1914\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6605\n",
            "Epoch 00042: val_loss did not improve from 0.18934\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6605 - val_loss: 0.1909\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6554\n",
            "Epoch 00043: val_loss did not improve from 0.18934\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6554 - val_loss: 0.1894\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6503\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.18934\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6503 - val_loss: 0.1910\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6440\n",
            "Epoch 00045: val_loss improved from 0.18934 to 0.18912, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6440 - val_loss: 0.1891\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6380\n",
            "Epoch 00046: val_loss did not improve from 0.18912\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6380 - val_loss: 0.1915\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6354\n",
            "Epoch 00047: val_loss did not improve from 0.18912\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6354 - val_loss: 0.1908\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6313\n",
            "Epoch 00048: val_loss did not improve from 0.18912\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6313 - val_loss: 0.1903\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6257\n",
            "Epoch 00049: val_loss did not improve from 0.18912\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6257 - val_loss: 0.1896\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6231\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.18912\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6231 - val_loss: 0.1901\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6163\n",
            "Epoch 00051: val_loss improved from 0.18912 to 0.18896, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.6163 - val_loss: 0.1890\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6121\n",
            "Epoch 00052: val_loss did not improve from 0.18896\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6121 - val_loss: 0.1891\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6086\n",
            "Epoch 00053: val_loss improved from 0.18896 to 0.18860, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6086 - val_loss: 0.1886\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6048\n",
            "Epoch 00054: val_loss did not improve from 0.18860\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6048 - val_loss: 0.1895\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6025\n",
            "Epoch 00055: val_loss improved from 0.18860 to 0.18819, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.6025 - val_loss: 0.1882\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5994\n",
            "Epoch 00056: val_loss did not improve from 0.18819\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5994 - val_loss: 0.1888\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5949\n",
            "Epoch 00057: val_loss did not improve from 0.18819\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5949 - val_loss: 0.1891\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5942\n",
            "Epoch 00058: val_loss did not improve from 0.18819\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5942 - val_loss: 0.1885\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5897\n",
            "Epoch 00059: val_loss did not improve from 0.18819\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5897 - val_loss: 0.1885\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5863\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.18819\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5863 - val_loss: 0.1887\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5845\n",
            "Epoch 00061: val_loss did not improve from 0.18819\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5845 - val_loss: 0.1888\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5807\n",
            "Epoch 00062: val_loss improved from 0.18819 to 0.18797, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5807 - val_loss: 0.1880\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5762\n",
            "Epoch 00063: val_loss did not improve from 0.18797\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5762 - val_loss: 0.1890\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5743\n",
            "Epoch 00064: val_loss did not improve from 0.18797\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5743 - val_loss: 0.1883\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5714\n",
            "Epoch 00065: val_loss did not improve from 0.18797\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5714 - val_loss: 0.1905\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5704\n",
            "Epoch 00066: val_loss did not improve from 0.18797\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5704 - val_loss: 0.1888\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5695\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.18797\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5695 - val_loss: 0.1902\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5642\n",
            "Epoch 00068: val_loss did not improve from 0.18797\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5642 - val_loss: 0.1902\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5607\n",
            "Epoch 00069: val_loss did not improve from 0.18797\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5607 - val_loss: 0.1887\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5585\n",
            "Epoch 00070: val_loss did not improve from 0.18797\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5585 - val_loss: 0.1889\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5564\n",
            "Epoch 00071: val_loss did not improve from 0.18797\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5564 - val_loss: 0.1896\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5548\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.18797\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5548 - val_loss: 0.1896\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5518\n",
            "Epoch 00073: val_loss improved from 0.18797 to 0.18797, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5518 - val_loss: 0.1880\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5472\n",
            "Epoch 00074: val_loss improved from 0.18797 to 0.18778, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5472 - val_loss: 0.1878\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5467\n",
            "Epoch 00075: val_loss did not improve from 0.18778\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5467 - val_loss: 0.1889\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5446\n",
            "Epoch 00076: val_loss did not improve from 0.18778\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5446 - val_loss: 0.1885\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5440\n",
            "Epoch 00077: val_loss did not improve from 0.18778\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5440 - val_loss: 0.1886\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5415\n",
            "Epoch 00078: val_loss did not improve from 0.18778\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5415 - val_loss: 0.1890\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5393\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.18778\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5393 - val_loss: 0.1881\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5377\n",
            "Epoch 00080: val_loss did not improve from 0.18778\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5377 - val_loss: 0.1879\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5337\n",
            "Epoch 00081: val_loss improved from 0.18778 to 0.18761, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5337 - val_loss: 0.1876\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5330\n",
            "Epoch 00082: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5330 - val_loss: 0.1877\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5314\n",
            "Epoch 00083: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5314 - val_loss: 0.1881\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5298\n",
            "Epoch 00084: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5298 - val_loss: 0.1877\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5298\n",
            "Epoch 00085: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5298 - val_loss: 0.1884\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5255\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5255 - val_loss: 0.1881\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5239\n",
            "Epoch 00087: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5239 - val_loss: 0.1878\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5232\n",
            "Epoch 00088: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5232 - val_loss: 0.1877\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5208\n",
            "Epoch 00089: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5208 - val_loss: 0.1882\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5191\n",
            "Epoch 00090: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5191 - val_loss: 0.1880\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5181\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5181 - val_loss: 0.1884\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5161\n",
            "Epoch 00092: val_loss did not improve from 0.18761\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5161 - val_loss: 0.1887\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5153\n",
            "Epoch 00093: val_loss improved from 0.18761 to 0.18756, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5153 - val_loss: 0.1876\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5143\n",
            "Epoch 00094: val_loss did not improve from 0.18756\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5143 - val_loss: 0.1877\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5122\n",
            "Epoch 00095: val_loss did not improve from 0.18756\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5122 - val_loss: 0.1879\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5113\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.18756\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5113 - val_loss: 0.1886\n",
            "Epoch 97/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5090\n",
            "Epoch 00097: val_loss did not improve from 0.18756\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5090 - val_loss: 0.1878\n",
            "Epoch 98/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5075\n",
            "Epoch 00098: val_loss did not improve from 0.18756\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5075 - val_loss: 0.1883\n",
            "Epoch 99/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5062\n",
            "Epoch 00099: val_loss improved from 0.18756 to 0.18726, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.5062 - val_loss: 0.1873\n",
            "Epoch 100/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5053\n",
            "Epoch 00100: val_loss improved from 0.18726 to 0.18716, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5053 - val_loss: 0.1872\n",
            "Epoch 101/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5041\n",
            "Epoch 00101: val_loss did not improve from 0.18716\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5041 - val_loss: 0.1873\n",
            "Epoch 102/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5042\n",
            "Epoch 00102: val_loss did not improve from 0.18716\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5042 - val_loss: 0.1880\n",
            "Epoch 103/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5026\n",
            "Epoch 00103: val_loss did not improve from 0.18716\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5026 - val_loss: 0.1881\n",
            "Epoch 104/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5018\n",
            "Epoch 00104: val_loss did not improve from 0.18716\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5018 - val_loss: 0.1872\n",
            "Epoch 105/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5005\n",
            "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.18716\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5005 - val_loss: 0.1876\n",
            "Epoch 106/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4990\n",
            "Epoch 00106: val_loss improved from 0.18716 to 0.18673, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4990 - val_loss: 0.1867\n",
            "Epoch 107/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4975\n",
            "Epoch 00107: val_loss did not improve from 0.18673\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4975 - val_loss: 0.1879\n",
            "Epoch 108/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4958\n",
            "Epoch 00108: val_loss improved from 0.18673 to 0.18660, saving model to gtn_aug_snr_0_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4958 - val_loss: 0.1866\n",
            "Epoch 109/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4948\n",
            "Epoch 00109: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.4948 - val_loss: 0.1868\n",
            "Epoch 110/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4956\n",
            "Epoch 00110: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4956 - val_loss: 0.1882\n",
            "Epoch 111/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4931\n",
            "Epoch 00111: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.4931 - val_loss: 0.1873\n",
            "Epoch 112/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4927\n",
            "Epoch 00112: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.4927 - val_loss: 0.1881\n",
            "Epoch 113/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4931\n",
            "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4931 - val_loss: 0.1873\n",
            "Epoch 114/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4908\n",
            "Epoch 00114: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4908 - val_loss: 0.1879\n",
            "Epoch 115/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4904\n",
            "Epoch 00115: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.4904 - val_loss: 0.1878\n",
            "Epoch 116/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4895\n",
            "Epoch 00116: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4895 - val_loss: 0.1876\n",
            "Epoch 117/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4881\n",
            "Epoch 00117: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4881 - val_loss: 0.1876\n",
            "Epoch 118/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4874\n",
            "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4874 - val_loss: 0.1881\n",
            "Epoch 119/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4860\n",
            "Epoch 00119: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.4860 - val_loss: 0.1884\n",
            "Epoch 120/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4845\n",
            "Epoch 00120: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4845 - val_loss: 0.1875\n",
            "Epoch 121/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4836\n",
            "Epoch 00121: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.4836 - val_loss: 0.1877\n",
            "Epoch 122/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4833\n",
            "Epoch 00122: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.4833 - val_loss: 0.1876\n",
            "Epoch 123/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4821\n",
            "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.18660\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.4821 - val_loss: 0.1872\n",
            "Epoch 00123: early stopping\n",
            "reactivity  : 0.1881\n",
            "deg_Mg_pH10 : 0.2166\n",
            "deg_pH10    : 0.2145\n",
            "deg_Mg_50C  : 0.1822\n",
            "deg_50C     : 0.1962\n",
            "total: 0.19563676757687326\n",
            "Fold: 1  model_num: 2\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.0263\n",
            "Epoch 00001: val_loss improved from inf to 0.31130, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 10s 145ms/step - loss: 2.0263 - val_loss: 0.3113\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4523\n",
            "Epoch 00002: val_loss improved from 0.31130 to 0.28402, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 1.4523 - val_loss: 0.2840\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3565\n",
            "Epoch 00003: val_loss improved from 0.28402 to 0.27207, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.3565 - val_loss: 0.2721\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3028\n",
            "Epoch 00004: val_loss improved from 0.27207 to 0.26972, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.3028 - val_loss: 0.2697\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2490\n",
            "Epoch 00005: val_loss improved from 0.26972 to 0.25301, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.2490 - val_loss: 0.2530\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2010\n",
            "Epoch 00006: val_loss improved from 0.25301 to 0.24469, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 1.2010 - val_loss: 0.2447\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1543\n",
            "Epoch 00007: val_loss improved from 0.24469 to 0.23400, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.1543 - val_loss: 0.2340\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1056\n",
            "Epoch 00008: val_loss improved from 0.23400 to 0.23260, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.1056 - val_loss: 0.2326\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0701\n",
            "Epoch 00009: val_loss improved from 0.23260 to 0.22674, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 1.0701 - val_loss: 0.2267\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0386\n",
            "Epoch 00010: val_loss improved from 0.22674 to 0.22268, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 1.0386 - val_loss: 0.2227\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0135\n",
            "Epoch 00011: val_loss did not improve from 0.22268\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 1.0135 - val_loss: 0.2253\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9940\n",
            "Epoch 00012: val_loss improved from 0.22268 to 0.22134, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.9940 - val_loss: 0.2213\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9674\n",
            "Epoch 00013: val_loss improved from 0.22134 to 0.21509, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.9674 - val_loss: 0.2151\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9471\n",
            "Epoch 00014: val_loss did not improve from 0.21509\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.9471 - val_loss: 0.2180\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9345\n",
            "Epoch 00015: val_loss did not improve from 0.21509\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.9345 - val_loss: 0.2160\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9156\n",
            "Epoch 00016: val_loss improved from 0.21509 to 0.21173, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.9156 - val_loss: 0.2117\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8991\n",
            "Epoch 00017: val_loss improved from 0.21173 to 0.21155, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.8991 - val_loss: 0.2115\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8888\n",
            "Epoch 00018: val_loss improved from 0.21155 to 0.20816, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.8888 - val_loss: 0.2082\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8691\n",
            "Epoch 00019: val_loss did not improve from 0.20816\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.8691 - val_loss: 0.2110\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8596\n",
            "Epoch 00020: val_loss did not improve from 0.20816\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.8596 - val_loss: 0.2108\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8444\n",
            "Epoch 00021: val_loss did not improve from 0.20816\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.8444 - val_loss: 0.2092\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8334\n",
            "Epoch 00022: val_loss improved from 0.20816 to 0.20485, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.8334 - val_loss: 0.2049\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8175\n",
            "Epoch 00023: val_loss did not improve from 0.20485\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.8175 - val_loss: 0.2062\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8045\n",
            "Epoch 00024: val_loss did not improve from 0.20485\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.8045 - val_loss: 0.2049\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7987\n",
            "Epoch 00025: val_loss did not improve from 0.20485\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7987 - val_loss: 0.2061\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7882\n",
            "Epoch 00026: val_loss improved from 0.20485 to 0.20399, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.7882 - val_loss: 0.2040\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7786\n",
            "Epoch 00027: val_loss improved from 0.20399 to 0.20175, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.7786 - val_loss: 0.2018\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7668\n",
            "Epoch 00028: val_loss did not improve from 0.20175\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7668 - val_loss: 0.2023\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7586\n",
            "Epoch 00029: val_loss did not improve from 0.20175\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7586 - val_loss: 0.2034\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7514\n",
            "Epoch 00030: val_loss improved from 0.20175 to 0.20000, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.7514 - val_loss: 0.2000\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7419\n",
            "Epoch 00031: val_loss did not improve from 0.20000\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7419 - val_loss: 0.2014\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7343\n",
            "Epoch 00032: val_loss did not improve from 0.20000\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7343 - val_loss: 0.2016\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7269\n",
            "Epoch 00033: val_loss did not improve from 0.20000\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7269 - val_loss: 0.2008\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7191\n",
            "Epoch 00034: val_loss did not improve from 0.20000\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.7191 - val_loss: 0.2008\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7115\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.20000\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7115 - val_loss: 0.2010\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7031\n",
            "Epoch 00036: val_loss did not improve from 0.20000\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.7031 - val_loss: 0.2013\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6942\n",
            "Epoch 00037: val_loss improved from 0.20000 to 0.19946, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6942 - val_loss: 0.1995\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6875\n",
            "Epoch 00038: val_loss did not improve from 0.19946\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.6875 - val_loss: 0.2002\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6814\n",
            "Epoch 00039: val_loss did not improve from 0.19946\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6814 - val_loss: 0.2001\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6769\n",
            "Epoch 00040: val_loss did not improve from 0.19946\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6769 - val_loss: 0.2003\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6726\n",
            "Epoch 00041: val_loss improved from 0.19946 to 0.19901, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6726 - val_loss: 0.1990\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6686\n",
            "Epoch 00042: val_loss improved from 0.19901 to 0.19779, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.6686 - val_loss: 0.1978\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6619\n",
            "Epoch 00043: val_loss did not improve from 0.19779\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6619 - val_loss: 0.1996\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6543\n",
            "Epoch 00044: val_loss improved from 0.19779 to 0.19673, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6543 - val_loss: 0.1967\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6520\n",
            "Epoch 00045: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6520 - val_loss: 0.1981\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6473\n",
            "Epoch 00046: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.6473 - val_loss: 0.1995\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6435\n",
            "Epoch 00047: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6435 - val_loss: 0.2000\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6392\n",
            "Epoch 00048: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6392 - val_loss: 0.1998\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6353\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6353 - val_loss: 0.1983\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6272\n",
            "Epoch 00050: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.6272 - val_loss: 0.1973\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6222\n",
            "Epoch 00051: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6222 - val_loss: 0.1972\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6195\n",
            "Epoch 00052: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6195 - val_loss: 0.1976\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6163\n",
            "Epoch 00053: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6163 - val_loss: 0.1989\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6113\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.6113 - val_loss: 0.1982\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6057\n",
            "Epoch 00055: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6057 - val_loss: 0.1972\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6022\n",
            "Epoch 00056: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.6022 - val_loss: 0.1976\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5988\n",
            "Epoch 00057: val_loss did not improve from 0.19673\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5988 - val_loss: 0.1974\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5954\n",
            "Epoch 00058: val_loss improved from 0.19673 to 0.19619, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.5954 - val_loss: 0.1962\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5924\n",
            "Epoch 00059: val_loss did not improve from 0.19619\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5924 - val_loss: 0.1972\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5895\n",
            "Epoch 00060: val_loss did not improve from 0.19619\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5895 - val_loss: 0.1963\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5888\n",
            "Epoch 00061: val_loss did not improve from 0.19619\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5888 - val_loss: 0.1970\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5851\n",
            "Epoch 00062: val_loss did not improve from 0.19619\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5851 - val_loss: 0.1973\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5835\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.19619\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5835 - val_loss: 0.1967\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5766\n",
            "Epoch 00064: val_loss did not improve from 0.19619\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5766 - val_loss: 0.1970\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5742\n",
            "Epoch 00065: val_loss did not improve from 0.19619\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.5742 - val_loss: 0.1962\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5718\n",
            "Epoch 00066: val_loss improved from 0.19619 to 0.19560, saving model to gtn_aug_snr_1_2.h5\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.5718 - val_loss: 0.1956\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5684\n",
            "Epoch 00067: val_loss did not improve from 0.19560\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.5684 - val_loss: 0.1959\n",
            "Epoch 68/500\n",
            "25/68 [==========>...................] - ETA: 5s - loss: 0.5606"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T06:41:19.520687Z",
          "iopub.status.busy": "2020-10-01T06:41:19.518940Z",
          "iopub.status.idle": "2020-10-01T06:41:19.521354Z",
          "shell.execute_reply": "2020-10-01T06:41:19.521878Z"
        },
        "papermill": {
          "duration": 42.401313,
          "end_time": "2020-10-01T06:41:19.522000",
          "exception": false,
          "start_time": "2020-10-01T06:40:37.120687",
          "status": "completed"
        },
        "tags": [],
        "id": "Q4GGiqtdaItT"
      },
      "source": [
        "if 0:\n",
        "    #plt.plot(history.history['loss'][10:], label='train')\n",
        "    plt.plot(history.history['val_loss'][10:], label='val')\n",
        "    plt.yscale('log')\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T06:42:44.907549Z",
          "iopub.status.busy": "2020-10-01T06:42:44.905860Z",
          "iopub.status.idle": "2020-10-01T06:43:00.606840Z",
          "shell.execute_reply": "2020-10-01T06:43:00.607922Z"
        },
        "papermill": {
          "duration": 58.187605,
          "end_time": "2020-10-01T06:43:00.608128",
          "exception": false,
          "start_time": "2020-10-01T06:42:02.420523",
          "status": "completed"
        },
        "tags": [],
        "id": "Uu_p4yRRaItV"
      },
      "source": [
        "np.save(f'/content/{model_name}_oof', oof)\n",
        "np.save(f'/content/{model_name}_gru_public_preds', gru_public_preds)\n",
        "np.save(f'/content/{model_name}_gru_private_preds', gru_private_preds)\n",
        "\n",
        "\n",
        "#gru_public_preds = np.load(f'preds/{model_name}_gru_public_preds.npy')\n",
        "#gru_private_preds = np.load(f'preds/{model_name}_gru_private_preds.npy')\n",
        "\n",
        "gru_private_preds = np.mean(gru_private_preds, axis=0)\n",
        "gru_public_preds = np.mean(gru_public_preds, axis=0)\n",
        "\n",
        "preds_gru = []\n",
        "\n",
        "for df, preds in [(public_df, gru_public_preds), (private_df, gru_private_preds)]:\n",
        "    for i, uid in enumerate(df.id):\n",
        "        single_pred = preds[i]\n",
        "\n",
        "        single_df = pd.DataFrame(single_pred, columns=target_cols)\n",
        "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
        "\n",
        "        preds_gru.append(single_df)\n",
        "\n",
        "preds_gru_df = pd.concat(preds_gru)\n",
        "\n",
        "preds_gru_df = preds_gru_df.groupby('id_seqpos').mean().reset_index()\n",
        "\n",
        "\n",
        "submission = sample_sub[['id_seqpos']].merge(preds_gru_df, on=['id_seqpos'])\n",
        "\n",
        "#sanity check\n",
        "submission.head()\n",
        "\n",
        "submission.to_csv(f'/content/drive/My Drive/Vaccine/submissionTransv2.csv', index=False)\n",
        "print('Submission saved')\n",
        "\n",
        "print('Run Time [min]:', round((time.time() - start)/60))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}