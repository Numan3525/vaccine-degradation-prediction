{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 17310.801886,
      "end_time": "2020-10-01T06:43:44.273538",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-10-01T01:55:13.471652",
      "version": "2.1.0"
    },
    "colab": {
      "name": "Wavenet_Final_Version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xj1yiNiaRUB",
        "outputId": "65ace708-0c32-4d68-8fd9-e90f3e3b433c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSqFBatsaR4M",
        "outputId": "b8cc5050-55e7-4519-89a5-9423f3ebd506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install kaggle\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"mizanurr\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"654c2a7dc145088aa93c65566a027cf6\"\n",
        "!kaggle competitions download -c stanford-covid-vaccine\n",
        "!kaggle datasets download -d vaghefi/aug-vaccine\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling kaggle-1.5.8:\n",
            "  Successfully uninstalled kaggle-1.5.8\n",
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/14/9db40d8d6230655e76fa12166006f952da4697c003610022683c514cf15f/kaggle-1.5.8.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.8-cp36-none-any.whl size=73275 sha256=4e52e70aacd8611528e52a9332fd375f54b493b5f9d06fac0a061d4cd9da3098\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/a7/09/68dc83c7c14fdbdf5d3f2b2da5b87e587bfc1e85df69b1130c\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.8\n",
            "Downloading stanford-covid-vaccine.zip to /content\n",
            " 45% 20.0M/44.1M [00:00<00:00, 38.3MB/s]\n",
            "100% 44.1M/44.1M [00:00<00:00, 128MB/s] \n",
            "Downloading aug-vaccine.zip to /content\n",
            " 83% 81.0M/97.1M [00:00<00:00, 111MB/s] \n",
            "100% 97.1M/97.1M [00:00<00:00, 121MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3v4QxCaaT_V"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfQS2VRcaX8u"
      },
      "source": [
        "with zipfile.ZipFile('/content/stanford-covid-vaccine.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/data/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "158HblVaacMB"
      },
      "source": [
        "with zipfile.ZipFile('/content/aug-vaccine.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/data/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:17.991651Z",
          "iopub.status.busy": "2020-10-01T01:55:17.990733Z",
          "iopub.status.idle": "2020-10-01T01:55:28.701411Z",
          "shell.execute_reply": "2020-10-01T01:55:28.700315Z"
        },
        "papermill": {
          "duration": 10.726996,
          "end_time": "2020-10-01T01:55:28.701553",
          "exception": false,
          "start_time": "2020-10-01T01:55:17.974557",
          "status": "completed"
        },
        "tags": [],
        "id": "0d9TNkX9aIs3",
        "outputId": "43e9d118-4c85-4612-a762-269787ca675f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "!pip install spektral"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spektral\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/2e/3b5bb768d0568f9568bcde08f42738b17bada5f5329221222edfad0838f6/spektral-0.6.1-py3-none-any.whl (95kB)\n",
            "\r\u001b[K     |███▍                            | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 40kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 81kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from spektral) (0.22.2.post1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from spektral) (2.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spektral) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from spektral) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spektral) (1.18.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from spektral) (4.2.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from spektral) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from spektral) (2.23.0)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from spektral) (2.3.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->spektral) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->spektral) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->spektral) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (3.0.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (50.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (3.2.0)\n",
            "Installing collected packages: spektral\n",
            "Successfully installed spektral-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:28.747768Z",
          "iopub.status.busy": "2020-10-01T01:55:28.746789Z",
          "iopub.status.idle": "2020-10-01T01:55:36.477040Z",
          "shell.execute_reply": "2020-10-01T01:55:36.476485Z"
        },
        "papermill": {
          "duration": 7.757591,
          "end_time": "2020-10-01T01:55:36.477169",
          "exception": false,
          "start_time": "2020-10-01T01:55:28.719578",
          "status": "completed"
        },
        "tags": [],
        "id": "xNAdxQ8VaIs7",
        "outputId": "70b90a06-d2f9-42cc-9945-e9e8cd9aae0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#the basics\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import math, json\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import time\n",
        "from spektral.layers import GraphAttention, GatedGraphConv\n",
        "\n",
        "#tensorflow deep learning basics\n",
        "import tensorflow as tf\n",
        "\n",
        "print('tf version:',tf.__version__)\n",
        "\n",
        "print('\\nList of GPUs:')\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version: 2.3.0\n",
            "\n",
            "List of GPUs:\n",
            "Name: /physical_device:GPU:0   Type: GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:36.522717Z",
          "iopub.status.busy": "2020-10-01T01:55:36.521914Z",
          "iopub.status.idle": "2020-10-01T01:55:46.339097Z",
          "shell.execute_reply": "2020-10-01T01:55:46.339950Z"
        },
        "papermill": {
          "duration": 9.843065,
          "end_time": "2020-10-01T01:55:46.340104",
          "exception": false,
          "start_time": "2020-10-01T01:55:36.497039",
          "status": "completed"
        },
        "tags": [],
        "id": "4vTAr-ylaIs-",
        "outputId": "0c63fa6b-2550-48cd-f00c-c5655ef2d9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "import os\n",
        "folder = '/content/data/bpps'\n",
        "files = os.listdir(folder)\n",
        "\n",
        "lst = []\n",
        "for file in tqdm(files):\n",
        "    data = np.load(os.path.join(folder, file))\n",
        "    lst.append([file.replace('.npy',''), data])\n",
        "    \n",
        "bpps = pd.DataFrame(lst, columns=['id', 'bpps'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6034/6034 [00:02<00:00, 2200.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:46.458781Z",
          "iopub.status.busy": "2020-10-01T01:55:46.456938Z",
          "iopub.status.idle": "2020-10-01T01:55:46.459644Z",
          "shell.execute_reply": "2020-10-01T01:55:46.460184Z"
        },
        "papermill": {
          "duration": 0.064842,
          "end_time": "2020-10-01T01:55:46.460317",
          "exception": false,
          "start_time": "2020-10-01T01:55:46.395475",
          "status": "completed"
        },
        "tags": [],
        "id": "rvqsfduUaItA"
      },
      "source": [
        "def get_structure_feature(structure):\n",
        "    pm = np.zeros((len(structure), 3))\n",
        "    start_token_indices = []\n",
        "    for i, token in enumerate(structure):\n",
        "        if token == \"(\":\n",
        "            start_token_indices.append(i)\n",
        "        elif token == \")\":\n",
        "            j = start_token_indices.pop()\n",
        "            pm[i, 0] = pm[i, 0] = i - j\n",
        "            pm[i, 1] = pm[j, 1] = structure[j:i+1].count('.')\n",
        "            pm[i, 2] = pm[j, 2] = structure[j:i+1].count(')') - 1\n",
        "    return pm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UkrstLqbZuB"
      },
      "source": [
        "train = pd.read_json('/content/data/train.json', lines=True).merge(bpps)\n",
        "test = pd.read_json('/content/data/test.json', lines=True).merge(bpps)\n",
        "sample_sub = pd.read_csv('/content/data/sample_submission.csv')\n",
        "augment = pd.read_csv('/content/drive/My Drive/kaggle/aug_data1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:46.588189Z",
          "iopub.status.busy": "2020-10-01T01:55:46.577873Z",
          "iopub.status.idle": "2020-10-01T01:55:52.471799Z",
          "shell.execute_reply": "2020-10-01T01:55:52.470919Z"
        },
        "papermill": {
          "duration": 5.958859,
          "end_time": "2020-10-01T01:55:52.471928",
          "exception": false,
          "start_time": "2020-10-01T01:55:46.513069",
          "status": "completed"
        },
        "tags": [],
        "id": "vbOzg9isaItC",
        "outputId": "c7de946c-3e4d-4e00-dc72-e06886ad80c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True).merge(bpps)\n",
        "# test = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True).merge(bpps)\n",
        "# sample_sub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\n",
        "# augment = pd.read_csv('../input/aug-vaccine/aug_data1.csv')\n",
        "\n",
        "\n",
        "train_aug = train.drop(columns=['structure', 'predicted_loop_type']).merge(augment, how='left', on=['id','sequence'])\n",
        "test_aug = test.drop(columns=['structure', 'predicted_loop_type']).merge(augment, how='left', on=['id','sequence'])\n",
        "\n",
        "test = test.append(test_aug[test.columns])\n",
        "\n",
        "#target columns\n",
        "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
        "error_cols = ['reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C']\n",
        "metric_cols = [0, 1, 3]\n",
        "\n",
        "token = {'sequence': 'ACGU', 'structure': '().', 'predicted_loop_type': 'BEHIMSX'}\n",
        "token_map = {key: {x:i for i, x in enumerate(val)} for key, val in token.items()}\n",
        "\n",
        "def get_adj(structure):\n",
        "    pm = np.zeros((len(structure), len(structure)))\n",
        "    start_token_indices = []\n",
        "    for i, token in enumerate(structure):\n",
        "        if token == \"(\":\n",
        "            start_token_indices.append(i)\n",
        "        elif token == \")\":\n",
        "            j = start_token_indices.pop()\n",
        "            pm[i, j] = 1.0\n",
        "            pm[j, i] = 1.0\n",
        "        pm[i, i] = 1\n",
        "    return pm\n",
        "\n",
        "\n",
        "mu_bpps = 0.368\n",
        "sd_bpps = 0.415\n",
        "\n",
        "def preprocess_inputs(df):\n",
        "    features = []\n",
        "    for col in ['sequence', 'structure', 'predicted_loop_type']:\n",
        "        x = np.array(df[col].apply(lambda seq: [token_map[col][x] for x in seq]).values.tolist())\n",
        "        features.append(tf.keras.backend.one_hot(x,len(token_map[col])))\n",
        "    bpps = np.array(df['bpps'].tolist())\n",
        "    features.append((1-bpps.sum(-1))[:,:,None])\n",
        "    features.append(bpps.max(-1)[:,:,None])\n",
        "    features.append((bpps > 0).mean(-1)[:,:,None])\n",
        "    features.append(np.array(df['structure'].apply(get_structure_feature).values.tolist())/130)\n",
        "    return np.concatenate(features, axis=-1)\n",
        "\n",
        "print('processing train')\n",
        "train_snfilter = train.SN_filter.values\n",
        "train_inputs = preprocess_inputs(train)\n",
        "train_inputs = np.pad(train_inputs,((0, 0), (0, 130-107), (0, 0)))\n",
        "\n",
        "train_inputs_aug = preprocess_inputs(train_aug)\n",
        "train_inputs_aug = np.pad(train_inputs_aug,((0, 0), (0, 130-107), (0, 0)))\n",
        "train_ids_aug = train_aug['id'].values\n",
        "\n",
        "train_weights = np.array(train.signal_to_noise.values.tolist())\n",
        "train_weights_aug = np.array(train_aug.signal_to_noise.values.tolist())\n",
        "\n",
        "train_labels = np.array(train[target_cols].values.tolist()).transpose((0, 2, 1))\n",
        "train_labels_aug = np.array(train_aug[target_cols].values.tolist()).transpose((0, 2, 1))\n",
        "\n",
        "print('Original Train:', train_inputs.shape, train_labels.shape, train_weights.shape)\n",
        "print('Augmented Train:', train_inputs_aug.shape, train_labels_aug.shape, train_weights_aug.shape)\n",
        "\n",
        "train_adj = np.array(train['structure'].apply(get_adj).values.tolist())\n",
        "train_adj = np.pad(train_adj, ((0,0),(0,130-107),(0,130-107)), 'constant')\n",
        "train_adj_aug = np.array(train_aug['structure'].apply(get_adj).values.tolist())\n",
        "train_adj_aug = np.pad(train_adj_aug, ((0,0),(0,130-107),(0,130-107)), 'constant')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing train\n",
            "Original Train: (2400, 130, 20) (2400, 68, 5) (2400,)\n",
            "Augmented Train: (2400, 130, 20) (2400, 68, 5) (2400,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:52.597137Z",
          "iopub.status.busy": "2020-10-01T01:55:52.596220Z",
          "iopub.status.idle": "2020-10-01T01:55:57.403347Z",
          "shell.execute_reply": "2020-10-01T01:55:57.402442Z"
        },
        "papermill": {
          "duration": 4.878349,
          "end_time": "2020-10-01T01:55:57.403509",
          "exception": false,
          "start_time": "2020-10-01T01:55:52.525160",
          "status": "completed"
        },
        "tags": [],
        "id": "RvcT3O61aItE",
        "outputId": "8a2286b9-8dfe-4fb3-c2e9-f0e64e9f5bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#get different test sets and process each\n",
        "public_df = test.query(\"seq_length == 107\").copy()\n",
        "private_df = test.query(\"seq_length == 130\").copy()\n",
        "\n",
        "print('processing test')\n",
        "public_inputs = preprocess_inputs(public_df)\n",
        "public_inputs = np.pad(public_inputs,((0, 0), (0, 130-public_inputs.shape[1]), (0, 0)))\n",
        "\n",
        "private_inputs = preprocess_inputs(private_df)\n",
        "private_inputs = np.pad(private_inputs,((0, 0), (0, 130-private_inputs.shape[1]), (0, 0)))\n",
        "\n",
        "public_adj = np.array(public_df.loc[:, 'structure'].apply(get_adj).values.tolist())\n",
        "public_adj = np.pad(public_adj, ((0,0),(0,130-public_adj.shape[1]),(0,130-public_adj.shape[1])), 'constant')\n",
        "\n",
        "private_adj = np.array(private_df.loc[:, 'structure'].apply(get_adj).values.tolist())\n",
        "private_adj = np.pad(private_adj, ((0,0),(0,130-private_adj.shape[1]),(0,130-private_adj.shape[1])), 'constant')\n",
        "\n",
        "print('Test Sizes:', public_inputs.shape, public_adj.shape, private_inputs.shape, private_adj.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing test\n",
            "Test Sizes: (1258, 130, 20) (1258, 130, 130) (6010, 130, 20) (6010, 130, 130)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:57.523170Z",
          "iopub.status.busy": "2020-10-01T01:55:57.521931Z",
          "iopub.status.idle": "2020-10-01T01:55:57.566000Z",
          "shell.execute_reply": "2020-10-01T01:55:57.564873Z"
        },
        "papermill": {
          "duration": 0.106026,
          "end_time": "2020-10-01T01:55:57.566120",
          "exception": false,
          "start_time": "2020-10-01T01:55:57.460094",
          "status": "completed"
        },
        "tags": [],
        "id": "7OkSXb3xaItH",
        "outputId": "07c1b8b3-6db8-4945-d198-e6f669913a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "public_preds = np.load('/content/data/gtn_aug_snr_gru_public_preds.npy')\n",
        "public_std = public_preds.mean(3).mean(2).std(0)\n",
        "good_public = np.where(public_std < np.quantile(public_std, 0.13))[0]\n",
        "public_labels = public_preds.mean(0)[good_public][:,:68,:]\n",
        "print('Public Pseudo-labeling Sizes:', public_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public Pseudo-labeling Sizes: (164, 68, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:57.829572Z",
          "iopub.status.busy": "2020-10-01T01:55:57.828534Z",
          "iopub.status.idle": "2020-10-01T01:55:58.078416Z",
          "shell.execute_reply": "2020-10-01T01:55:58.079529Z"
        },
        "papermill": {
          "duration": 0.457064,
          "end_time": "2020-10-01T01:55:58.079750",
          "exception": false,
          "start_time": "2020-10-01T01:55:57.622686",
          "status": "completed"
        },
        "tags": [],
        "id": "eWjp5f_MaItJ",
        "outputId": "796239a2-4641-48aa-f9a5-90f83691c3e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "private_preds = np.load('/content/data/gtn_aug_snr_gru_private_preds.npy')\n",
        "private_std = private_preds.mean(3).mean(2).std(0)\n",
        "good_private = np.where(private_std < np.quantile(private_std, 0.13))[0]\n",
        "private_labels = private_preds.mean(0)[good_private][:,:68,:]\n",
        "print('Private Pseudo-labeling Sizes:', private_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Private Pseudo-labeling Sizes: (782, 68, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:58.274929Z",
          "iopub.status.busy": "2020-10-01T01:55:58.257981Z",
          "iopub.status.idle": "2020-10-01T01:55:58.307957Z",
          "shell.execute_reply": "2020-10-01T01:55:58.309296Z"
        },
        "papermill": {
          "duration": 0.146152,
          "end_time": "2020-10-01T01:55:58.309511",
          "exception": false,
          "start_time": "2020-10-01T01:55:58.163359",
          "status": "completed"
        },
        "tags": [],
        "id": "r8A1zztTaItL"
      },
      "source": [
        "nnodes = train_inputs.shape[-2]          # Number of nodes in the graphs\n",
        "nfeatures = train_inputs.shape[-1]          # Original feature dimensionality\n",
        "\n",
        "def cbr(x, out_layer, kernel, stride, dilation):\n",
        "        x = L.Conv1D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
        "        # x = L.BatchNormalization()(x)\n",
        "        x = L.Activation(\"relu\")(x)\n",
        "        return x\n",
        "\n",
        "def wave_block(x, filters, kernel_size, n):\n",
        "        dilation_rates = [2**i for i in range(n)]\n",
        "        x = tf.keras.layers.Conv1D(filters = filters,\n",
        "                   kernel_size = 1,\n",
        "                   padding = 'same')(x)\n",
        "        res_x = x\n",
        "        for dilation_rate in dilation_rates:\n",
        "            tanh_out = tf.keras.layers.Conv1D(filters = filters,\n",
        "                              kernel_size = kernel_size,\n",
        "                              padding = 'same', \n",
        "                              activation = 'tanh', \n",
        "                              dilation_rate = dilation_rate)(x)\n",
        "            sigm_out = tf.keras.layers.Conv1D(filters = filters,\n",
        "                              kernel_size = kernel_size,\n",
        "                              padding = 'same',\n",
        "                              activation = 'sigmoid', \n",
        "                              dilation_rate = dilation_rate)(x)\n",
        "            x = tf.keras.layers.Multiply()([tanh_out, sigm_out])\n",
        "            x = tf.keras.layers.Conv1D(filters = filters,\n",
        "                       kernel_size = 1,\n",
        "                       padding = 'same')(x)\n",
        "            res_x = tf.keras.layers.Add()([res_x, x])\n",
        "        return res_x\n",
        "\n",
        "def gru_layer(hidden_dim, dropout):\n",
        "    return tf.keras.layers.Bidirectional(\n",
        "                                tf.keras.layers.GRU(hidden_dim,\n",
        "                                dropout=dropout,\n",
        "                                return_sequences=True,\n",
        "                                kernel_initializer = 'orthogonal'))\n",
        "\n",
        "def lstm_layer(hidden_dim, dropout):\n",
        "    return tf.keras.layers.Bidirectional(\n",
        "                                tf.keras.layers.LSTM(hidden_dim,\n",
        "                                dropout=dropout,\n",
        "                                return_sequences=True,\n",
        "                                kernel_initializer = 'orthogonal'))\n",
        "\n",
        "def mcrmse_loss(y_true, y_pred):\n",
        "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
        "\n",
        "def mcrmse(y_true, y_pred):\n",
        "    diff = tf.reshape(y_true[:,:,:5] - y_pred, [-1, 5])\n",
        "    colwise_mse = tf.reduce_mean(tf.square(diff), axis=0)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse))\n",
        "\n",
        "\n",
        "def competition_metric(y_true, y_pred):\n",
        "    total = 0\n",
        "    for i in range(5):\n",
        "        rmse = np.mean((y_pred[:,:,i] - y_true[:,:,i])**2)**0.5\n",
        "        print('{:12s}: {:.4f}'.format(target_cols[i], rmse))\n",
        "        if target_cols[i] in ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']:\n",
        "            total += rmse/3\n",
        "    print('total:', total)\n",
        "\n",
        "def build_model(model_num=0,seq_len=130, pred_len=68, dropout=0.4,\n",
        "                embed_dim=512, hidden_dim=256):\n",
        "    \n",
        "    X_in = tf.keras.layers.Input(shape=(seq_len, nfeatures))\n",
        "    A_in = tf.keras.layers.Input(shape=(seq_len, seq_len))\n",
        "    embed = tf.keras.layers.Dense(embed_dim, activation='linear')(X_in)    \n",
        "        \n",
        "    gc1 = GraphAttention(embed_dim, activation='relu', dropout_rate=0.1)([X_in, A_in])\n",
        "    gc1 = tf.keras.layers.Dropout(.2)(gc1)\n",
        "    gc1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(gc1 + embed)\n",
        "    \n",
        "    gc2 = GraphAttention(embed_dim, activation='relu', dropout_rate=0.1)([gc1, A_in])\n",
        "    gc2 = tf.keras.layers.Dropout(.2)(gc2)\n",
        "    gc2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(gc2 + gc1)\n",
        "    \n",
        "    reshaped = tf.keras.layers.LayerNormalization(epsilon=1e-6)(gc2 + embed)\n",
        "    \n",
        "    \n",
        "    if model_num == 0:\n",
        "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "\n",
        "    if model_num == 1:\n",
        "        hidden =cbr(reshaped, 64, 7, 1, 1)\n",
        "        hidden = cbr(hidden, 64, 7, 1, 1)#\n",
        "        hidden = cbr(hidden, 64, 7, 1, 1)   \n",
        "              \n",
        "    if model_num == 2:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "\n",
        "    if model_num == 3:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "\n",
        "    if model_num == 4:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "\n",
        "    if model_num == 5:\n",
        "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden) \n",
        "        \n",
        "    if model_num == 6:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        \n",
        "    if model_num == 7:\n",
        "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "    \n",
        "    hidden = wave_block(hidden, 16, 3, 12)\n",
        "    hidden = wave_block(hidden, 32, 3, 8)\n",
        "    hidden = wave_block(hidden, 64, 3, 4)\n",
        "    hidden = wave_block(hidden, 128, 3, 1)\n",
        "    \n",
        "    #only making predictions on the first part of each sequence\n",
        "    truncated = hidden[:, :pred_len]\n",
        "    \n",
        "    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[X_in, A_in], outputs=out)\n",
        "\n",
        "    #some optimizers\n",
        "    adam = tf.optimizers.Adam()\n",
        "    \n",
        "    model.compile(optimizer = adam, loss=mcrmse_loss)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:58.485135Z",
          "iopub.status.busy": "2020-10-01T01:55:58.484268Z",
          "iopub.status.idle": "2020-10-01T01:55:58.488357Z",
          "shell.execute_reply": "2020-10-01T01:55:58.487814Z"
        },
        "papermill": {
          "duration": 0.097,
          "end_time": "2020-10-01T01:55:58.488480",
          "exception": false,
          "start_time": "2020-10-01T01:55:58.391480",
          "status": "completed"
        },
        "tags": [],
        "id": "eT57g8JmaItN"
      },
      "source": [
        "#basic training configuration\n",
        "FOLDS = 10\n",
        "EPOCHS = 500\n",
        "BATCH_SIZE = 64*len(gpus)\n",
        "VERBOSE = 1\n",
        "\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(verbose=VERBOSE, factor=0.9, patience = 5 )\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=VERBOSE, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o-n-i6x7ppv"
      },
      "source": [
        "import tensorflow.keras.layers as L\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T01:55:58.629846Z",
          "iopub.status.busy": "2020-10-01T01:55:58.619409Z",
          "iopub.status.idle": "2020-10-01T06:39:54.540864Z",
          "shell.execute_reply": "2020-10-01T06:39:54.542107Z"
        },
        "papermill": {
          "duration": 17035.99745,
          "end_time": "2020-10-01T06:39:54.542340",
          "exception": false,
          "start_time": "2020-10-01T01:55:58.544890",
          "status": "completed"
        },
        "tags": [],
        "id": "2moDM897aItP",
        "outputId": "c091993b-329a-4687-a2b6-c79033e17ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = KFold(FOLDS, shuffle = True, random_state = 34)\n",
        "\n",
        "#strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "model_name = 'gtn_aug_snr'\n",
        "\n",
        "train_ids = train['id'].values\n",
        "\n",
        "models = [0,1,2,3]\n",
        "\n",
        "gru_private_preds = [None]*len(models)\n",
        "gru_public_preds = [None]*len(models)\n",
        "oof = [None]*len(models)\n",
        "\n",
        "for model_num in models:\n",
        "    \n",
        "    gru_private_preds[model_num] = np.zeros((private_df.shape[0], 130, 5))\n",
        "    gru_public_preds[model_num] = np.zeros((public_df.shape[0], 107, 5))\n",
        "    oof[model_num] = np.zeros((train_labels.shape[0], 68, 5))\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(list(kfold.split(train_inputs))[:]):\n",
        "        print('Fold:', fold, ' model_num:', model_num)\n",
        "        cp = tf.keras.callbacks.ModelCheckpoint(f'{model_name}_{fold}_{model_num}.h5', monitor='val_loss', verbose=VERBOSE, save_best_only=True,\n",
        "            save_weights_only=True, mode='auto', save_freq='epoch')\n",
        "        \n",
        "        #train_index = train_index[train_snfilter[train_index] == 1]\n",
        "        train_X = train_inputs[train_index]\n",
        "        train_y = train_labels[train_index]\n",
        "        train_A = train_adj[train_index]\n",
        "        train_W = train_weights[train_index]\n",
        "        \n",
        "        if 1:\n",
        "            aug_indx = np.isin(train_ids_aug, train_ids[train_index])    \n",
        "            train_X_aug = train_inputs_aug[aug_indx]\n",
        "            train_y_aug = train_labels_aug[aug_indx]\n",
        "            train_A_aug = train_adj_aug[aug_indx]\n",
        "            train_W_aug = train_weights_aug[aug_indx]\n",
        "\n",
        "            train_X = np.concatenate((train_X, train_X_aug))\n",
        "            train_y = np.concatenate((train_y, train_y_aug))\n",
        "            train_A = np.concatenate((train_A, train_A_aug))\n",
        "            train_W = np.concatenate((train_W, train_W_aug))\n",
        "        \n",
        "        if 0:\n",
        "            train_X_aug = public_inputs[good_public]\n",
        "            train_A_aug = public_adj[good_public]\n",
        "            train_W_aug = train_weights[train_index].mean()*np.ones(train_X_aug.shape[0])\n",
        "            train_y_aug = public_labels\n",
        "\n",
        "            train_X = np.concatenate((train_X, train_X_aug))\n",
        "            train_y = np.concatenate((train_y, train_y_aug))\n",
        "            train_A = np.concatenate((train_A, train_A_aug))\n",
        "            train_W = np.concatenate((train_W, train_W_aug))    \n",
        "            \n",
        "            train_X_aug = private_inputs[good_private]\n",
        "            train_A_aug = private_adj[good_private]\n",
        "            train_W_aug = train_weights[train_index].mean()*np.ones(train_X_aug.shape[0])\n",
        "            train_y_aug = private_labels\n",
        "\n",
        "            train_X = np.concatenate((train_X, train_X_aug))\n",
        "            train_y = np.concatenate((train_y, train_y_aug))\n",
        "            train_A = np.concatenate((train_A, train_A_aug))\n",
        "            train_W = np.concatenate((train_W, train_W_aug)) \n",
        "        \n",
        "        print(train_X.shape)\n",
        "        \n",
        "        val_index = val_index[train_snfilter[val_index] == 1]\n",
        "        valid_X = train_inputs[val_index]\n",
        "        valid_y = train_labels[val_index]\n",
        "        valid_A = train_adj[val_index]\n",
        "        \n",
        "        model = build_model(model_num)\n",
        "        history = model.fit([train_X,train_A], train_y, sample_weight = train_W, validation_data=([valid_X,valid_A],valid_y), \n",
        "                            batch_size=BATCH_SIZE, epochs=EPOCHS,callbacks=[lr,cp,es],verbose = VERBOSE)      \n",
        "        \n",
        "        model.load_weights(f'{model_name}_{fold}_{model_num}.h5')\n",
        "        oof[model_num][val_index] = model.predict([valid_X,valid_A])\n",
        "        \n",
        "        competition_metric(valid_y, oof[model_num][val_index])\n",
        "    \n",
        "        \n",
        "        if 1:\n",
        "            #load best model and predict\n",
        "            gru_short = build_model(model_num, pred_len=107)\n",
        "            gru_short.load_weights(f'{model_name}_{fold}_{model_num}.h5')\n",
        "            gru_public_pred = gru_short.predict([public_inputs,public_adj]) / FOLDS\n",
        "            \n",
        "            gru_long = build_model(model_num, pred_len=130)\n",
        "            gru_long.load_weights(f'{model_name}_{fold}_{model_num}.h5')\n",
        "            gru_private_pred = gru_long.predict([private_inputs, private_adj]) / FOLDS\n",
        "            \n",
        "            gru_public_preds[model_num] += gru_public_pred\n",
        "            gru_private_preds[model_num] += gru_private_pred\n",
        "      \n",
        "    print('===================OOF RMSE=================')\n",
        "    competition_metric(train_labels[train_snfilter == 1], oof[model_num][train_snfilter == 1])\n",
        "    print('============================================')\n",
        "\n",
        "\n",
        "print('===================COMBINED OOF RMSE=================')\n",
        "competition_metric(train_labels[train_snfilter == 1], np.mean(oof, axis=0)[train_snfilter == 1])\n",
        "print('=====================================================')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 0  model_num: 0\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.2770\n",
            "Epoch 00001: val_loss improved from inf to 0.32976, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 24s 359ms/step - loss: 2.2770 - val_loss: 0.3298\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4934\n",
            "Epoch 00002: val_loss improved from 0.32976 to 0.31037, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.4934 - val_loss: 0.3104\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3840\n",
            "Epoch 00003: val_loss improved from 0.31037 to 0.28511, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3840 - val_loss: 0.2851\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3138\n",
            "Epoch 00004: val_loss improved from 0.28511 to 0.27326, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3138 - val_loss: 0.2733\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2533\n",
            "Epoch 00005: val_loss improved from 0.27326 to 0.24918, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.2533 - val_loss: 0.2492\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1953\n",
            "Epoch 00006: val_loss improved from 0.24918 to 0.24564, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1953 - val_loss: 0.2456\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1562\n",
            "Epoch 00007: val_loss improved from 0.24564 to 0.23558, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.1562 - val_loss: 0.2356\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1304\n",
            "Epoch 00008: val_loss improved from 0.23558 to 0.23121, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1304 - val_loss: 0.2312\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0896\n",
            "Epoch 00009: val_loss improved from 0.23121 to 0.22341, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.0896 - val_loss: 0.2234\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0572\n",
            "Epoch 00010: val_loss improved from 0.22341 to 0.21968, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0572 - val_loss: 0.2197\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0245\n",
            "Epoch 00011: val_loss improved from 0.21968 to 0.21680, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.0245 - val_loss: 0.2168\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9989\n",
            "Epoch 00012: val_loss improved from 0.21680 to 0.21502, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9989 - val_loss: 0.2150\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9804\n",
            "Epoch 00013: val_loss improved from 0.21502 to 0.21208, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9804 - val_loss: 0.2121\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9583\n",
            "Epoch 00014: val_loss did not improve from 0.21208\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.9583 - val_loss: 0.2123\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9388\n",
            "Epoch 00015: val_loss improved from 0.21208 to 0.20734, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9388 - val_loss: 0.2073\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9251\n",
            "Epoch 00016: val_loss improved from 0.20734 to 0.20675, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9251 - val_loss: 0.2067\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9055\n",
            "Epoch 00017: val_loss did not improve from 0.20675\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.9055 - val_loss: 0.2092\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8938\n",
            "Epoch 00018: val_loss improved from 0.20675 to 0.20165, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.8938 - val_loss: 0.2016\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8803\n",
            "Epoch 00019: val_loss did not improve from 0.20165\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8803 - val_loss: 0.2078\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8657\n",
            "Epoch 00020: val_loss did not improve from 0.20165\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8657 - val_loss: 0.2025\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8487\n",
            "Epoch 00021: val_loss did not improve from 0.20165\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8487 - val_loss: 0.2024\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8408\n",
            "Epoch 00022: val_loss improved from 0.20165 to 0.20039, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8408 - val_loss: 0.2004\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8287\n",
            "Epoch 00023: val_loss improved from 0.20039 to 0.19572, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8287 - val_loss: 0.1957\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8085\n",
            "Epoch 00024: val_loss did not improve from 0.19572\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8085 - val_loss: 0.1963\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7987\n",
            "Epoch 00025: val_loss did not improve from 0.19572\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7987 - val_loss: 0.1964\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7966\n",
            "Epoch 00026: val_loss did not improve from 0.19572\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7966 - val_loss: 0.1984\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7869\n",
            "Epoch 00027: val_loss did not improve from 0.19572\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7869 - val_loss: 0.1963\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7740\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.19572\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7740 - val_loss: 0.1966\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7598\n",
            "Epoch 00029: val_loss improved from 0.19572 to 0.19400, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7598 - val_loss: 0.1940\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7522\n",
            "Epoch 00030: val_loss improved from 0.19400 to 0.19324, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7522 - val_loss: 0.1932\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7428\n",
            "Epoch 00031: val_loss did not improve from 0.19324\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.7428 - val_loss: 0.1940\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7347\n",
            "Epoch 00032: val_loss did not improve from 0.19324\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.7347 - val_loss: 0.1938\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7291\n",
            "Epoch 00033: val_loss did not improve from 0.19324\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7291 - val_loss: 0.1983\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7249\n",
            "Epoch 00034: val_loss did not improve from 0.19324\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7249 - val_loss: 0.1942\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7227\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.19324\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.7227 - val_loss: 0.1947\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7148\n",
            "Epoch 00036: val_loss improved from 0.19324 to 0.19185, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7148 - val_loss: 0.1918\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7004\n",
            "Epoch 00037: val_loss improved from 0.19185 to 0.19117, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7004 - val_loss: 0.1912\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6942\n",
            "Epoch 00038: val_loss did not improve from 0.19117\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6942 - val_loss: 0.1945\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6901\n",
            "Epoch 00039: val_loss did not improve from 0.19117\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6901 - val_loss: 0.1913\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6887\n",
            "Epoch 00040: val_loss did not improve from 0.19117\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6887 - val_loss: 0.1918\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6785\n",
            "Epoch 00041: val_loss did not improve from 0.19117\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6785 - val_loss: 0.1920\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6743\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.19117\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6743 - val_loss: 0.1915\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6684\n",
            "Epoch 00043: val_loss improved from 0.19117 to 0.19105, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6684 - val_loss: 0.1911\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6637\n",
            "Epoch 00044: val_loss improved from 0.19105 to 0.19017, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6637 - val_loss: 0.1902\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6605\n",
            "Epoch 00045: val_loss did not improve from 0.19017\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6605 - val_loss: 0.1932\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6579\n",
            "Epoch 00046: val_loss did not improve from 0.19017\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6579 - val_loss: 0.1911\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6553\n",
            "Epoch 00047: val_loss improved from 0.19017 to 0.18998, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6553 - val_loss: 0.1900\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6469\n",
            "Epoch 00048: val_loss did not improve from 0.18998\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6469 - val_loss: 0.1924\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6438\n",
            "Epoch 00049: val_loss did not improve from 0.18998\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6438 - val_loss: 0.1900\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6393\n",
            "Epoch 00050: val_loss did not improve from 0.18998\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6393 - val_loss: 0.1914\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6374\n",
            "Epoch 00051: val_loss did not improve from 0.18998\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6374 - val_loss: 0.1910\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6326\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.18998\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6326 - val_loss: 0.1907\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6265\n",
            "Epoch 00053: val_loss improved from 0.18998 to 0.18971, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6265 - val_loss: 0.1897\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6228\n",
            "Epoch 00054: val_loss did not improve from 0.18971\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6228 - val_loss: 0.1906\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6217\n",
            "Epoch 00055: val_loss did not improve from 0.18971\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6217 - val_loss: 0.1906\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6171\n",
            "Epoch 00056: val_loss improved from 0.18971 to 0.18948, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6171 - val_loss: 0.1895\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6140\n",
            "Epoch 00057: val_loss improved from 0.18948 to 0.18802, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6140 - val_loss: 0.1880\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6108\n",
            "Epoch 00058: val_loss did not improve from 0.18802\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6108 - val_loss: 0.1898\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6093\n",
            "Epoch 00059: val_loss did not improve from 0.18802\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6093 - val_loss: 0.1896\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6049\n",
            "Epoch 00060: val_loss improved from 0.18802 to 0.18767, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6049 - val_loss: 0.1877\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6017\n",
            "Epoch 00061: val_loss did not improve from 0.18767\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6017 - val_loss: 0.1905\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6011\n",
            "Epoch 00062: val_loss did not improve from 0.18767\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6011 - val_loss: 0.1891\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5972\n",
            "Epoch 00063: val_loss did not improve from 0.18767\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5972 - val_loss: 0.1878\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5944\n",
            "Epoch 00064: val_loss did not improve from 0.18767\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5944 - val_loss: 0.1893\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5941\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.18767\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5941 - val_loss: 0.1891\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5861\n",
            "Epoch 00066: val_loss did not improve from 0.18767\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5861 - val_loss: 0.1889\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5824\n",
            "Epoch 00067: val_loss improved from 0.18767 to 0.18720, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5824 - val_loss: 0.1872\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5801\n",
            "Epoch 00068: val_loss improved from 0.18720 to 0.18668, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5801 - val_loss: 0.1867\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5780\n",
            "Epoch 00069: val_loss did not improve from 0.18668\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5780 - val_loss: 0.1899\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5782\n",
            "Epoch 00070: val_loss did not improve from 0.18668\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5782 - val_loss: 0.1876\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5749\n",
            "Epoch 00071: val_loss did not improve from 0.18668\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5749 - val_loss: 0.1874\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5713\n",
            "Epoch 00072: val_loss did not improve from 0.18668\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5713 - val_loss: 0.1882\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5693\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.18668\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5693 - val_loss: 0.1887\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5680\n",
            "Epoch 00074: val_loss did not improve from 0.18668\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5680 - val_loss: 0.1896\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5631\n",
            "Epoch 00075: val_loss did not improve from 0.18668\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5631 - val_loss: 0.1873\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5584\n",
            "Epoch 00076: val_loss did not improve from 0.18668\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5584 - val_loss: 0.1871\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5581\n",
            "Epoch 00077: val_loss improved from 0.18668 to 0.18618, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5581 - val_loss: 0.1862\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5549\n",
            "Epoch 00078: val_loss did not improve from 0.18618\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5549 - val_loss: 0.1872\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5546\n",
            "Epoch 00079: val_loss did not improve from 0.18618\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5546 - val_loss: 0.1887\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5518\n",
            "Epoch 00080: val_loss did not improve from 0.18618\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5518 - val_loss: 0.1875\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5513\n",
            "Epoch 00081: val_loss did not improve from 0.18618\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5513 - val_loss: 0.1868\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5520\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.18618\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5520 - val_loss: 0.1873\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5455\n",
            "Epoch 00083: val_loss did not improve from 0.18618\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5455 - val_loss: 0.1868\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5431\n",
            "Epoch 00084: val_loss did not improve from 0.18618\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5431 - val_loss: 0.1871\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5409\n",
            "Epoch 00085: val_loss did not improve from 0.18618\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5409 - val_loss: 0.1874\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5384\n",
            "Epoch 00086: val_loss did not improve from 0.18618\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5384 - val_loss: 0.1873\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5378\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.18618\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5378 - val_loss: 0.1873\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5349\n",
            "Epoch 00088: val_loss improved from 0.18618 to 0.18598, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5349 - val_loss: 0.1860\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5317\n",
            "Epoch 00089: val_loss improved from 0.18598 to 0.18551, saving model to gtn_aug_snr_0_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5317 - val_loss: 0.1855\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5289\n",
            "Epoch 00090: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5289 - val_loss: 0.1869\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5285\n",
            "Epoch 00091: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5285 - val_loss: 0.1873\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5273\n",
            "Epoch 00092: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5273 - val_loss: 0.1871\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5257\n",
            "Epoch 00093: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5257 - val_loss: 0.1861\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5239\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5239 - val_loss: 0.1865\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5221\n",
            "Epoch 00095: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5221 - val_loss: 0.1862\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5195\n",
            "Epoch 00096: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5195 - val_loss: 0.1858\n",
            "Epoch 97/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5175\n",
            "Epoch 00097: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5175 - val_loss: 0.1871\n",
            "Epoch 98/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5155\n",
            "Epoch 00098: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5155 - val_loss: 0.1872\n",
            "Epoch 99/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5145\n",
            "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5145 - val_loss: 0.1866\n",
            "Epoch 100/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5120\n",
            "Epoch 00100: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5120 - val_loss: 0.1858\n",
            "Epoch 101/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5095\n",
            "Epoch 00101: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5095 - val_loss: 0.1868\n",
            "Epoch 102/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5112\n",
            "Epoch 00102: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5112 - val_loss: 0.1870\n",
            "Epoch 103/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5082\n",
            "Epoch 00103: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5082 - val_loss: 0.1863\n",
            "Epoch 104/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5069\n",
            "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.18551\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5069 - val_loss: 0.1860\n",
            "Epoch 00104: early stopping\n",
            "reactivity  : 0.1878\n",
            "deg_Mg_pH10 : 0.2174\n",
            "deg_pH10    : 0.2096\n",
            "deg_Mg_50C  : 0.1806\n",
            "deg_50C     : 0.1961\n",
            "total: 0.195264384522353\n",
            "Fold: 1  model_num: 0\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.4907\n",
            "Epoch 00001: val_loss improved from inf to 0.33187, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 24s 353ms/step - loss: 2.4907 - val_loss: 0.3319\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.5132\n",
            "Epoch 00002: val_loss improved from 0.33187 to 0.29740, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.5132 - val_loss: 0.2974\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3852\n",
            "Epoch 00003: val_loss improved from 0.29740 to 0.28029, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3852 - val_loss: 0.2803\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3076\n",
            "Epoch 00004: val_loss improved from 0.28029 to 0.26780, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3076 - val_loss: 0.2678\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2528\n",
            "Epoch 00005: val_loss improved from 0.26780 to 0.25577, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.2528 - val_loss: 0.2558\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1940\n",
            "Epoch 00006: val_loss did not improve from 0.25577\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 1.1940 - val_loss: 0.2566\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1546\n",
            "Epoch 00007: val_loss improved from 0.25577 to 0.24398, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1546 - val_loss: 0.2440\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1220\n",
            "Epoch 00008: val_loss improved from 0.24398 to 0.23635, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1220 - val_loss: 0.2363\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0896\n",
            "Epoch 00009: val_loss improved from 0.23635 to 0.23426, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0896 - val_loss: 0.2343\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0601\n",
            "Epoch 00010: val_loss improved from 0.23426 to 0.23401, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0601 - val_loss: 0.2340\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0306\n",
            "Epoch 00011: val_loss improved from 0.23401 to 0.22617, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0306 - val_loss: 0.2262\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0082\n",
            "Epoch 00012: val_loss improved from 0.22617 to 0.22306, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0082 - val_loss: 0.2231\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9829\n",
            "Epoch 00013: val_loss did not improve from 0.22306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.9829 - val_loss: 0.2257\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9666\n",
            "Epoch 00014: val_loss did not improve from 0.22306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.9666 - val_loss: 0.2241\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9463\n",
            "Epoch 00015: val_loss improved from 0.22306 to 0.22073, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9463 - val_loss: 0.2207\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9274\n",
            "Epoch 00016: val_loss improved from 0.22073 to 0.21786, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9274 - val_loss: 0.2179\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9130\n",
            "Epoch 00017: val_loss improved from 0.21786 to 0.21493, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9130 - val_loss: 0.2149\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8918\n",
            "Epoch 00018: val_loss did not improve from 0.21493\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8918 - val_loss: 0.2198\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8795\n",
            "Epoch 00019: val_loss did not improve from 0.21493\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8795 - val_loss: 0.2159\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8625\n",
            "Epoch 00020: val_loss improved from 0.21493 to 0.21201, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8625 - val_loss: 0.2120\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8520\n",
            "Epoch 00021: val_loss did not improve from 0.21201\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8520 - val_loss: 0.2121\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8363\n",
            "Epoch 00022: val_loss improved from 0.21201 to 0.20822, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8363 - val_loss: 0.2082\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8215\n",
            "Epoch 00023: val_loss did not improve from 0.20822\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8215 - val_loss: 0.2084\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8157\n",
            "Epoch 00024: val_loss did not improve from 0.20822\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.8157 - val_loss: 0.2095\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8038\n",
            "Epoch 00025: val_loss did not improve from 0.20822\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8038 - val_loss: 0.2088\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7930\n",
            "Epoch 00026: val_loss improved from 0.20822 to 0.20479, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7930 - val_loss: 0.2048\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7816\n",
            "Epoch 00027: val_loss improved from 0.20479 to 0.20408, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7816 - val_loss: 0.2041\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7751\n",
            "Epoch 00028: val_loss did not improve from 0.20408\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7751 - val_loss: 0.2053\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7664\n",
            "Epoch 00029: val_loss improved from 0.20408 to 0.20402, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7664 - val_loss: 0.2040\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7556\n",
            "Epoch 00030: val_loss did not improve from 0.20402\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7556 - val_loss: 0.2054\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7479\n",
            "Epoch 00031: val_loss improved from 0.20402 to 0.20386, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7479 - val_loss: 0.2039\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7405\n",
            "Epoch 00032: val_loss did not improve from 0.20386\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7405 - val_loss: 0.2044\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7319\n",
            "Epoch 00033: val_loss improved from 0.20386 to 0.20124, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7319 - val_loss: 0.2012\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7286\n",
            "Epoch 00034: val_loss did not improve from 0.20124\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7286 - val_loss: 0.2027\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7197\n",
            "Epoch 00035: val_loss did not improve from 0.20124\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7197 - val_loss: 0.2021\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7128\n",
            "Epoch 00036: val_loss improved from 0.20124 to 0.20021, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7128 - val_loss: 0.2002\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7079\n",
            "Epoch 00037: val_loss did not improve from 0.20021\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7079 - val_loss: 0.2005\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7031\n",
            "Epoch 00038: val_loss improved from 0.20021 to 0.19997, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7031 - val_loss: 0.2000\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6942\n",
            "Epoch 00039: val_loss did not improve from 0.19997\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6942 - val_loss: 0.2003\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6866\n",
            "Epoch 00040: val_loss improved from 0.19997 to 0.19967, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6866 - val_loss: 0.1997\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6837\n",
            "Epoch 00041: val_loss did not improve from 0.19967\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6837 - val_loss: 0.2013\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6814\n",
            "Epoch 00042: val_loss did not improve from 0.19967\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6814 - val_loss: 0.2002\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6724\n",
            "Epoch 00043: val_loss did not improve from 0.19967\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6724 - val_loss: 0.2024\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6783\n",
            "Epoch 00044: val_loss improved from 0.19967 to 0.19931, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6783 - val_loss: 0.1993\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6636\n",
            "Epoch 00045: val_loss did not improve from 0.19931\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6636 - val_loss: 0.2002\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6619\n",
            "Epoch 00046: val_loss improved from 0.19931 to 0.19922, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6619 - val_loss: 0.1992\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6560\n",
            "Epoch 00047: val_loss improved from 0.19922 to 0.19821, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6560 - val_loss: 0.1982\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6522\n",
            "Epoch 00048: val_loss did not improve from 0.19821\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6522 - val_loss: 0.1983\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6471\n",
            "Epoch 00049: val_loss did not improve from 0.19821\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6471 - val_loss: 0.1990\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6415\n",
            "Epoch 00050: val_loss did not improve from 0.19821\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6415 - val_loss: 0.1997\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6353\n",
            "Epoch 00051: val_loss improved from 0.19821 to 0.19736, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6353 - val_loss: 0.1974\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6329\n",
            "Epoch 00052: val_loss did not improve from 0.19736\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6329 - val_loss: 0.2008\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6346\n",
            "Epoch 00053: val_loss did not improve from 0.19736\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6346 - val_loss: 0.1994\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6274\n",
            "Epoch 00054: val_loss did not improve from 0.19736\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6274 - val_loss: 0.1982\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6226\n",
            "Epoch 00055: val_loss improved from 0.19736 to 0.19605, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6226 - val_loss: 0.1960\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6183\n",
            "Epoch 00056: val_loss did not improve from 0.19605\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6183 - val_loss: 0.1990\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6162\n",
            "Epoch 00057: val_loss did not improve from 0.19605\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6162 - val_loss: 0.1980\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6139\n",
            "Epoch 00058: val_loss did not improve from 0.19605\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6139 - val_loss: 0.1972\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6105\n",
            "Epoch 00059: val_loss did not improve from 0.19605\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6105 - val_loss: 0.1981\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6062\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.19605\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6062 - val_loss: 0.1972\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6001\n",
            "Epoch 00061: val_loss did not improve from 0.19605\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6001 - val_loss: 0.1977\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5952\n",
            "Epoch 00062: val_loss improved from 0.19605 to 0.19535, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5952 - val_loss: 0.1954\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5910\n",
            "Epoch 00063: val_loss did not improve from 0.19535\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5910 - val_loss: 0.1977\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5883\n",
            "Epoch 00064: val_loss did not improve from 0.19535\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5883 - val_loss: 0.1958\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5836\n",
            "Epoch 00065: val_loss improved from 0.19535 to 0.19523, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5836 - val_loss: 0.1952\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5837\n",
            "Epoch 00066: val_loss improved from 0.19523 to 0.19501, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5837 - val_loss: 0.1950\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5838\n",
            "Epoch 00067: val_loss did not improve from 0.19501\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5838 - val_loss: 0.1962\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5788\n",
            "Epoch 00068: val_loss did not improve from 0.19501\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5788 - val_loss: 0.1967\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5780\n",
            "Epoch 00069: val_loss did not improve from 0.19501\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5780 - val_loss: 0.1959\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5726\n",
            "Epoch 00070: val_loss did not improve from 0.19501\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5726 - val_loss: 0.1968\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5725\n",
            "Epoch 00071: val_loss improved from 0.19501 to 0.19490, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.5725 - val_loss: 0.1949\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5681\n",
            "Epoch 00072: val_loss did not improve from 0.19490\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5681 - val_loss: 0.1965\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5662\n",
            "Epoch 00073: val_loss did not improve from 0.19490\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5662 - val_loss: 0.1955\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5633\n",
            "Epoch 00074: val_loss did not improve from 0.19490\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5633 - val_loss: 0.1969\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5621\n",
            "Epoch 00075: val_loss improved from 0.19490 to 0.19472, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5621 - val_loss: 0.1947\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5620\n",
            "Epoch 00076: val_loss did not improve from 0.19472\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5620 - val_loss: 0.1958\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5643\n",
            "Epoch 00077: val_loss did not improve from 0.19472\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5643 - val_loss: 0.1965\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5602\n",
            "Epoch 00078: val_loss did not improve from 0.19472\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5602 - val_loss: 0.1969\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5563\n",
            "Epoch 00079: val_loss did not improve from 0.19472\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5563 - val_loss: 0.1959\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5530\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.19472\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5530 - val_loss: 0.1950\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5454\n",
            "Epoch 00081: val_loss did not improve from 0.19472\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5454 - val_loss: 0.1950\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5429\n",
            "Epoch 00082: val_loss did not improve from 0.19472\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5429 - val_loss: 0.1949\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5406\n",
            "Epoch 00083: val_loss improved from 0.19472 to 0.19461, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5406 - val_loss: 0.1946\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5374\n",
            "Epoch 00084: val_loss did not improve from 0.19461\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5374 - val_loss: 0.1954\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5354\n",
            "Epoch 00085: val_loss did not improve from 0.19461\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5354 - val_loss: 0.1952\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5364\n",
            "Epoch 00086: val_loss improved from 0.19461 to 0.19448, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5364 - val_loss: 0.1945\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5342\n",
            "Epoch 00087: val_loss did not improve from 0.19448\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5342 - val_loss: 0.1961\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5311\n",
            "Epoch 00088: val_loss did not improve from 0.19448\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5311 - val_loss: 0.1955\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5311\n",
            "Epoch 00089: val_loss did not improve from 0.19448\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5311 - val_loss: 0.1960\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5266\n",
            "Epoch 00090: val_loss did not improve from 0.19448\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5266 - val_loss: 0.1955\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5256\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.19448\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5256 - val_loss: 0.1948\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5209\n",
            "Epoch 00092: val_loss did not improve from 0.19448\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5209 - val_loss: 0.1945\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5170\n",
            "Epoch 00093: val_loss did not improve from 0.19448\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5170 - val_loss: 0.1945\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5169\n",
            "Epoch 00094: val_loss did not improve from 0.19448\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5169 - val_loss: 0.1953\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5125\n",
            "Epoch 00095: val_loss did not improve from 0.19448\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5125 - val_loss: 0.1958\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5111\n",
            "Epoch 00096: val_loss improved from 0.19448 to 0.19390, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.5111 - val_loss: 0.1939\n",
            "Epoch 97/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5100\n",
            "Epoch 00097: val_loss did not improve from 0.19390\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5100 - val_loss: 0.1945\n",
            "Epoch 98/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5098\n",
            "Epoch 00098: val_loss did not improve from 0.19390\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5098 - val_loss: 0.1942\n",
            "Epoch 99/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5081\n",
            "Epoch 00099: val_loss did not improve from 0.19390\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5081 - val_loss: 0.1947\n",
            "Epoch 100/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5087\n",
            "Epoch 00100: val_loss did not improve from 0.19390\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5087 - val_loss: 0.1962\n",
            "Epoch 101/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5058\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.19390\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5058 - val_loss: 0.1956\n",
            "Epoch 102/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4999\n",
            "Epoch 00102: val_loss did not improve from 0.19390\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4999 - val_loss: 0.1942\n",
            "Epoch 103/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4983\n",
            "Epoch 00103: val_loss did not improve from 0.19390\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4983 - val_loss: 0.1954\n",
            "Epoch 104/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4957\n",
            "Epoch 00104: val_loss improved from 0.19390 to 0.19366, saving model to gtn_aug_snr_1_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.4957 - val_loss: 0.1937\n",
            "Epoch 105/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4932\n",
            "Epoch 00105: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4932 - val_loss: 0.1949\n",
            "Epoch 106/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4931\n",
            "Epoch 00106: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4931 - val_loss: 0.1944\n",
            "Epoch 107/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4919\n",
            "Epoch 00107: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4919 - val_loss: 0.1945\n",
            "Epoch 108/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4914\n",
            "Epoch 00108: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4914 - val_loss: 0.1945\n",
            "Epoch 109/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4910\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4910 - val_loss: 0.1951\n",
            "Epoch 110/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4854\n",
            "Epoch 00110: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4854 - val_loss: 0.1938\n",
            "Epoch 111/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4831\n",
            "Epoch 00111: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4831 - val_loss: 0.1947\n",
            "Epoch 112/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4803\n",
            "Epoch 00112: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4803 - val_loss: 0.1944\n",
            "Epoch 113/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4804\n",
            "Epoch 00113: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4804 - val_loss: 0.1966\n",
            "Epoch 114/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4795\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4795 - val_loss: 0.1958\n",
            "Epoch 115/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4746\n",
            "Epoch 00115: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4746 - val_loss: 0.1955\n",
            "Epoch 116/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4717\n",
            "Epoch 00116: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4717 - val_loss: 0.1943\n",
            "Epoch 117/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4714\n",
            "Epoch 00117: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4714 - val_loss: 0.1950\n",
            "Epoch 118/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4702\n",
            "Epoch 00118: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4702 - val_loss: 0.1946\n",
            "Epoch 119/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4692\n",
            "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.19366\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4692 - val_loss: 0.1958\n",
            "Epoch 00119: early stopping\n",
            "reactivity  : 0.1950\n",
            "deg_Mg_pH10 : 0.2287\n",
            "deg_pH10    : 0.2288\n",
            "deg_Mg_50C  : 0.1941\n",
            "deg_50C     : 0.1928\n",
            "total: 0.2059354750297553\n",
            "Fold: 2  model_num: 0\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            " 2/68 [..............................] - ETA: 9s - loss: 4.6281WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1118s vs `on_train_batch_end` time: 0.1702s). Check your callbacks.\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.5354\n",
            "Epoch 00001: val_loss improved from inf to 0.37093, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 23s 345ms/step - loss: 2.5354 - val_loss: 0.3709\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.5371\n",
            "Epoch 00002: val_loss improved from 0.37093 to 0.31516, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.5371 - val_loss: 0.3152\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4091\n",
            "Epoch 00003: val_loss improved from 0.31516 to 0.28803, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.4091 - val_loss: 0.2880\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3428\n",
            "Epoch 00004: val_loss improved from 0.28803 to 0.26845, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3428 - val_loss: 0.2685\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2876\n",
            "Epoch 00005: val_loss did not improve from 0.26845\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 1.2876 - val_loss: 0.2702\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2290\n",
            "Epoch 00006: val_loss improved from 0.26845 to 0.24996, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.2290 - val_loss: 0.2500\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1850\n",
            "Epoch 00007: val_loss improved from 0.24996 to 0.24151, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1850 - val_loss: 0.2415\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1437\n",
            "Epoch 00008: val_loss did not improve from 0.24151\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 1.1437 - val_loss: 0.2433\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1254\n",
            "Epoch 00009: val_loss improved from 0.24151 to 0.23811, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1254 - val_loss: 0.2381\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0741\n",
            "Epoch 00010: val_loss improved from 0.23811 to 0.23768, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0741 - val_loss: 0.2377\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0509\n",
            "Epoch 00011: val_loss improved from 0.23768 to 0.22142, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0509 - val_loss: 0.2214\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0326\n",
            "Epoch 00012: val_loss did not improve from 0.22142\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 1.0326 - val_loss: 0.2224\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0111\n",
            "Epoch 00013: val_loss did not improve from 0.22142\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 1.0111 - val_loss: 0.2232\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9880\n",
            "Epoch 00014: val_loss improved from 0.22142 to 0.21909, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9880 - val_loss: 0.2191\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9685\n",
            "Epoch 00015: val_loss improved from 0.21909 to 0.21406, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9685 - val_loss: 0.2141\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9511\n",
            "Epoch 00016: val_loss improved from 0.21406 to 0.21214, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9511 - val_loss: 0.2121\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9359\n",
            "Epoch 00017: val_loss did not improve from 0.21214\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.9359 - val_loss: 0.2176\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9221\n",
            "Epoch 00018: val_loss improved from 0.21214 to 0.20940, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9221 - val_loss: 0.2094\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9043\n",
            "Epoch 00019: val_loss improved from 0.20940 to 0.20718, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9043 - val_loss: 0.2072\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8932\n",
            "Epoch 00020: val_loss improved from 0.20718 to 0.20529, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8932 - val_loss: 0.2053\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8803\n",
            "Epoch 00021: val_loss did not improve from 0.20529\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8803 - val_loss: 0.2055\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8627\n",
            "Epoch 00022: val_loss improved from 0.20529 to 0.20173, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8627 - val_loss: 0.2017\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8529\n",
            "Epoch 00023: val_loss did not improve from 0.20173\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8529 - val_loss: 0.2088\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8404\n",
            "Epoch 00024: val_loss did not improve from 0.20173\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8404 - val_loss: 0.2035\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8305\n",
            "Epoch 00025: val_loss did not improve from 0.20173\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8305 - val_loss: 0.2038\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8213\n",
            "Epoch 00026: val_loss did not improve from 0.20173\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8213 - val_loss: 0.2054\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8084\n",
            "Epoch 00027: val_loss improved from 0.20173 to 0.19782, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.8084 - val_loss: 0.1978\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8038\n",
            "Epoch 00028: val_loss did not improve from 0.19782\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.8038 - val_loss: 0.2001\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7934\n",
            "Epoch 00029: val_loss did not improve from 0.19782\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7934 - val_loss: 0.2003\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7824\n",
            "Epoch 00030: val_loss improved from 0.19782 to 0.19780, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7824 - val_loss: 0.1978\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7730\n",
            "Epoch 00031: val_loss improved from 0.19780 to 0.19266, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7730 - val_loss: 0.1927\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7666\n",
            "Epoch 00032: val_loss did not improve from 0.19266\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7666 - val_loss: 0.1953\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7614\n",
            "Epoch 00033: val_loss did not improve from 0.19266\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7614 - val_loss: 0.1960\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7541\n",
            "Epoch 00034: val_loss did not improve from 0.19266\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7541 - val_loss: 0.1934\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7427\n",
            "Epoch 00035: val_loss did not improve from 0.19266\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7427 - val_loss: 0.1966\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7344\n",
            "Epoch 00036: val_loss improved from 0.19266 to 0.19185, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7344 - val_loss: 0.1919\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7333\n",
            "Epoch 00037: val_loss did not improve from 0.19185\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7333 - val_loss: 0.1927\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7239\n",
            "Epoch 00038: val_loss did not improve from 0.19185\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7239 - val_loss: 0.1944\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7198\n",
            "Epoch 00039: val_loss did not improve from 0.19185\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7198 - val_loss: 0.1919\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7131\n",
            "Epoch 00040: val_loss did not improve from 0.19185\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7131 - val_loss: 0.1938\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7064\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.19185\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7064 - val_loss: 0.1942\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6980\n",
            "Epoch 00042: val_loss did not improve from 0.19185\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6980 - val_loss: 0.1953\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6902\n",
            "Epoch 00043: val_loss improved from 0.19185 to 0.19170, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6902 - val_loss: 0.1917\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6857\n",
            "Epoch 00044: val_loss improved from 0.19170 to 0.19119, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6857 - val_loss: 0.1912\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6787\n",
            "Epoch 00045: val_loss did not improve from 0.19119\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6787 - val_loss: 0.1925\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6770\n",
            "Epoch 00046: val_loss improved from 0.19119 to 0.19114, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6770 - val_loss: 0.1911\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6742\n",
            "Epoch 00047: val_loss did not improve from 0.19114\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6742 - val_loss: 0.1915\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6673\n",
            "Epoch 00048: val_loss improved from 0.19114 to 0.18969, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.6673 - val_loss: 0.1897\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6647\n",
            "Epoch 00049: val_loss did not improve from 0.18969\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6647 - val_loss: 0.1908\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6613\n",
            "Epoch 00050: val_loss did not improve from 0.18969\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6613 - val_loss: 0.1900\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6540\n",
            "Epoch 00051: val_loss did not improve from 0.18969\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6540 - val_loss: 0.1903\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6509\n",
            "Epoch 00052: val_loss did not improve from 0.18969\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6509 - val_loss: 0.1903\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6479\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.18969\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6479 - val_loss: 0.1921\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6401\n",
            "Epoch 00054: val_loss improved from 0.18969 to 0.18922, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6401 - val_loss: 0.1892\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6348\n",
            "Epoch 00055: val_loss improved from 0.18922 to 0.18836, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6348 - val_loss: 0.1884\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6301\n",
            "Epoch 00056: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6301 - val_loss: 0.1896\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6269\n",
            "Epoch 00057: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6269 - val_loss: 0.1895\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6298\n",
            "Epoch 00058: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6298 - val_loss: 0.1899\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6212\n",
            "Epoch 00059: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6212 - val_loss: 0.1894\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6185\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6185 - val_loss: 0.1887\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6109\n",
            "Epoch 00061: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6109 - val_loss: 0.1896\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6080\n",
            "Epoch 00062: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6080 - val_loss: 0.1908\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6067\n",
            "Epoch 00063: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6067 - val_loss: 0.1902\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6032\n",
            "Epoch 00064: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6032 - val_loss: 0.1889\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6022\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6022 - val_loss: 0.1891\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5947\n",
            "Epoch 00066: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5947 - val_loss: 0.1889\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5919\n",
            "Epoch 00067: val_loss did not improve from 0.18836\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5919 - val_loss: 0.1886\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5898\n",
            "Epoch 00068: val_loss improved from 0.18836 to 0.18790, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5898 - val_loss: 0.1879\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5864\n",
            "Epoch 00069: val_loss improved from 0.18790 to 0.18715, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5864 - val_loss: 0.1871\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5835\n",
            "Epoch 00070: val_loss did not improve from 0.18715\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5835 - val_loss: 0.1885\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5823\n",
            "Epoch 00071: val_loss did not improve from 0.18715\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5823 - val_loss: 0.1885\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5812\n",
            "Epoch 00072: val_loss did not improve from 0.18715\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5812 - val_loss: 0.1879\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5770\n",
            "Epoch 00073: val_loss did not improve from 0.18715\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5770 - val_loss: 0.1903\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5763\n",
            "Epoch 00074: val_loss improved from 0.18715 to 0.18703, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5763 - val_loss: 0.1870\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5732\n",
            "Epoch 00075: val_loss did not improve from 0.18703\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5732 - val_loss: 0.1894\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5688\n",
            "Epoch 00076: val_loss improved from 0.18703 to 0.18691, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5688 - val_loss: 0.1869\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5669\n",
            "Epoch 00077: val_loss did not improve from 0.18691\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5669 - val_loss: 0.1890\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5678\n",
            "Epoch 00078: val_loss did not improve from 0.18691\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5678 - val_loss: 0.1878\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5674\n",
            "Epoch 00079: val_loss did not improve from 0.18691\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5674 - val_loss: 0.1876\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5628\n",
            "Epoch 00080: val_loss did not improve from 0.18691\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5628 - val_loss: 0.1891\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5617\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.18691\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5617 - val_loss: 0.1870\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5572\n",
            "Epoch 00082: val_loss did not improve from 0.18691\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5572 - val_loss: 0.1876\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5547\n",
            "Epoch 00083: val_loss improved from 0.18691 to 0.18599, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5547 - val_loss: 0.1860\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5518\n",
            "Epoch 00084: val_loss did not improve from 0.18599\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5518 - val_loss: 0.1863\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5481\n",
            "Epoch 00085: val_loss did not improve from 0.18599\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5481 - val_loss: 0.1865\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5469\n",
            "Epoch 00086: val_loss improved from 0.18599 to 0.18597, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5469 - val_loss: 0.1860\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5467\n",
            "Epoch 00087: val_loss improved from 0.18597 to 0.18521, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5467 - val_loss: 0.1852\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5442\n",
            "Epoch 00088: val_loss did not improve from 0.18521\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5442 - val_loss: 0.1860\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5418\n",
            "Epoch 00089: val_loss did not improve from 0.18521\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5418 - val_loss: 0.1864\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5394\n",
            "Epoch 00090: val_loss improved from 0.18521 to 0.18516, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5394 - val_loss: 0.1852\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5386\n",
            "Epoch 00091: val_loss did not improve from 0.18516\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5386 - val_loss: 0.1856\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5383\n",
            "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.18516\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5383 - val_loss: 0.1872\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5341\n",
            "Epoch 00093: val_loss improved from 0.18516 to 0.18499, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5341 - val_loss: 0.1850\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5318\n",
            "Epoch 00094: val_loss did not improve from 0.18499\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5318 - val_loss: 0.1866\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5278\n",
            "Epoch 00095: val_loss did not improve from 0.18499\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5278 - val_loss: 0.1853\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5276\n",
            "Epoch 00096: val_loss improved from 0.18499 to 0.18496, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5276 - val_loss: 0.1850\n",
            "Epoch 97/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5270\n",
            "Epoch 00097: val_loss did not improve from 0.18496\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5270 - val_loss: 0.1861\n",
            "Epoch 98/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5238\n",
            "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.18496\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5238 - val_loss: 0.1859\n",
            "Epoch 99/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5202\n",
            "Epoch 00099: val_loss did not improve from 0.18496\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5202 - val_loss: 0.1867\n",
            "Epoch 100/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5179\n",
            "Epoch 00100: val_loss did not improve from 0.18496\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5179 - val_loss: 0.1860\n",
            "Epoch 101/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5175\n",
            "Epoch 00101: val_loss did not improve from 0.18496\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5175 - val_loss: 0.1863\n",
            "Epoch 102/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5148\n",
            "Epoch 00102: val_loss did not improve from 0.18496\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5148 - val_loss: 0.1854\n",
            "Epoch 103/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5138\n",
            "Epoch 00103: val_loss improved from 0.18496 to 0.18311, saving model to gtn_aug_snr_2_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5138 - val_loss: 0.1831\n",
            "Epoch 104/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5132\n",
            "Epoch 00104: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5132 - val_loss: 0.1843\n",
            "Epoch 105/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5111\n",
            "Epoch 00105: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5111 - val_loss: 0.1858\n",
            "Epoch 106/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5114\n",
            "Epoch 00106: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5114 - val_loss: 0.1848\n",
            "Epoch 107/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5098\n",
            "Epoch 00107: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5098 - val_loss: 0.1847\n",
            "Epoch 108/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5077\n",
            "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5077 - val_loss: 0.1857\n",
            "Epoch 109/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5040\n",
            "Epoch 00109: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5040 - val_loss: 0.1849\n",
            "Epoch 110/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5014\n",
            "Epoch 00110: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5014 - val_loss: 0.1859\n",
            "Epoch 111/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5006\n",
            "Epoch 00111: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5006 - val_loss: 0.1855\n",
            "Epoch 112/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4991\n",
            "Epoch 00112: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4991 - val_loss: 0.1864\n",
            "Epoch 113/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4991\n",
            "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4991 - val_loss: 0.1860\n",
            "Epoch 114/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4959\n",
            "Epoch 00114: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4959 - val_loss: 0.1855\n",
            "Epoch 115/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4944\n",
            "Epoch 00115: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4944 - val_loss: 0.1848\n",
            "Epoch 116/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4933\n",
            "Epoch 00116: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4933 - val_loss: 0.1853\n",
            "Epoch 117/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4915\n",
            "Epoch 00117: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4915 - val_loss: 0.1857\n",
            "Epoch 118/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4907\n",
            "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.18311\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4907 - val_loss: 0.1847\n",
            "Epoch 00118: early stopping\n",
            "reactivity  : 0.1816\n",
            "deg_Mg_pH10 : 0.2273\n",
            "deg_pH10    : 0.2014\n",
            "deg_Mg_50C  : 0.1890\n",
            "deg_50C     : 0.1842\n",
            "total: 0.19929315588404373\n",
            "Fold: 3  model_num: 0\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            " 2/68 [..............................] - ETA: 9s - loss: 4.4019WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1126s vs `on_train_batch_end` time: 0.1700s). Check your callbacks.\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.3033\n",
            "Epoch 00001: val_loss improved from inf to 0.32628, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 24s 349ms/step - loss: 2.3033 - val_loss: 0.3263\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4689\n",
            "Epoch 00002: val_loss improved from 0.32628 to 0.29582, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 1.4689 - val_loss: 0.2958\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3561\n",
            "Epoch 00003: val_loss improved from 0.29582 to 0.27051, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3561 - val_loss: 0.2705\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2883\n",
            "Epoch 00004: val_loss improved from 0.27051 to 0.25370, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 1.2883 - val_loss: 0.2537\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2199\n",
            "Epoch 00005: val_loss improved from 0.25370 to 0.24595, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 1.2199 - val_loss: 0.2459\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1712\n",
            "Epoch 00006: val_loss improved from 0.24595 to 0.23472, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 1.1712 - val_loss: 0.2347\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1366\n",
            "Epoch 00007: val_loss improved from 0.23472 to 0.22966, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.1366 - val_loss: 0.2297\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0966\n",
            "Epoch 00008: val_loss improved from 0.22966 to 0.22913, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0966 - val_loss: 0.2291\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0663\n",
            "Epoch 00009: val_loss improved from 0.22913 to 0.22188, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 1.0663 - val_loss: 0.2219\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0299\n",
            "Epoch 00010: val_loss did not improve from 0.22188\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 1.0299 - val_loss: 0.2226\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0088\n",
            "Epoch 00011: val_loss improved from 0.22188 to 0.21739, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0088 - val_loss: 0.2174\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9758\n",
            "Epoch 00012: val_loss improved from 0.21739 to 0.21384, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.9758 - val_loss: 0.2138\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9591\n",
            "Epoch 00013: val_loss improved from 0.21384 to 0.21220, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9591 - val_loss: 0.2122\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9382\n",
            "Epoch 00014: val_loss did not improve from 0.21220\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.9382 - val_loss: 0.2162\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9163\n",
            "Epoch 00015: val_loss improved from 0.21220 to 0.20819, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9163 - val_loss: 0.2082\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9023\n",
            "Epoch 00016: val_loss improved from 0.20819 to 0.20778, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9023 - val_loss: 0.2078\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8818\n",
            "Epoch 00017: val_loss improved from 0.20778 to 0.20628, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8818 - val_loss: 0.2063\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8693\n",
            "Epoch 00018: val_loss improved from 0.20628 to 0.20387, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.8693 - val_loss: 0.2039\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8511\n",
            "Epoch 00019: val_loss did not improve from 0.20387\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8511 - val_loss: 0.2049\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8361\n",
            "Epoch 00020: val_loss did not improve from 0.20387\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8361 - val_loss: 0.2078\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8278\n",
            "Epoch 00021: val_loss did not improve from 0.20387\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.8278 - val_loss: 0.2041\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8132\n",
            "Epoch 00022: val_loss improved from 0.20387 to 0.20261, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.8132 - val_loss: 0.2026\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8100\n",
            "Epoch 00023: val_loss did not improve from 0.20261\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.8100 - val_loss: 0.2048\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7931\n",
            "Epoch 00024: val_loss improved from 0.20261 to 0.20168, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.7931 - val_loss: 0.2017\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7842\n",
            "Epoch 00025: val_loss improved from 0.20168 to 0.20117, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.7842 - val_loss: 0.2012\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7746\n",
            "Epoch 00026: val_loss improved from 0.20117 to 0.20024, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.7746 - val_loss: 0.2002\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7677\n",
            "Epoch 00027: val_loss did not improve from 0.20024\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.7677 - val_loss: 0.2026\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7528\n",
            "Epoch 00028: val_loss did not improve from 0.20024\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.7528 - val_loss: 0.2019\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7475\n",
            "Epoch 00029: val_loss improved from 0.20024 to 0.19944, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7475 - val_loss: 0.1994\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7364\n",
            "Epoch 00030: val_loss improved from 0.19944 to 0.19900, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.7364 - val_loss: 0.1990\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7292\n",
            "Epoch 00031: val_loss improved from 0.19900 to 0.19844, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.7292 - val_loss: 0.1984\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7208\n",
            "Epoch 00032: val_loss improved from 0.19844 to 0.19757, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.7208 - val_loss: 0.1976\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7183\n",
            "Epoch 00033: val_loss did not improve from 0.19757\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.7183 - val_loss: 0.1977\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7103\n",
            "Epoch 00034: val_loss improved from 0.19757 to 0.19691, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.7103 - val_loss: 0.1969\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7018\n",
            "Epoch 00035: val_loss did not improve from 0.19691\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.7018 - val_loss: 0.1984\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6990\n",
            "Epoch 00036: val_loss improved from 0.19691 to 0.19660, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.6990 - val_loss: 0.1966\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6880\n",
            "Epoch 00037: val_loss did not improve from 0.19660\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6880 - val_loss: 0.2000\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6858\n",
            "Epoch 00038: val_loss improved from 0.19660 to 0.19630, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.6858 - val_loss: 0.1963\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6789\n",
            "Epoch 00039: val_loss did not improve from 0.19630\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6789 - val_loss: 0.1973\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6752\n",
            "Epoch 00040: val_loss did not improve from 0.19630\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6752 - val_loss: 0.1972\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6685\n",
            "Epoch 00041: val_loss improved from 0.19630 to 0.19487, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.6685 - val_loss: 0.1949\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6641\n",
            "Epoch 00042: val_loss did not improve from 0.19487\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6641 - val_loss: 0.1963\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6624\n",
            "Epoch 00043: val_loss did not improve from 0.19487\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6624 - val_loss: 0.1962\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6539\n",
            "Epoch 00044: val_loss did not improve from 0.19487\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6539 - val_loss: 0.1952\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6474\n",
            "Epoch 00045: val_loss improved from 0.19487 to 0.19329, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.6474 - val_loss: 0.1933\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6447\n",
            "Epoch 00046: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6447 - val_loss: 0.1950\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6396\n",
            "Epoch 00047: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6396 - val_loss: 0.1955\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6404\n",
            "Epoch 00048: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6404 - val_loss: 0.1948\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6333\n",
            "Epoch 00049: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6333 - val_loss: 0.1973\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6306\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6306 - val_loss: 0.1937\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6200\n",
            "Epoch 00051: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6200 - val_loss: 0.1951\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6139\n",
            "Epoch 00052: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6139 - val_loss: 0.1941\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6101\n",
            "Epoch 00053: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6101 - val_loss: 0.1936\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6070\n",
            "Epoch 00054: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6070 - val_loss: 0.1939\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6064\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6064 - val_loss: 0.1942\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5990\n",
            "Epoch 00056: val_loss did not improve from 0.19329\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5990 - val_loss: 0.1937\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5955\n",
            "Epoch 00057: val_loss improved from 0.19329 to 0.19267, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.5955 - val_loss: 0.1927\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5899\n",
            "Epoch 00058: val_loss did not improve from 0.19267\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5899 - val_loss: 0.1933\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5853\n",
            "Epoch 00059: val_loss improved from 0.19267 to 0.19251, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.5853 - val_loss: 0.1925\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5867\n",
            "Epoch 00060: val_loss improved from 0.19251 to 0.19179, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.5867 - val_loss: 0.1918\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5841\n",
            "Epoch 00061: val_loss did not improve from 0.19179\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5841 - val_loss: 0.1920\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5798\n",
            "Epoch 00062: val_loss did not improve from 0.19179\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5798 - val_loss: 0.1925\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5771\n",
            "Epoch 00063: val_loss improved from 0.19179 to 0.19171, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5771 - val_loss: 0.1917\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5769\n",
            "Epoch 00064: val_loss improved from 0.19171 to 0.19136, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5769 - val_loss: 0.1914\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5723\n",
            "Epoch 00065: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5723 - val_loss: 0.1922\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5713\n",
            "Epoch 00066: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5713 - val_loss: 0.1925\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5696\n",
            "Epoch 00067: val_loss improved from 0.19136 to 0.19136, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.5696 - val_loss: 0.1914\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5671\n",
            "Epoch 00068: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5671 - val_loss: 0.1918\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5658\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5658 - val_loss: 0.1914\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5586\n",
            "Epoch 00070: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5586 - val_loss: 0.1921\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5563\n",
            "Epoch 00071: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5563 - val_loss: 0.1918\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5546\n",
            "Epoch 00072: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5546 - val_loss: 0.1916\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5510\n",
            "Epoch 00073: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5510 - val_loss: 0.1919\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5468\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5468 - val_loss: 0.1918\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5447\n",
            "Epoch 00075: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5447 - val_loss: 0.1916\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5409\n",
            "Epoch 00076: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5409 - val_loss: 0.1919\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5392\n",
            "Epoch 00077: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5392 - val_loss: 0.1915\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5360\n",
            "Epoch 00078: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5360 - val_loss: 0.1926\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5369\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.19136\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5369 - val_loss: 0.1935\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5306\n",
            "Epoch 00080: val_loss improved from 0.19136 to 0.19105, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.5306 - val_loss: 0.1911\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5269\n",
            "Epoch 00081: val_loss improved from 0.19105 to 0.19019, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.5269 - val_loss: 0.1902\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5281\n",
            "Epoch 00082: val_loss did not improve from 0.19019\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5281 - val_loss: 0.1914\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5255\n",
            "Epoch 00083: val_loss did not improve from 0.19019\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5255 - val_loss: 0.1912\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5233\n",
            "Epoch 00084: val_loss did not improve from 0.19019\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5233 - val_loss: 0.1916\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5206\n",
            "Epoch 00085: val_loss improved from 0.19019 to 0.19009, saving model to gtn_aug_snr_3_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.5206 - val_loss: 0.1901\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5200\n",
            "Epoch 00086: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5200 - val_loss: 0.1914\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5205\n",
            "Epoch 00087: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5205 - val_loss: 0.1928\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5162\n",
            "Epoch 00088: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5162 - val_loss: 0.1906\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5146\n",
            "Epoch 00089: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5146 - val_loss: 0.1915\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5146\n",
            "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5146 - val_loss: 0.1920\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5110\n",
            "Epoch 00091: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.5110 - val_loss: 0.1909\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5076\n",
            "Epoch 00092: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5076 - val_loss: 0.1926\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5051\n",
            "Epoch 00093: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5051 - val_loss: 0.1908\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5058\n",
            "Epoch 00094: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5058 - val_loss: 0.1918\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5009\n",
            "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5009 - val_loss: 0.1916\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4995\n",
            "Epoch 00096: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4995 - val_loss: 0.1914\n",
            "Epoch 97/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4971\n",
            "Epoch 00097: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4971 - val_loss: 0.1919\n",
            "Epoch 98/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4967\n",
            "Epoch 00098: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.4967 - val_loss: 0.1916\n",
            "Epoch 99/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4953\n",
            "Epoch 00099: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.4953 - val_loss: 0.1913\n",
            "Epoch 100/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4936\n",
            "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.19009\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.4936 - val_loss: 0.1910\n",
            "Epoch 00100: early stopping\n",
            "reactivity  : 0.1822\n",
            "deg_Mg_pH10 : 0.2394\n",
            "deg_pH10    : 0.2180\n",
            "deg_Mg_50C  : 0.1947\n",
            "deg_50C     : 0.1858\n",
            "total: 0.205429116045743\n",
            "Fold: 4  model_num: 0\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.3406\n",
            "Epoch 00001: val_loss improved from inf to 0.34098, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 24s 348ms/step - loss: 2.3406 - val_loss: 0.3410\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4819\n",
            "Epoch 00002: val_loss improved from 0.34098 to 0.31172, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 1.4819 - val_loss: 0.3117\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3775\n",
            "Epoch 00003: val_loss improved from 0.31172 to 0.30390, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3775 - val_loss: 0.3039\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3171\n",
            "Epoch 00004: val_loss did not improve from 0.30390\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 1.3171 - val_loss: 0.3049\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2545\n",
            "Epoch 00005: val_loss improved from 0.30390 to 0.27414, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 1.2545 - val_loss: 0.2741\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1873\n",
            "Epoch 00006: val_loss improved from 0.27414 to 0.26462, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1873 - val_loss: 0.2646\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1489\n",
            "Epoch 00007: val_loss did not improve from 0.26462\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 1.1489 - val_loss: 0.2647\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1140\n",
            "Epoch 00008: val_loss improved from 0.26462 to 0.25979, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1140 - val_loss: 0.2598\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0785\n",
            "Epoch 00009: val_loss improved from 0.25979 to 0.25185, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0785 - val_loss: 0.2518\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0617\n",
            "Epoch 00010: val_loss improved from 0.25185 to 0.25072, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0617 - val_loss: 0.2507\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0369\n",
            "Epoch 00011: val_loss did not improve from 0.25072\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 1.0369 - val_loss: 0.2604\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0092\n",
            "Epoch 00012: val_loss did not improve from 0.25072\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 1.0092 - val_loss: 0.2524\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9898\n",
            "Epoch 00013: val_loss improved from 0.25072 to 0.24007, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9898 - val_loss: 0.2401\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9749\n",
            "Epoch 00014: val_loss improved from 0.24007 to 0.23754, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9749 - val_loss: 0.2375\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9518\n",
            "Epoch 00015: val_loss improved from 0.23754 to 0.23634, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9518 - val_loss: 0.2363\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9287\n",
            "Epoch 00016: val_loss did not improve from 0.23634\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.9287 - val_loss: 0.2396\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9145\n",
            "Epoch 00017: val_loss improved from 0.23634 to 0.23318, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.9145 - val_loss: 0.2332\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8972\n",
            "Epoch 00018: val_loss improved from 0.23318 to 0.23010, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8972 - val_loss: 0.2301\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8829\n",
            "Epoch 00019: val_loss improved from 0.23010 to 0.22872, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8829 - val_loss: 0.2287\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8698\n",
            "Epoch 00020: val_loss improved from 0.22872 to 0.22845, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8698 - val_loss: 0.2284\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8576\n",
            "Epoch 00021: val_loss improved from 0.22845 to 0.22588, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.8576 - val_loss: 0.2259\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8460\n",
            "Epoch 00022: val_loss did not improve from 0.22588\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8460 - val_loss: 0.2264\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8354\n",
            "Epoch 00023: val_loss did not improve from 0.22588\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.8354 - val_loss: 0.2271\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8241\n",
            "Epoch 00024: val_loss improved from 0.22588 to 0.22348, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8241 - val_loss: 0.2235\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8107\n",
            "Epoch 00025: val_loss did not improve from 0.22348\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.8107 - val_loss: 0.2241\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8019\n",
            "Epoch 00026: val_loss improved from 0.22348 to 0.22263, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8019 - val_loss: 0.2226\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7929\n",
            "Epoch 00027: val_loss did not improve from 0.22263\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.7929 - val_loss: 0.2229\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7819\n",
            "Epoch 00028: val_loss improved from 0.22263 to 0.22058, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7819 - val_loss: 0.2206\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7740\n",
            "Epoch 00029: val_loss did not improve from 0.22058\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.7740 - val_loss: 0.2222\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7685\n",
            "Epoch 00030: val_loss improved from 0.22058 to 0.22031, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.7685 - val_loss: 0.2203\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7547\n",
            "Epoch 00031: val_loss did not improve from 0.22031\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.7547 - val_loss: 0.2214\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7481\n",
            "Epoch 00032: val_loss improved from 0.22031 to 0.21838, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.7481 - val_loss: 0.2184\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7404\n",
            "Epoch 00033: val_loss improved from 0.21838 to 0.21685, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7404 - val_loss: 0.2169\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7369\n",
            "Epoch 00034: val_loss did not improve from 0.21685\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.7369 - val_loss: 0.2180\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7263\n",
            "Epoch 00035: val_loss did not improve from 0.21685\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.7263 - val_loss: 0.2211\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7214\n",
            "Epoch 00036: val_loss did not improve from 0.21685\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.7214 - val_loss: 0.2176\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7128\n",
            "Epoch 00037: val_loss improved from 0.21685 to 0.21570, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.7128 - val_loss: 0.2157\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7076\n",
            "Epoch 00038: val_loss did not improve from 0.21570\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.7076 - val_loss: 0.2171\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7006\n",
            "Epoch 00039: val_loss did not improve from 0.21570\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7006 - val_loss: 0.2157\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6950\n",
            "Epoch 00040: val_loss did not improve from 0.21570\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6950 - val_loss: 0.2174\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6895\n",
            "Epoch 00041: val_loss improved from 0.21570 to 0.21535, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6895 - val_loss: 0.2154\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6867\n",
            "Epoch 00042: val_loss improved from 0.21535 to 0.21478, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6867 - val_loss: 0.2148\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6789\n",
            "Epoch 00043: val_loss did not improve from 0.21478\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6789 - val_loss: 0.2165\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6771\n",
            "Epoch 00044: val_loss did not improve from 0.21478\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6771 - val_loss: 0.2187\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6753\n",
            "Epoch 00045: val_loss did not improve from 0.21478\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6753 - val_loss: 0.2171\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6682\n",
            "Epoch 00046: val_loss did not improve from 0.21478\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6682 - val_loss: 0.2161\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6631\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.21478\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6631 - val_loss: 0.2151\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6513\n",
            "Epoch 00048: val_loss improved from 0.21478 to 0.21455, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6513 - val_loss: 0.2146\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6455\n",
            "Epoch 00049: val_loss improved from 0.21455 to 0.21393, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.6455 - val_loss: 0.2139\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6417\n",
            "Epoch 00050: val_loss did not improve from 0.21393\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6417 - val_loss: 0.2143\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6406\n",
            "Epoch 00051: val_loss improved from 0.21393 to 0.21393, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.6406 - val_loss: 0.2139\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6355\n",
            "Epoch 00052: val_loss did not improve from 0.21393\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6355 - val_loss: 0.2152\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6301\n",
            "Epoch 00053: val_loss improved from 0.21393 to 0.21236, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.6301 - val_loss: 0.2124\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6272\n",
            "Epoch 00054: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6272 - val_loss: 0.2163\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6244\n",
            "Epoch 00055: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6244 - val_loss: 0.2138\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6240\n",
            "Epoch 00056: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6240 - val_loss: 0.2124\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6182\n",
            "Epoch 00057: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6182 - val_loss: 0.2134\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6137\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6137 - val_loss: 0.2131\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6062\n",
            "Epoch 00059: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6062 - val_loss: 0.2130\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6057\n",
            "Epoch 00060: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6057 - val_loss: 0.2128\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6009\n",
            "Epoch 00061: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6009 - val_loss: 0.2129\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5984\n",
            "Epoch 00062: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.5984 - val_loss: 0.2143\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5970\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.21236\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5970 - val_loss: 0.2134\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5898\n",
            "Epoch 00064: val_loss improved from 0.21236 to 0.21219, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5898 - val_loss: 0.2122\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5860\n",
            "Epoch 00065: val_loss did not improve from 0.21219\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5860 - val_loss: 0.2131\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5841\n",
            "Epoch 00066: val_loss improved from 0.21219 to 0.21214, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5841 - val_loss: 0.2121\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5814\n",
            "Epoch 00067: val_loss improved from 0.21214 to 0.21139, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5814 - val_loss: 0.2114\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5765\n",
            "Epoch 00068: val_loss did not improve from 0.21139\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5765 - val_loss: 0.2121\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5754\n",
            "Epoch 00069: val_loss did not improve from 0.21139\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5754 - val_loss: 0.2116\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5734\n",
            "Epoch 00070: val_loss did not improve from 0.21139\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5734 - val_loss: 0.2136\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5717\n",
            "Epoch 00071: val_loss improved from 0.21139 to 0.21081, saving model to gtn_aug_snr_4_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5717 - val_loss: 0.2108\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5690\n",
            "Epoch 00072: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5690 - val_loss: 0.2116\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5704\n",
            "Epoch 00073: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5704 - val_loss: 0.2130\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5661\n",
            "Epoch 00074: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5661 - val_loss: 0.2122\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5660\n",
            "Epoch 00075: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5660 - val_loss: 0.2113\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5608\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5608 - val_loss: 0.2109\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5560\n",
            "Epoch 00077: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5560 - val_loss: 0.2125\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5519\n",
            "Epoch 00078: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5519 - val_loss: 0.2130\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5523\n",
            "Epoch 00079: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5523 - val_loss: 0.2116\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5492\n",
            "Epoch 00080: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5492 - val_loss: 0.2122\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5464\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5464 - val_loss: 0.2123\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5411\n",
            "Epoch 00082: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5411 - val_loss: 0.2115\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5397\n",
            "Epoch 00083: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5397 - val_loss: 0.2124\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5383\n",
            "Epoch 00084: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5383 - val_loss: 0.2113\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5364\n",
            "Epoch 00085: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5364 - val_loss: 0.2126\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5361\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.21081\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5361 - val_loss: 0.2128\n",
            "Epoch 00086: early stopping\n",
            "reactivity  : 0.2080\n",
            "deg_Mg_pH10 : 0.2733\n",
            "deg_pH10    : 0.2554\n",
            "deg_Mg_50C  : 0.2224\n",
            "deg_50C     : 0.2081\n",
            "total: 0.23454828712511921\n",
            "Fold: 5  model_num: 0\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.3876\n",
            "Epoch 00001: val_loss improved from inf to 0.34496, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 24s 347ms/step - loss: 2.3876 - val_loss: 0.3450\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4951\n",
            "Epoch 00002: val_loss improved from 0.34496 to 0.31374, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 1.4951 - val_loss: 0.3137\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3886\n",
            "Epoch 00003: val_loss improved from 0.31374 to 0.28329, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3886 - val_loss: 0.2833\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3152\n",
            "Epoch 00004: val_loss improved from 0.28329 to 0.27943, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3152 - val_loss: 0.2794\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2680\n",
            "Epoch 00005: val_loss improved from 0.27943 to 0.27305, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 20s 297ms/step - loss: 1.2680 - val_loss: 0.2731\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1984\n",
            "Epoch 00006: val_loss improved from 0.27305 to 0.26097, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.1984 - val_loss: 0.2610\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1576\n",
            "Epoch 00007: val_loss improved from 0.26097 to 0.25143, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1576 - val_loss: 0.2514\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1288\n",
            "Epoch 00008: val_loss improved from 0.25143 to 0.24392, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1288 - val_loss: 0.2439\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0806\n",
            "Epoch 00009: val_loss did not improve from 0.24392\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 1.0806 - val_loss: 0.2452\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0525\n",
            "Epoch 00010: val_loss improved from 0.24392 to 0.23736, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0525 - val_loss: 0.2374\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0272\n",
            "Epoch 00011: val_loss did not improve from 0.23736\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 1.0272 - val_loss: 0.2409\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0052\n",
            "Epoch 00012: val_loss improved from 0.23736 to 0.23216, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0052 - val_loss: 0.2322\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9794\n",
            "Epoch 00013: val_loss improved from 0.23216 to 0.22952, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9794 - val_loss: 0.2295\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9654\n",
            "Epoch 00014: val_loss improved from 0.22952 to 0.22729, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9654 - val_loss: 0.2273\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9419\n",
            "Epoch 00015: val_loss improved from 0.22729 to 0.22139, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9419 - val_loss: 0.2214\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9273\n",
            "Epoch 00016: val_loss did not improve from 0.22139\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.9273 - val_loss: 0.2226\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9109\n",
            "Epoch 00017: val_loss improved from 0.22139 to 0.22025, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9109 - val_loss: 0.2202\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8931\n",
            "Epoch 00018: val_loss improved from 0.22025 to 0.21745, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8931 - val_loss: 0.2175\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8768\n",
            "Epoch 00019: val_loss did not improve from 0.21745\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8768 - val_loss: 0.2196\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8666\n",
            "Epoch 00020: val_loss improved from 0.21745 to 0.21589, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8666 - val_loss: 0.2159\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8535\n",
            "Epoch 00021: val_loss improved from 0.21589 to 0.21540, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8535 - val_loss: 0.2154\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8433\n",
            "Epoch 00022: val_loss did not improve from 0.21540\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8433 - val_loss: 0.2154\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8281\n",
            "Epoch 00023: val_loss improved from 0.21540 to 0.21192, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8281 - val_loss: 0.2119\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8180\n",
            "Epoch 00024: val_loss improved from 0.21192 to 0.21006, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8180 - val_loss: 0.2101\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8123\n",
            "Epoch 00025: val_loss did not improve from 0.21006\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8123 - val_loss: 0.2104\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7984\n",
            "Epoch 00026: val_loss did not improve from 0.21006\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7984 - val_loss: 0.2110\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7890\n",
            "Epoch 00027: val_loss did not improve from 0.21006\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7890 - val_loss: 0.2106\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7827\n",
            "Epoch 00028: val_loss did not improve from 0.21006\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7827 - val_loss: 0.2108\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7682\n",
            "Epoch 00029: val_loss improved from 0.21006 to 0.20807, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7682 - val_loss: 0.2081\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7632\n",
            "Epoch 00030: val_loss did not improve from 0.20807\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7632 - val_loss: 0.2085\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7543\n",
            "Epoch 00031: val_loss improved from 0.20807 to 0.20799, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7543 - val_loss: 0.2080\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7480\n",
            "Epoch 00032: val_loss improved from 0.20799 to 0.20695, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7480 - val_loss: 0.2070\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7425\n",
            "Epoch 00033: val_loss did not improve from 0.20695\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7425 - val_loss: 0.2094\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7312\n",
            "Epoch 00034: val_loss improved from 0.20695 to 0.20556, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7312 - val_loss: 0.2056\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7292\n",
            "Epoch 00035: val_loss did not improve from 0.20556\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7292 - val_loss: 0.2070\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7194\n",
            "Epoch 00036: val_loss improved from 0.20556 to 0.20504, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7194 - val_loss: 0.2050\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7137\n",
            "Epoch 00037: val_loss did not improve from 0.20504\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7137 - val_loss: 0.2069\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7042\n",
            "Epoch 00038: val_loss did not improve from 0.20504\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.7042 - val_loss: 0.2064\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7009\n",
            "Epoch 00039: val_loss improved from 0.20504 to 0.20386, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7009 - val_loss: 0.2039\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6924\n",
            "Epoch 00040: val_loss did not improve from 0.20386\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6924 - val_loss: 0.2069\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6888\n",
            "Epoch 00041: val_loss did not improve from 0.20386\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6888 - val_loss: 0.2040\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6848\n",
            "Epoch 00042: val_loss improved from 0.20386 to 0.20364, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6848 - val_loss: 0.2036\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6829\n",
            "Epoch 00043: val_loss did not improve from 0.20364\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6829 - val_loss: 0.2046\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6736\n",
            "Epoch 00044: val_loss did not improve from 0.20364\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6736 - val_loss: 0.2061\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6672\n",
            "Epoch 00045: val_loss improved from 0.20364 to 0.20322, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6672 - val_loss: 0.2032\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6617\n",
            "Epoch 00046: val_loss did not improve from 0.20322\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6617 - val_loss: 0.2047\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6608\n",
            "Epoch 00047: val_loss improved from 0.20322 to 0.20240, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6608 - val_loss: 0.2024\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6535\n",
            "Epoch 00048: val_loss did not improve from 0.20240\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6535 - val_loss: 0.2026\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6521\n",
            "Epoch 00049: val_loss did not improve from 0.20240\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6521 - val_loss: 0.2027\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6445\n",
            "Epoch 00050: val_loss did not improve from 0.20240\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6445 - val_loss: 0.2035\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6431\n",
            "Epoch 00051: val_loss did not improve from 0.20240\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 0.6431 - val_loss: 0.2027\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6401\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.20240\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6401 - val_loss: 0.2047\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6300\n",
            "Epoch 00053: val_loss improved from 0.20240 to 0.20167, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6300 - val_loss: 0.2017\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6243\n",
            "Epoch 00054: val_loss improved from 0.20167 to 0.20018, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6243 - val_loss: 0.2002\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6202\n",
            "Epoch 00055: val_loss did not improve from 0.20018\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6202 - val_loss: 0.2024\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6185\n",
            "Epoch 00056: val_loss did not improve from 0.20018\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6185 - val_loss: 0.2005\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6178\n",
            "Epoch 00057: val_loss did not improve from 0.20018\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6178 - val_loss: 0.2016\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6111\n",
            "Epoch 00058: val_loss improved from 0.20018 to 0.19943, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 0.6111 - val_loss: 0.1994\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6100\n",
            "Epoch 00059: val_loss did not improve from 0.19943\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6100 - val_loss: 0.1997\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6032\n",
            "Epoch 00060: val_loss did not improve from 0.19943\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6032 - val_loss: 0.2025\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6022\n",
            "Epoch 00061: val_loss did not improve from 0.19943\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6022 - val_loss: 0.2010\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5985\n",
            "Epoch 00062: val_loss did not improve from 0.19943\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5985 - val_loss: 0.2004\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5959\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.19943\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5959 - val_loss: 0.2004\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5913\n",
            "Epoch 00064: val_loss did not improve from 0.19943\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5913 - val_loss: 0.1999\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5876\n",
            "Epoch 00065: val_loss improved from 0.19943 to 0.19883, saving model to gtn_aug_snr_5_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5876 - val_loss: 0.1988\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5828\n",
            "Epoch 00066: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5828 - val_loss: 0.2009\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5820\n",
            "Epoch 00067: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5820 - val_loss: 0.2007\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5774\n",
            "Epoch 00068: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5774 - val_loss: 0.2001\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5757\n",
            "Epoch 00069: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5757 - val_loss: 0.2014\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5729\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5729 - val_loss: 0.2026\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5707\n",
            "Epoch 00071: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5707 - val_loss: 0.2009\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5642\n",
            "Epoch 00072: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5642 - val_loss: 0.2021\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5630\n",
            "Epoch 00073: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5630 - val_loss: 0.1999\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5598\n",
            "Epoch 00074: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5598 - val_loss: 0.1991\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5579\n",
            "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5579 - val_loss: 0.2005\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5547\n",
            "Epoch 00076: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5547 - val_loss: 0.1995\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5507\n",
            "Epoch 00077: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5507 - val_loss: 0.1997\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5488\n",
            "Epoch 00078: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5488 - val_loss: 0.1999\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5464\n",
            "Epoch 00079: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5464 - val_loss: 0.2008\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5461\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.19883\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5461 - val_loss: 0.1999\n",
            "Epoch 00080: early stopping\n",
            "reactivity  : 0.1962\n",
            "deg_Mg_pH10 : 0.2468\n",
            "deg_pH10    : 0.2300\n",
            "deg_Mg_50C  : 0.2014\n",
            "deg_50C     : 0.2002\n",
            "total: 0.21480612516904812\n",
            "Fold: 6  model_num: 0\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            " 2/68 [..............................] - ETA: 9s - loss: 4.3154WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1120s vs `on_train_batch_end` time: 0.1698s). Check your callbacks.\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.1557\n",
            "Epoch 00001: val_loss improved from inf to 0.31914, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 23s 343ms/step - loss: 2.1557 - val_loss: 0.3191\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4470\n",
            "Epoch 00002: val_loss improved from 0.31914 to 0.29732, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.4470 - val_loss: 0.2973\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3466\n",
            "Epoch 00003: val_loss improved from 0.29732 to 0.27766, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.3466 - val_loss: 0.2777\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2671\n",
            "Epoch 00004: val_loss improved from 0.27766 to 0.26204, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.2671 - val_loss: 0.2620\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2055\n",
            "Epoch 00005: val_loss improved from 0.26204 to 0.24642, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.2055 - val_loss: 0.2464\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1552\n",
            "Epoch 00006: val_loss improved from 0.24642 to 0.24115, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.1552 - val_loss: 0.2411\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1191\n",
            "Epoch 00007: val_loss improved from 0.24115 to 0.23847, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.1191 - val_loss: 0.2385\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0828\n",
            "Epoch 00008: val_loss improved from 0.23847 to 0.22755, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.0828 - val_loss: 0.2276\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0488\n",
            "Epoch 00009: val_loss did not improve from 0.22755\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 1.0488 - val_loss: 0.2302\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0178\n",
            "Epoch 00010: val_loss did not improve from 0.22755\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 1.0178 - val_loss: 0.2328\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9930\n",
            "Epoch 00011: val_loss improved from 0.22755 to 0.22495, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9930 - val_loss: 0.2249\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9835\n",
            "Epoch 00012: val_loss improved from 0.22495 to 0.21920, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9835 - val_loss: 0.2192\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9470\n",
            "Epoch 00013: val_loss improved from 0.21920 to 0.21811, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9470 - val_loss: 0.2181\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9374\n",
            "Epoch 00014: val_loss improved from 0.21811 to 0.21349, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9374 - val_loss: 0.2135\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9150\n",
            "Epoch 00015: val_loss improved from 0.21349 to 0.21101, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9150 - val_loss: 0.2110\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8997\n",
            "Epoch 00016: val_loss did not improve from 0.21101\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8997 - val_loss: 0.2136\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8811\n",
            "Epoch 00017: val_loss did not improve from 0.21101\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8811 - val_loss: 0.2121\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8632\n",
            "Epoch 00018: val_loss did not improve from 0.21101\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8632 - val_loss: 0.2134\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8523\n",
            "Epoch 00019: val_loss improved from 0.21101 to 0.21011, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.8523 - val_loss: 0.2101\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8393\n",
            "Epoch 00020: val_loss did not improve from 0.21011\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8393 - val_loss: 0.2103\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8252\n",
            "Epoch 00021: val_loss did not improve from 0.21011\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8252 - val_loss: 0.2104\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8114\n",
            "Epoch 00022: val_loss improved from 0.21011 to 0.20673, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.8114 - val_loss: 0.2067\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8033\n",
            "Epoch 00023: val_loss did not improve from 0.20673\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8033 - val_loss: 0.2099\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7930\n",
            "Epoch 00024: val_loss improved from 0.20673 to 0.20362, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7930 - val_loss: 0.2036\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7812\n",
            "Epoch 00025: val_loss did not improve from 0.20362\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.7812 - val_loss: 0.2069\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7697\n",
            "Epoch 00026: val_loss did not improve from 0.20362\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7697 - val_loss: 0.2066\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7665\n",
            "Epoch 00027: val_loss did not improve from 0.20362\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7665 - val_loss: 0.2103\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7569\n",
            "Epoch 00028: val_loss improved from 0.20362 to 0.20268, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7569 - val_loss: 0.2027\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7412\n",
            "Epoch 00029: val_loss did not improve from 0.20268\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7412 - val_loss: 0.2051\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7385\n",
            "Epoch 00030: val_loss did not improve from 0.20268\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7385 - val_loss: 0.2033\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7291\n",
            "Epoch 00031: val_loss did not improve from 0.20268\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.7291 - val_loss: 0.2029\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7195\n",
            "Epoch 00032: val_loss improved from 0.20268 to 0.20178, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7195 - val_loss: 0.2018\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7130\n",
            "Epoch 00033: val_loss did not improve from 0.20178\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.7130 - val_loss: 0.2018\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7064\n",
            "Epoch 00034: val_loss did not improve from 0.20178\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7064 - val_loss: 0.2022\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7027\n",
            "Epoch 00035: val_loss improved from 0.20178 to 0.19993, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7027 - val_loss: 0.1999\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6966\n",
            "Epoch 00036: val_loss did not improve from 0.19993\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6966 - val_loss: 0.2018\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6908\n",
            "Epoch 00037: val_loss did not improve from 0.19993\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6908 - val_loss: 0.2013\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6846\n",
            "Epoch 00038: val_loss did not improve from 0.19993\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6846 - val_loss: 0.2000\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6794\n",
            "Epoch 00039: val_loss did not improve from 0.19993\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6794 - val_loss: 0.2005\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6715\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.19993 to 0.19984, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6715 - val_loss: 0.1998\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6649\n",
            "Epoch 00041: val_loss improved from 0.19984 to 0.19714, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6649 - val_loss: 0.1971\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6578\n",
            "Epoch 00042: val_loss did not improve from 0.19714\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6578 - val_loss: 0.1998\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6513\n",
            "Epoch 00043: val_loss did not improve from 0.19714\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6513 - val_loss: 0.1988\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6489\n",
            "Epoch 00044: val_loss did not improve from 0.19714\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6489 - val_loss: 0.1981\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6438\n",
            "Epoch 00045: val_loss did not improve from 0.19714\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6438 - val_loss: 0.1982\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6411\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.19714\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6411 - val_loss: 0.1977\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6341\n",
            "Epoch 00047: val_loss improved from 0.19714 to 0.19676, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6341 - val_loss: 0.1968\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6265\n",
            "Epoch 00048: val_loss did not improve from 0.19676\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6265 - val_loss: 0.1968\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6230\n",
            "Epoch 00049: val_loss improved from 0.19676 to 0.19570, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6230 - val_loss: 0.1957\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6212\n",
            "Epoch 00050: val_loss did not improve from 0.19570\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6212 - val_loss: 0.1982\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6178\n",
            "Epoch 00051: val_loss did not improve from 0.19570\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6178 - val_loss: 0.1965\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6140\n",
            "Epoch 00052: val_loss improved from 0.19570 to 0.19543, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6140 - val_loss: 0.1954\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6089\n",
            "Epoch 00053: val_loss did not improve from 0.19543\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6089 - val_loss: 0.1976\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6092\n",
            "Epoch 00054: val_loss did not improve from 0.19543\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6092 - val_loss: 0.1976\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6073\n",
            "Epoch 00055: val_loss did not improve from 0.19543\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6073 - val_loss: 0.1955\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6036\n",
            "Epoch 00056: val_loss did not improve from 0.19543\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6036 - val_loss: 0.1988\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6014\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.19543 to 0.19541, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6014 - val_loss: 0.1954\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5924\n",
            "Epoch 00058: val_loss improved from 0.19541 to 0.19446, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5924 - val_loss: 0.1945\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5887\n",
            "Epoch 00059: val_loss did not improve from 0.19446\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5887 - val_loss: 0.1954\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5848\n",
            "Epoch 00060: val_loss did not improve from 0.19446\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5848 - val_loss: 0.1948\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5816\n",
            "Epoch 00061: val_loss did not improve from 0.19446\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5816 - val_loss: 0.1955\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5803\n",
            "Epoch 00062: val_loss did not improve from 0.19446\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5803 - val_loss: 0.1958\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5791\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.19446\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5791 - val_loss: 0.1955\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5724\n",
            "Epoch 00064: val_loss did not improve from 0.19446\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5724 - val_loss: 0.1964\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5684\n",
            "Epoch 00065: val_loss improved from 0.19446 to 0.19431, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5684 - val_loss: 0.1943\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5656\n",
            "Epoch 00066: val_loss did not improve from 0.19431\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5656 - val_loss: 0.1943\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5650\n",
            "Epoch 00067: val_loss did not improve from 0.19431\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5650 - val_loss: 0.1969\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5638\n",
            "Epoch 00068: val_loss did not improve from 0.19431\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5638 - val_loss: 0.1952\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5616\n",
            "Epoch 00069: val_loss improved from 0.19431 to 0.19419, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5616 - val_loss: 0.1942\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5563\n",
            "Epoch 00070: val_loss improved from 0.19419 to 0.19352, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5563 - val_loss: 0.1935\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5554\n",
            "Epoch 00071: val_loss did not improve from 0.19352\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5554 - val_loss: 0.1955\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5531\n",
            "Epoch 00072: val_loss improved from 0.19352 to 0.19341, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5531 - val_loss: 0.1934\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5528\n",
            "Epoch 00073: val_loss did not improve from 0.19341\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5528 - val_loss: 0.1955\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5494\n",
            "Epoch 00074: val_loss did not improve from 0.19341\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5494 - val_loss: 0.1944\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5473\n",
            "Epoch 00075: val_loss did not improve from 0.19341\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5473 - val_loss: 0.1943\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5460\n",
            "Epoch 00076: val_loss did not improve from 0.19341\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5460 - val_loss: 0.1976\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5457\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.19341\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5457 - val_loss: 0.1949\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5381\n",
            "Epoch 00078: val_loss did not improve from 0.19341\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5381 - val_loss: 0.1943\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5354\n",
            "Epoch 00079: val_loss improved from 0.19341 to 0.19306, saving model to gtn_aug_snr_6_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5354 - val_loss: 0.1931\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5332\n",
            "Epoch 00080: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5332 - val_loss: 0.1940\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5326\n",
            "Epoch 00081: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5326 - val_loss: 0.1957\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5290\n",
            "Epoch 00082: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5290 - val_loss: 0.1947\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5276\n",
            "Epoch 00083: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5276 - val_loss: 0.1946\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5265\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5265 - val_loss: 0.1947\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5215\n",
            "Epoch 00085: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5215 - val_loss: 0.1938\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5194\n",
            "Epoch 00086: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5194 - val_loss: 0.1956\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5199\n",
            "Epoch 00087: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5199 - val_loss: 0.1943\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5160\n",
            "Epoch 00088: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5160 - val_loss: 0.1931\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5146\n",
            "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5146 - val_loss: 0.1952\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5114\n",
            "Epoch 00090: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5114 - val_loss: 0.1951\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5093\n",
            "Epoch 00091: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5093 - val_loss: 0.1953\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5065\n",
            "Epoch 00092: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5065 - val_loss: 0.1947\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5051\n",
            "Epoch 00093: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5051 - val_loss: 0.1953\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5046\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.19306\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5046 - val_loss: 0.1936\n",
            "Epoch 00094: early stopping\n",
            "reactivity  : 0.1870\n",
            "deg_Mg_pH10 : 0.2346\n",
            "deg_pH10    : 0.2276\n",
            "deg_Mg_50C  : 0.1952\n",
            "deg_50C     : 0.1958\n",
            "total: 0.20561410823491044\n",
            "Fold: 7  model_num: 0\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            " 2/68 [..............................] - ETA: 9s - loss: 8.0302WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1117s vs `on_train_batch_end` time: 0.1713s). Check your callbacks.\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.2752\n",
            "Epoch 00001: val_loss improved from inf to 0.35253, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 23s 343ms/step - loss: 2.2752 - val_loss: 0.3525\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4481\n",
            "Epoch 00002: val_loss improved from 0.35253 to 0.30920, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.4481 - val_loss: 0.3092\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3528\n",
            "Epoch 00003: val_loss improved from 0.30920 to 0.28772, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3528 - val_loss: 0.2877\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2688\n",
            "Epoch 00004: val_loss improved from 0.28772 to 0.27608, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.2688 - val_loss: 0.2761\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2205\n",
            "Epoch 00005: val_loss improved from 0.27608 to 0.26205, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.2205 - val_loss: 0.2621\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1709\n",
            "Epoch 00006: val_loss improved from 0.26205 to 0.25154, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1709 - val_loss: 0.2515\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1268\n",
            "Epoch 00007: val_loss improved from 0.25154 to 0.25098, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1268 - val_loss: 0.2510\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0920\n",
            "Epoch 00008: val_loss did not improve from 0.25098\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 1.0920 - val_loss: 0.2526\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0557\n",
            "Epoch 00009: val_loss improved from 0.25098 to 0.23765, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.0557 - val_loss: 0.2376\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0240\n",
            "Epoch 00010: val_loss improved from 0.23765 to 0.23325, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0240 - val_loss: 0.2333\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0034\n",
            "Epoch 00011: val_loss improved from 0.23325 to 0.22913, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 1.0034 - val_loss: 0.2291\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9736\n",
            "Epoch 00012: val_loss improved from 0.22913 to 0.22632, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9736 - val_loss: 0.2263\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9629\n",
            "Epoch 00013: val_loss did not improve from 0.22632\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.9629 - val_loss: 0.2279\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9387\n",
            "Epoch 00014: val_loss improved from 0.22632 to 0.22182, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9387 - val_loss: 0.2218\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9172\n",
            "Epoch 00015: val_loss improved from 0.22182 to 0.22107, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9172 - val_loss: 0.2211\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9017\n",
            "Epoch 00016: val_loss improved from 0.22107 to 0.21815, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.9017 - val_loss: 0.2181\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8897\n",
            "Epoch 00017: val_loss improved from 0.21815 to 0.21669, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.8897 - val_loss: 0.2167\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8701\n",
            "Epoch 00018: val_loss did not improve from 0.21669\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8701 - val_loss: 0.2212\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8618\n",
            "Epoch 00019: val_loss did not improve from 0.21669\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8618 - val_loss: 0.2182\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8417\n",
            "Epoch 00020: val_loss improved from 0.21669 to 0.21507, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.8417 - val_loss: 0.2151\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8319\n",
            "Epoch 00021: val_loss improved from 0.21507 to 0.21452, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.8319 - val_loss: 0.2145\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8174\n",
            "Epoch 00022: val_loss improved from 0.21452 to 0.21252, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8174 - val_loss: 0.2125\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8045\n",
            "Epoch 00023: val_loss did not improve from 0.21252\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8045 - val_loss: 0.2148\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7980\n",
            "Epoch 00024: val_loss did not improve from 0.21252\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.7980 - val_loss: 0.2127\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7831\n",
            "Epoch 00025: val_loss improved from 0.21252 to 0.21228, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7831 - val_loss: 0.2123\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7719\n",
            "Epoch 00026: val_loss improved from 0.21228 to 0.20994, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7719 - val_loss: 0.2099\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7617\n",
            "Epoch 00027: val_loss did not improve from 0.20994\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7617 - val_loss: 0.2126\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7588\n",
            "Epoch 00028: val_loss improved from 0.20994 to 0.20877, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7588 - val_loss: 0.2088\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7485\n",
            "Epoch 00029: val_loss improved from 0.20877 to 0.20794, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7485 - val_loss: 0.2079\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7407\n",
            "Epoch 00030: val_loss did not improve from 0.20794\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7407 - val_loss: 0.2094\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7334\n",
            "Epoch 00031: val_loss improved from 0.20794 to 0.20731, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7334 - val_loss: 0.2073\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7242\n",
            "Epoch 00032: val_loss did not improve from 0.20731\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7242 - val_loss: 0.2080\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7172\n",
            "Epoch 00033: val_loss did not improve from 0.20731\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7172 - val_loss: 0.2077\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7112\n",
            "Epoch 00034: val_loss did not improve from 0.20731\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7112 - val_loss: 0.2089\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7041\n",
            "Epoch 00035: val_loss improved from 0.20731 to 0.20640, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7041 - val_loss: 0.2064\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6985\n",
            "Epoch 00036: val_loss did not improve from 0.20640\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6985 - val_loss: 0.2116\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6939\n",
            "Epoch 00037: val_loss did not improve from 0.20640\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6939 - val_loss: 0.2073\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6874\n",
            "Epoch 00038: val_loss did not improve from 0.20640\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6874 - val_loss: 0.2072\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6863\n",
            "Epoch 00039: val_loss did not improve from 0.20640\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6863 - val_loss: 0.2076\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6785\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.20640\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6785 - val_loss: 0.2071\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6639\n",
            "Epoch 00041: val_loss improved from 0.20640 to 0.20474, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6639 - val_loss: 0.2047\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6597\n",
            "Epoch 00042: val_loss improved from 0.20474 to 0.20461, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6597 - val_loss: 0.2046\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6537\n",
            "Epoch 00043: val_loss did not improve from 0.20461\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6537 - val_loss: 0.2054\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6486\n",
            "Epoch 00044: val_loss improved from 0.20461 to 0.20399, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6486 - val_loss: 0.2040\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6475\n",
            "Epoch 00045: val_loss did not improve from 0.20399\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6475 - val_loss: 0.2050\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6441\n",
            "Epoch 00046: val_loss did not improve from 0.20399\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6441 - val_loss: 0.2077\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6407\n",
            "Epoch 00047: val_loss improved from 0.20399 to 0.20320, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6407 - val_loss: 0.2032\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6334\n",
            "Epoch 00048: val_loss did not improve from 0.20320\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6334 - val_loss: 0.2047\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6325\n",
            "Epoch 00049: val_loss did not improve from 0.20320\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6325 - val_loss: 0.2052\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6310\n",
            "Epoch 00050: val_loss did not improve from 0.20320\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6310 - val_loss: 0.2044\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6245\n",
            "Epoch 00051: val_loss did not improve from 0.20320\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6245 - val_loss: 0.2038\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6220\n",
            "Epoch 00052: val_loss improved from 0.20320 to 0.20218, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.6220 - val_loss: 0.2022\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6177\n",
            "Epoch 00053: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6177 - val_loss: 0.2052\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6164\n",
            "Epoch 00054: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6164 - val_loss: 0.2032\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6117\n",
            "Epoch 00055: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6117 - val_loss: 0.2039\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6064\n",
            "Epoch 00056: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.6064 - val_loss: 0.2041\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6041\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6041 - val_loss: 0.2054\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5975\n",
            "Epoch 00058: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5975 - val_loss: 0.2029\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5913\n",
            "Epoch 00059: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5913 - val_loss: 0.2034\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5895\n",
            "Epoch 00060: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5895 - val_loss: 0.2040\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5924\n",
            "Epoch 00061: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5924 - val_loss: 0.2043\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5882\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5882 - val_loss: 0.2028\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5787\n",
            "Epoch 00063: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5787 - val_loss: 0.2028\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5748\n",
            "Epoch 00064: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5748 - val_loss: 0.2041\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5706\n",
            "Epoch 00065: val_loss did not improve from 0.20218\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5706 - val_loss: 0.2034\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5702\n",
            "Epoch 00066: val_loss improved from 0.20218 to 0.20192, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5702 - val_loss: 0.2019\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5665\n",
            "Epoch 00067: val_loss did not improve from 0.20192\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5665 - val_loss: 0.2025\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5650\n",
            "Epoch 00068: val_loss did not improve from 0.20192\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5650 - val_loss: 0.2036\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5655\n",
            "Epoch 00069: val_loss did not improve from 0.20192\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5655 - val_loss: 0.2027\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5607\n",
            "Epoch 00070: val_loss did not improve from 0.20192\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5607 - val_loss: 0.2034\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5591\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.20192\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5591 - val_loss: 0.2025\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5524\n",
            "Epoch 00072: val_loss improved from 0.20192 to 0.20155, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5524 - val_loss: 0.2015\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5492\n",
            "Epoch 00073: val_loss did not improve from 0.20155\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5492 - val_loss: 0.2023\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5475\n",
            "Epoch 00074: val_loss did not improve from 0.20155\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5475 - val_loss: 0.2021\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5486\n",
            "Epoch 00075: val_loss did not improve from 0.20155\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5486 - val_loss: 0.2031\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5448\n",
            "Epoch 00076: val_loss did not improve from 0.20155\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5448 - val_loss: 0.2018\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5411\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.20155\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5411 - val_loss: 0.2021\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5368\n",
            "Epoch 00078: val_loss did not improve from 0.20155\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5368 - val_loss: 0.2027\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5359\n",
            "Epoch 00079: val_loss improved from 0.20155 to 0.20136, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5359 - val_loss: 0.2014\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5332\n",
            "Epoch 00080: val_loss improved from 0.20136 to 0.20067, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5332 - val_loss: 0.2007\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5314\n",
            "Epoch 00081: val_loss did not improve from 0.20067\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5314 - val_loss: 0.2015\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5304\n",
            "Epoch 00082: val_loss did not improve from 0.20067\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5304 - val_loss: 0.2017\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5271\n",
            "Epoch 00083: val_loss did not improve from 0.20067\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5271 - val_loss: 0.2009\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5265\n",
            "Epoch 00084: val_loss did not improve from 0.20067\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5265 - val_loss: 0.2013\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5252\n",
            "Epoch 00085: val_loss improved from 0.20067 to 0.20057, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5252 - val_loss: 0.2006\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5221\n",
            "Epoch 00086: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5221 - val_loss: 0.2011\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5209\n",
            "Epoch 00087: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5209 - val_loss: 0.2020\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5199\n",
            "Epoch 00088: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5199 - val_loss: 0.2017\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5186\n",
            "Epoch 00089: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5186 - val_loss: 0.2006\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5181\n",
            "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5181 - val_loss: 0.2013\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5128\n",
            "Epoch 00091: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5128 - val_loss: 0.2009\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5102\n",
            "Epoch 00092: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5102 - val_loss: 0.2009\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5077\n",
            "Epoch 00093: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5077 - val_loss: 0.2014\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5078\n",
            "Epoch 00094: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5078 - val_loss: 0.2007\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5059\n",
            "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.20057\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.5059 - val_loss: 0.2018\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5007\n",
            "Epoch 00096: val_loss improved from 0.20057 to 0.20050, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.5007 - val_loss: 0.2005\n",
            "Epoch 97/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4987\n",
            "Epoch 00097: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4987 - val_loss: 0.2010\n",
            "Epoch 98/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4981\n",
            "Epoch 00098: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4981 - val_loss: 0.2020\n",
            "Epoch 99/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4958\n",
            "Epoch 00099: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4958 - val_loss: 0.2017\n",
            "Epoch 100/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4957\n",
            "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4957 - val_loss: 0.2023\n",
            "Epoch 101/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4927\n",
            "Epoch 00101: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4927 - val_loss: 0.2015\n",
            "Epoch 102/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4892\n",
            "Epoch 00102: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4892 - val_loss: 0.2014\n",
            "Epoch 103/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4887\n",
            "Epoch 00103: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4887 - val_loss: 0.2013\n",
            "Epoch 104/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4867\n",
            "Epoch 00104: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4867 - val_loss: 0.2006\n",
            "Epoch 105/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4864\n",
            "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4864 - val_loss: 0.2011\n",
            "Epoch 106/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4832\n",
            "Epoch 00106: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4832 - val_loss: 0.2011\n",
            "Epoch 107/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4818\n",
            "Epoch 00107: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4818 - val_loss: 0.2008\n",
            "Epoch 108/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4802\n",
            "Epoch 00108: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4802 - val_loss: 0.2010\n",
            "Epoch 109/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4786\n",
            "Epoch 00109: val_loss did not improve from 0.20050\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4786 - val_loss: 0.2008\n",
            "Epoch 110/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4776\n",
            "Epoch 00110: val_loss improved from 0.20050 to 0.20045, saving model to gtn_aug_snr_7_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.4776 - val_loss: 0.2005\n",
            "Epoch 111/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4772\n",
            "Epoch 00111: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4772 - val_loss: 0.2008\n",
            "Epoch 112/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4772\n",
            "Epoch 00112: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4772 - val_loss: 0.2021\n",
            "Epoch 113/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4743\n",
            "Epoch 00113: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4743 - val_loss: 0.2013\n",
            "Epoch 114/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4736\n",
            "Epoch 00114: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4736 - val_loss: 0.2017\n",
            "Epoch 115/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4712\n",
            "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4712 - val_loss: 0.2011\n",
            "Epoch 116/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4690\n",
            "Epoch 00116: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4690 - val_loss: 0.2019\n",
            "Epoch 117/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4690\n",
            "Epoch 00117: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4690 - val_loss: 0.2017\n",
            "Epoch 118/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4675\n",
            "Epoch 00118: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4675 - val_loss: 0.2009\n",
            "Epoch 119/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4659\n",
            "Epoch 00119: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4659 - val_loss: 0.2015\n",
            "Epoch 120/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4658\n",
            "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4658 - val_loss: 0.2010\n",
            "Epoch 121/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4626\n",
            "Epoch 00121: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4626 - val_loss: 0.2011\n",
            "Epoch 122/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4622\n",
            "Epoch 00122: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4622 - val_loss: 0.2017\n",
            "Epoch 123/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4605\n",
            "Epoch 00123: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4605 - val_loss: 0.2012\n",
            "Epoch 124/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4597\n",
            "Epoch 00124: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.4597 - val_loss: 0.2011\n",
            "Epoch 125/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.4582\n",
            "Epoch 00125: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.20045\n",
            "68/68 [==============================] - 19s 278ms/step - loss: 0.4582 - val_loss: 0.2012\n",
            "Epoch 00125: early stopping\n",
            "reactivity  : 0.2008\n",
            "deg_Mg_pH10 : 0.2774\n",
            "deg_pH10    : 0.2314\n",
            "deg_Mg_50C  : 0.2060\n",
            "deg_50C     : 0.1936\n",
            "total: 0.22808461062124502\n",
            "Fold: 8  model_num: 0\n",
            "(4320, 130, 20)\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.3809\n",
            "Epoch 00001: val_loss improved from inf to 0.35566, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 23s 343ms/step - loss: 2.3809 - val_loss: 0.3557\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.4916\n",
            "Epoch 00002: val_loss improved from 0.35566 to 0.32859, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.4916 - val_loss: 0.3286\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3879\n",
            "Epoch 00003: val_loss improved from 0.32859 to 0.29237, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.3879 - val_loss: 0.2924\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.3069\n",
            "Epoch 00004: val_loss improved from 0.29237 to 0.28129, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 1.3069 - val_loss: 0.2813\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.2476\n",
            "Epoch 00005: val_loss improved from 0.28129 to 0.27190, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 1.2476 - val_loss: 0.2719\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1947\n",
            "Epoch 00006: val_loss improved from 0.27190 to 0.26311, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1947 - val_loss: 0.2631\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1474\n",
            "Epoch 00007: val_loss improved from 0.26311 to 0.24967, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1474 - val_loss: 0.2497\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.1091\n",
            "Epoch 00008: val_loss improved from 0.24967 to 0.24794, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.1091 - val_loss: 0.2479\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0748\n",
            "Epoch 00009: val_loss did not improve from 0.24794\n",
            "68/68 [==============================] - 19s 280ms/step - loss: 1.0748 - val_loss: 0.2514\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0470\n",
            "Epoch 00010: val_loss improved from 0.24794 to 0.24202, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0470 - val_loss: 0.2420\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.0244\n",
            "Epoch 00011: val_loss improved from 0.24202 to 0.23912, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 1.0244 - val_loss: 0.2391\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9991\n",
            "Epoch 00012: val_loss improved from 0.23912 to 0.23463, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9991 - val_loss: 0.2346\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9817\n",
            "Epoch 00013: val_loss improved from 0.23463 to 0.23133, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9817 - val_loss: 0.2313\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9549\n",
            "Epoch 00014: val_loss improved from 0.23133 to 0.22804, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9549 - val_loss: 0.2280\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9358\n",
            "Epoch 00015: val_loss improved from 0.22804 to 0.22525, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9358 - val_loss: 0.2253\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9211\n",
            "Epoch 00016: val_loss improved from 0.22525 to 0.22387, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.9211 - val_loss: 0.2239\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.9072\n",
            "Epoch 00017: val_loss did not improve from 0.22387\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.9072 - val_loss: 0.2240\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8882\n",
            "Epoch 00018: val_loss improved from 0.22387 to 0.22133, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.8882 - val_loss: 0.2213\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8758\n",
            "Epoch 00019: val_loss did not improve from 0.22133\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8758 - val_loss: 0.2219\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8617\n",
            "Epoch 00020: val_loss did not improve from 0.22133\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8617 - val_loss: 0.2255\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8626\n",
            "Epoch 00021: val_loss improved from 0.22133 to 0.21766, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8626 - val_loss: 0.2177\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8388\n",
            "Epoch 00022: val_loss did not improve from 0.21766\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8388 - val_loss: 0.2195\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8212\n",
            "Epoch 00023: val_loss did not improve from 0.21766\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.8212 - val_loss: 0.2186\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8158\n",
            "Epoch 00024: val_loss improved from 0.21766 to 0.21626, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8158 - val_loss: 0.2163\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.8009\n",
            "Epoch 00025: val_loss improved from 0.21626 to 0.21502, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.8009 - val_loss: 0.2150\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7933\n",
            "Epoch 00026: val_loss did not improve from 0.21502\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7933 - val_loss: 0.2157\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7834\n",
            "Epoch 00027: val_loss improved from 0.21502 to 0.21486, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7834 - val_loss: 0.2149\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7731\n",
            "Epoch 00028: val_loss improved from 0.21486 to 0.21381, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.7731 - val_loss: 0.2138\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7630\n",
            "Epoch 00029: val_loss improved from 0.21381 to 0.21210, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7630 - val_loss: 0.2121\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7504\n",
            "Epoch 00030: val_loss did not improve from 0.21210\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7504 - val_loss: 0.2125\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7453\n",
            "Epoch 00031: val_loss did not improve from 0.21210\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7453 - val_loss: 0.2135\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7403\n",
            "Epoch 00032: val_loss improved from 0.21210 to 0.21041, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7403 - val_loss: 0.2104\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7334\n",
            "Epoch 00033: val_loss did not improve from 0.21041\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7334 - val_loss: 0.2123\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7248\n",
            "Epoch 00034: val_loss did not improve from 0.21041\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7248 - val_loss: 0.2109\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7197\n",
            "Epoch 00035: val_loss did not improve from 0.21041\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7197 - val_loss: 0.2104\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7115\n",
            "Epoch 00036: val_loss improved from 0.21041 to 0.21020, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7115 - val_loss: 0.2102\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7050\n",
            "Epoch 00037: val_loss improved from 0.21020 to 0.20898, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.7050 - val_loss: 0.2090\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.7025\n",
            "Epoch 00038: val_loss did not improve from 0.20898\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.7025 - val_loss: 0.2101\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6937\n",
            "Epoch 00039: val_loss did not improve from 0.20898\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6937 - val_loss: 0.2097\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6846\n",
            "Epoch 00040: val_loss did not improve from 0.20898\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6846 - val_loss: 0.2114\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6827\n",
            "Epoch 00041: val_loss did not improve from 0.20898\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6827 - val_loss: 0.2118\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6761\n",
            "Epoch 00042: val_loss improved from 0.20898 to 0.20718, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6761 - val_loss: 0.2072\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6662\n",
            "Epoch 00043: val_loss did not improve from 0.20718\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6662 - val_loss: 0.2082\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6635\n",
            "Epoch 00044: val_loss did not improve from 0.20718\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6635 - val_loss: 0.2087\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6635\n",
            "Epoch 00045: val_loss did not improve from 0.20718\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6635 - val_loss: 0.2072\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6559\n",
            "Epoch 00046: val_loss improved from 0.20718 to 0.20677, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6559 - val_loss: 0.2068\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6500\n",
            "Epoch 00047: val_loss did not improve from 0.20677\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6500 - val_loss: 0.2076\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6465\n",
            "Epoch 00048: val_loss did not improve from 0.20677\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6465 - val_loss: 0.2069\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6412\n",
            "Epoch 00049: val_loss did not improve from 0.20677\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6412 - val_loss: 0.2078\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6429\n",
            "Epoch 00050: val_loss did not improve from 0.20677\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6429 - val_loss: 0.2070\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6366\n",
            "Epoch 00051: val_loss improved from 0.20677 to 0.20664, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6366 - val_loss: 0.2066\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6308\n",
            "Epoch 00052: val_loss did not improve from 0.20664\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6308 - val_loss: 0.2070\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6255\n",
            "Epoch 00053: val_loss improved from 0.20664 to 0.20650, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6255 - val_loss: 0.2065\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6259\n",
            "Epoch 00054: val_loss improved from 0.20650 to 0.20544, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6259 - val_loss: 0.2054\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6200\n",
            "Epoch 00055: val_loss improved from 0.20544 to 0.20485, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6200 - val_loss: 0.2048\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6163\n",
            "Epoch 00056: val_loss did not improve from 0.20485\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6163 - val_loss: 0.2051\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6112\n",
            "Epoch 00057: val_loss improved from 0.20485 to 0.20397, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6112 - val_loss: 0.2040\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6091\n",
            "Epoch 00058: val_loss did not improve from 0.20397\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6091 - val_loss: 0.2041\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6090\n",
            "Epoch 00059: val_loss did not improve from 0.20397\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.6090 - val_loss: 0.2057\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.6081\n",
            "Epoch 00060: val_loss improved from 0.20397 to 0.20393, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.6081 - val_loss: 0.2039\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5967\n",
            "Epoch 00061: val_loss did not improve from 0.20393\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5967 - val_loss: 0.2044\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5970\n",
            "Epoch 00062: val_loss improved from 0.20393 to 0.20287, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5970 - val_loss: 0.2029\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5936\n",
            "Epoch 00063: val_loss did not improve from 0.20287\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5936 - val_loss: 0.2047\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5917\n",
            "Epoch 00064: val_loss did not improve from 0.20287\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5917 - val_loss: 0.2055\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5883\n",
            "Epoch 00065: val_loss did not improve from 0.20287\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5883 - val_loss: 0.2037\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5870\n",
            "Epoch 00066: val_loss improved from 0.20287 to 0.20225, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5870 - val_loss: 0.2023\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5811\n",
            "Epoch 00067: val_loss did not improve from 0.20225\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5811 - val_loss: 0.2031\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5801\n",
            "Epoch 00068: val_loss improved from 0.20225 to 0.20192, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5801 - val_loss: 0.2019\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5755\n",
            "Epoch 00069: val_loss did not improve from 0.20192\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5755 - val_loss: 0.2042\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5727\n",
            "Epoch 00070: val_loss did not improve from 0.20192\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5727 - val_loss: 0.2033\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5711\n",
            "Epoch 00071: val_loss improved from 0.20192 to 0.20129, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5711 - val_loss: 0.2013\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5693\n",
            "Epoch 00072: val_loss did not improve from 0.20129\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5693 - val_loss: 0.2021\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5662\n",
            "Epoch 00073: val_loss did not improve from 0.20129\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5662 - val_loss: 0.2015\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5664\n",
            "Epoch 00074: val_loss did not improve from 0.20129\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5664 - val_loss: 0.2032\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5656\n",
            "Epoch 00075: val_loss did not improve from 0.20129\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5656 - val_loss: 0.2030\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5652\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.20129\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5652 - val_loss: 0.2021\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5526\n",
            "Epoch 00077: val_loss improved from 0.20129 to 0.20056, saving model to gtn_aug_snr_8_0.h5\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.5526 - val_loss: 0.2006\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - ETA: 0s - loss: 0.5498\n",
            "Epoch 00078: val_loss did not improve from 0.20056\n",
            "68/68 [==============================] - 19s 279ms/step - loss: 0.5498 - val_loss: 0.2026\n",
            "Epoch 79/500\n",
            "18/68 [======>.......................] - ETA: 13s - loss: 0.5468Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T06:41:19.520687Z",
          "iopub.status.busy": "2020-10-01T06:41:19.518940Z",
          "iopub.status.idle": "2020-10-01T06:41:19.521354Z",
          "shell.execute_reply": "2020-10-01T06:41:19.521878Z"
        },
        "papermill": {
          "duration": 42.401313,
          "end_time": "2020-10-01T06:41:19.522000",
          "exception": false,
          "start_time": "2020-10-01T06:40:37.120687",
          "status": "completed"
        },
        "tags": [],
        "id": "Q4GGiqtdaItT"
      },
      "source": [
        "if 0:\n",
        "    #plt.plot(history.history['loss'][10:], label='train')\n",
        "    plt.plot(history.history['val_loss'][10:], label='val')\n",
        "    plt.yscale('log')\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-01T06:42:44.907549Z",
          "iopub.status.busy": "2020-10-01T06:42:44.905860Z",
          "iopub.status.idle": "2020-10-01T06:43:00.606840Z",
          "shell.execute_reply": "2020-10-01T06:43:00.607922Z"
        },
        "papermill": {
          "duration": 58.187605,
          "end_time": "2020-10-01T06:43:00.608128",
          "exception": false,
          "start_time": "2020-10-01T06:42:02.420523",
          "status": "completed"
        },
        "tags": [],
        "id": "Uu_p4yRRaItV"
      },
      "source": [
        "np.save(f'/content/{model_name}_oof', oof)\n",
        "np.save(f'/content/{model_name}_gru_public_preds', gru_public_preds)\n",
        "np.save(f'/content/{model_name}_gru_private_preds', gru_private_preds)\n",
        "\n",
        "\n",
        "#gru_public_preds = np.load(f'preds/{model_name}_gru_public_preds.npy')\n",
        "#gru_private_preds = np.load(f'preds/{model_name}_gru_private_preds.npy')\n",
        "\n",
        "gru_private_preds = np.mean(gru_private_preds, axis=0)\n",
        "gru_public_preds = np.mean(gru_public_preds, axis=0)\n",
        "\n",
        "preds_gru = []\n",
        "\n",
        "for df, preds in [(public_df, gru_public_preds), (private_df, gru_private_preds)]:\n",
        "    for i, uid in enumerate(df.id):\n",
        "        single_pred = preds[i]\n",
        "\n",
        "        single_df = pd.DataFrame(single_pred, columns=target_cols)\n",
        "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
        "\n",
        "        preds_gru.append(single_df)\n",
        "\n",
        "preds_gru_df = pd.concat(preds_gru)\n",
        "\n",
        "preds_gru_df = preds_gru_df.groupby('id_seqpos').mean().reset_index()\n",
        "\n",
        "\n",
        "submission = sample_sub[['id_seqpos']].merge(preds_gru_df, on=['id_seqpos'])\n",
        "\n",
        "#sanity check\n",
        "submission.head()\n",
        "\n",
        "submission.to_csv(f'/content/drive/My Drive/kaggle/submissionwavenetfinalv1.csv', index=False)\n",
        "print('Submission saved')\n",
        "\n",
        "print('Run Time [min]:', round((time.time() - start)/60))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}